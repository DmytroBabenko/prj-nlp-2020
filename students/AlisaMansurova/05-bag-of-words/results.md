## –î–∞–Ω—ñ

–î–∞–Ω—ñ –∑—ñ–±—Ä–∞–Ω—ñ –∑ —Ä–æ–∑–¥—ñ–ª—É "–¢–í, –ê—É–¥—ñ–æ/–í—ñ–¥–µ–æ, –§–æ—Ç–æ". –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–∞–Ω–∏–º:

-   –≤—Å—å–æ–≥–æ –∑—ñ–±—Ä–∞–Ω–æ 59644 –≤—ñ–¥–≥—É–∫—ñ–≤
-   –∑ –Ω–∏—Ö 29171 –≤—ñ–¥–≥—É–∫—ñ–≤ –∑ —Ä–µ–π—Ç–∏–Ω–≥–æ–º –∞–±–æ –∑–∞–ø–æ–≤–Ω–µ–Ω–∏–º–∏ —Å–µ–∫—Ü—ñ—è–º–∏ "–ø–µ—Ä–µ–≤–∞–≥–∏"/"–Ω–µ–¥–æ–ª—ñ–∫–∏"
-   –∑ –Ω–∏—Ö 5830 —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é

–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—ó –¥–∞–Ω–∏—Ö –∑–∞ —Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞–º–∏ –±—É–ª–æ –æ—Ç—Ä–∏–º–∞–Ω–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ä–æ–∑–ø–æ–¥—ñ–ª –∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏:
- pos: 7163
- neg: 4115
- neut: 1643

–í—Å—ñ –≤—ñ–¥–≥—É–∫–∏ [—Ç—É—Ç](./rozetka_all.zip), y–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é [—Ç—É—Ç](./rozetka_uk.json)


## –ü—Ä–æ–±–ª–µ–º–∏
–û—Å–Ω–æ–≤–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏: –∞) –º–∞–ª–æ –¥–∞–Ω–∏—Ö, –±) –º–∞–ª–æ –¥–∞–Ω–∏—Ö —É –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—ñ
–ü–µ—Ä—à—É –ø—Ä–æ–±–ª–µ–º—É –Ω–∞–º–∞–≥–∞–ª–∞—Å—å –≤–∏—Ä—ñ—à–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥–∞–º–∏, –∞–ª–µ –º–µ–Ω–µ —à–≤–∏–¥–∫–æ –∑–∞–±–∞–Ω–∏–ª–∞ –≥—É–≥–ª —Ç—Ä–∞–Ω—Å–ª–µ–π—Ç –∞–ø—ñ—à–∫–∞ :) –î—Ä—É–≥—É –ø—Ä–æ–±–ª–µ–º—É —Ç—Ä–æ—à–∫–∏ –≤–¥–∞–ª–æ—Å—å –ø–æ—Ä—ñ—à–∞—Ç–∏, —Ñ—ñ–ª—å—Ç—Ä—É—é—á–∏ "–ø–µ—Ä–µ–≤–∞–≥–∏" —ñ "–Ω–µ–¥–æ–ª—ñ–∫–∏" –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –º–æ–∂–ª–∏–≤–æ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É


## –ü—ñ–¥—Ö—ñ–¥

–û—Å–∫—ñ–ª—å–∫–∏ —ñ–Ω–æ–¥—ñ —è —á–∏—Ç–∞—é –Ω–µ–≤—ñ–¥–æ–º–æ —á–∏–º, —Ç–æ –ø—Ä–æ–≤—Ç–∏–∫–∞–ª–∞ —Ç–∞–∫—ñ –Ω—é–∞–Ω—Å–∏, —è–∫ –∫—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è —ñ —â–æ —Ç—Ä–µ–±–∞ **–≤–∏–±—Ä–∞—Ç–∏** –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä, –∞ –Ω–µ **–Ω–∞–ø–∏—Å–∞—Ç–∏**. –Ü –∑–≤–µ—Ä–Ω—É–ª–∞ —É–≤–∞–≥—É –Ω–∞ —Ü–µ –∞–∂ –º–∞–π–∂–µ –≤ –æ—Å—Ç–∞–Ω–Ω—ñ–π –º–æ–º–µ–Ω—Ç üôÅ –¢–æ–º—É, —è–∫ –Ω–∞–≤—ñ–∂–µ–Ω–∞, –ø–∏–ª—è–ª–∞ Naive Bayes –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä (–Ω—É –∞–ª–µ, –æ—Å–∫—ñ–ª—å–∫–∏ –Ω–µ –¥–æ—ñ–º–ø–ª–µ–º–µ–Ω—Ç—É–≤–∞–ª–∞ –π–æ–≥–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–º—É –∑–∞–Ω—è—Ç—Ç—ñ, —Ç–æ –¥–æ—Ä–æ–±–∏–ª–∞ —Ç—É—Ç, —Å–ø–æ–¥—ñ–≤–∞—é—Å—å, –±—ñ–ª—å—à-–º–µ–Ω—à –≤—ñ—Ä–Ω–æ). –í –∫—ñ–Ω—Ü—ñ —è —Ç–∞–∫–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–ª–∞ —Ç—Ä–æ—Ö–∏ –º–∞–≥—ñ—ó –∑ `sklearn`, –ø—Ä–∞–≤–¥–∞, –Ω—É –æ—Ç –≤–∑–∞–≥–∞–ª—ñ –Ω–µ –≤–ø–µ–≤–Ω–µ–Ω–∞ —É –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—ñ –¥—ñ–π, –±–æ –ø–æ—Å–ª—É–≥–æ–≤—É–∞–ª–∞—Å—å –≤ –æ—Å–Ω–æ–≤–Ω–æ–º—É –≥—É–≥–ª–æ–º —ñ –Ω–µ –¥–æ –∫—ñ–Ω—Ü—è –ø–æ–∫–∏ —Ä–æ–∑—É–º—ñ—é, —â–æ –≤–æ–Ω–æ –ø—ñ–¥ –∫–∞–ø–æ—Ç–æ–º —Ä–æ–±–∏—Ç—å

## –Ü—Ç–µ—Ä–∞—Ü—ñ—ó

–ö–æ–∂–Ω–∞ –Ω–∞—Å—Ç—É–ø–Ω–∞ —ñ—Ç–µ—Ä–∞—Ü—ñ—è —î –∫—É–º—É–ª—è—Ç–∏–≤–Ω–æ—é (–æ–ø–µ—Ä—É—î –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ—ó, –æ–∫—Ä—ñ–º n-gramms, —Ç–∞–º –±—É–ª–∏ –æ–ø—Ä–æ–±—É–≤–∞–Ω—ñ –≤—Å—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏)

### Tokenization

-   classification report

```
              precision    recall  f1-score   support

         neg       0.90      0.34      0.49      1241
        neut       0.72      0.06      0.12       489
         pos       0.63      0.98      0.76      2147

    accuracy                           0.66      3877
   macro avg       0.75      0.46      0.46      3877
weighted avg       0.73      0.66      0.60      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.74   0.95     0.83
neut               0.5    0.2     0.29
neg               0.81   0.61      0.7
                                      
accuracy                          0.75
macro avg         0.68   0.59     0.61
weighted avg      0.73   0.75     0.72
```

### Lowercasing

-   classification report

```
              precision    recall  f1-score   support

         neg       0.91      0.35      0.50      1241
        neut       0.62      0.04      0.07       489
         pos       0.63      0.98      0.77      2147

    accuracy                           0.66      3877
   macro avg       0.72      0.46      0.45      3877
weighted avg       0.72      0.66      0.59      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.74   0.95     0.83
neut               0.5    0.2     0.29
neg               0.81   0.61      0.7
                                      
accuracy                          0.75
macro avg         0.68   0.59     0.61
weighted avg      0.73   0.75     0.72
```

–¥–∏–≤–Ω–æ, —á–æ–º—É—Å—å —Ç—É—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–≥—ñ—Ä—à–∏–ª–∏—Å—å

### Lemmatization

-   classification report

```
              precision    recall  f1-score   support

         neg       0.89      0.34      0.49      1241
        neut       0.47      0.01      0.03       489
         pos       0.62      0.99      0.76      2147

    accuracy                           0.66      3877
   macro avg       0.66      0.45      0.43      3877
weighted avg       0.69      0.66      0.58      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.77   0.94     0.84
neut              0.49   0.23     0.31
neg               0.79   0.66     0.72
                                      
accuracy                          0.76
macro avg         0.68   0.61     0.63
weighted avg      0.74   0.76     0.74
```


### Filtering symbols, punctuation, latin words, nums

-   classification report

```
              precision    recall  f1-score   support

         neg       0.81      0.40      0.54      1241
        neut       0.17      0.01      0.01       489
         pos       0.65      0.98      0.78      2147

    accuracy                           0.67      3877
   macro avg       0.54      0.46      0.44      3877
weighted avg       0.64      0.67      0.60      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.77   0.93     0.84
neut              0.41   0.15     0.22
neg               0.76   0.67     0.71
                                      
accuracy                          0.75
macro avg         0.65   0.58     0.59
weighted avg      0.72   0.75     0.72
```

 —à–æ—Å—å –Ω–µ —Ç–æ
 

### Processing negations

-   classification report

```
              precision    recall  f1-score   support

         neg       0.83      0.45      0.59      1241
        neut       0.32      0.02      0.03       489
         pos       0.66      0.98      0.79      2147

    accuracy                           0.69      3877
   macro avg       0.60      0.48      0.47      3877
weighted avg       0.67      0.69      0.63      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.79   0.93     0.85
neut              0.46   0.18     0.25
neg               0.78   0.72     0.75
                                      
accuracy                          0.77
macro avg         0.68   0.61     0.62
weighted avg      0.74   0.77     0.74
```

—è –ø–æ–∫–ª–∞–¥–∞–ª–∞ –±—ñ–ª—å—à—ñ –Ω–∞–¥—ñ—ó –Ω–∞ —Ü–µ–π –º–µ—Ç–æ–¥, –Ω—É –∞–ª–µ, –º–∞–±—É—Ç—å, –Ω–µ –¥–æ –∫—ñ–Ω—Ü—è –π–æ–≥–æ "–ø—Ä–æ–∂–∞—Ä–∏–ª–∞", –∞–±–æ –¥–µ—Å—å –ø–æ–º–∏–ª–∏–ª–∞—Å—å, –±–æ –∑–∞–ø–µ—Ä–µ—á–µ–Ω—å —É –¥–∞–Ω–∏—Ö –≤–∏—Å—Ç–∞—á–∞—î


### n-grams

–¢—É—Ç —è –ø–æ—î–¥–Ω—É–≤–∞–ª–∞ –Ω-–≥—Ä–∞–º–∏ –∑ —ñ–Ω—à–∏–º–∏ (–∫—É–º—É–ª—è—Ç–∏–≤–Ω–∏–º–∏) –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞–º–∏

1. with lowerizing

-   classification report

```
              precision    recall  f1-score   support

         neg       0.89      0.31      0.46      1241
        neut       1.00      0.02      0.04       489
         pos       0.62      0.99      0.76      2147

    accuracy                           0.65      3877
   macro avg       0.83      0.44      0.42      3877
weighted avg       0.75      0.65      0.57      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.82   0.85     0.84
neut              0.41   0.39      0.4
neg               0.76   0.72     0.74
                                      
accuracy                          0.75
macro avg         0.66   0.66     0.66
weighted avg      0.75   0.75     0.75
```

—á–æ–≥–æ—Å—å —Ç–∞–∫–æ—î...

2. with lemmatization

-   classification report

```
              precision    recall  f1-score   support

         neg       0.88      0.33      0.48      1241
        neut       0.00      0.00      0.00       489
         pos       0.62      0.99      0.76      2147

    accuracy                           0.65      3877
   macro avg       0.50      0.44      0.41      3877
weighted avg       0.62      0.65      0.57      3877
```

—à–æ—Å—å –∑–æ–≤—Å—ñ–º –ø—ñ—à–ª–æ –Ω–µ —Ç–∞–∫...


-   cross-validation report

```
             precision recall f1-score
pos               0.82   0.85     0.84
neut               0.4   0.36     0.38
neg               0.75   0.73     0.74
                                      
accuracy                          0.75
macro avg         0.66   0.65     0.65
weighted avg      0.74   0.75     0.75
```


3. with stop-words filtering

-   classification report

```
              precision    recall  f1-score   support

         neg       0.81      0.35      0.49      1241
        neut       0.00      0.00      0.00       489
         pos       0.63      0.98      0.77      2147

    accuracy                           0.66      3877
   macro avg       0.48      0.44      0.42      3877
weighted avg       0.61      0.66      0.58      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.83   0.83     0.83
neut              0.33   0.32     0.33
neg               0.72   0.73     0.72
                                      
accuracy                          0.73
macro avg         0.63   0.63     0.63
weighted avg      0.73   0.73     0.73
```

... —ñ —Ç—É—Ç...

4. with negation processing

-   classification report

```
              precision    recall  f1-score   support

         neg       0.80      0.35      0.49      1241
        neut       0.00      0.00      0.00       489
         pos       0.63      0.98      0.77      2147

    accuracy                           0.66      3877
   macro avg       0.48      0.45      0.42      3877
weighted avg       0.61      0.66      0.58      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.83   0.84     0.84
neut              0.33   0.31     0.32
neg               0.73   0.73     0.73
                                      
accuracy                          0.74
macro avg         0.63   0.63     0.63
weighted avg      0.73   0.74     0.73
```

... —Ç–µ–∂ ...

5. without any additional preprocessing

-   classification report

```
              precision    recall  f1-score   support

         neg       0.87      0.34      0.49      1241
        neut       1.00      0.02      0.05       489
         pos       0.63      0.98      0.76      2147

    accuracy                           0.66      3877
   macro avg       0.83      0.45      0.43      3877
weighted avg       0.75      0.66      0.59      3877
```

-   cross-validation report

```
             precision recall f1-score
pos               0.81   0.87     0.84
neut              0.43   0.35     0.38
neg               0.76   0.72     0.74
                                      
accuracy                          0.76
macro avg         0.67   0.65     0.66
weighted avg      0.75   0.76     0.75
```

—è–∫ –Ω–µ –¥–∏–≤–Ω–æ, –∞–ª–µ —Ü–µ –Ω–∞–π–∫—Ä–∞—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–µ—Ä–µ–¥ "–Ω-–≥—Ä–∞–º–Ω–∏—Ö" (—è–∫—â–æ —è –Ω—ñ—á–æ–≥–æ –Ω–µ –ø–ª—É—Ç–∞—é), —ñ –º–æ–∂–Ω–∞ –∑—Ä–æ–±–∏—Ç–∏ –≤–∏—Å–Ω–æ–≤–æ–∫, —â–æ –∑ –Ω-–≥—Ä–∞–º–∞–º–∏ –∫—Ä–∞—â–µ –Ω–µ –ø–æ—î–¥–Ω—É–≤–∞—Ç–∏ —ñ–Ω—à—ñ —Ç–µ–∫—Å—Ç –ø—Ä–æ—Ü–µ—Å–æ—Ä–∏. –∞–ª–µ –≤—Å–µ –æ–¥–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ–≥–∞–Ω—ñ. –ø—Ä–æ–±—É–≤–∞–ª–∞ –±—ñ–≥—Ä–∞–º–∏ - –Ω–µ –¥–æ–ø–æ–º–æ–≥–ª–æ
