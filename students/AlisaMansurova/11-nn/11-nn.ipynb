{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1547,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tokenize_uk\n",
    "import pymorphy2\n",
    "import stanza\n",
    "import spacy\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from conllu import parse\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import OrderedDict\n",
    "import progressbar\n",
    "import tensorflow as tf\n",
    "import random as python_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1401,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../../../UD_Ukrainian-IU'\n",
    "\n",
    "with open(PATH + '/uk_iu-ud-train.conllu') as f:\n",
    "    train_data = f.read()\n",
    "    \n",
    "with open(PATH + '/uk_iu-ud-dev.conllu') as f:\n",
    "    test_data = f.read()\n",
    "\n",
    "train_trees = parse(train_data)\n",
    "test_trees = parse(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1402,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_uk = spacy.load('/Users/lissm/Work/Dev/NLP/corpora/vectors/ubercorpus_lowercased_tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Oracle LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(int, Enum):\n",
    "    SHIFT = 0\n",
    "    REDUCE = 1\n",
    "    RIGHT = 2\n",
    "    LEFT = 3\n",
    "\n",
    "\n",
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats',\n",
    "                                        None), ('head', None),  ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_as(trees, clf, vect, feature_extractor):\n",
    "    total, tpu, tpl, full_match = 0, 0, 0, 0\n",
    "    golden_u, golden_l = None, None\n",
    "    for tree in trees:\n",
    "        tree = [t for t in tree if type(t['id']) == int]\n",
    "        golden_all = [(node['id'], node['head'], node['deprel'])\n",
    "                      for node in tree]\n",
    "        golden_u = [(x, y) for x, y, _ in golden_all]\n",
    "\n",
    "        predicted_all = dep_parse(tree, clf, vect, feature_extractor)\n",
    "        predicted_u = [(x, y) for x, y, _ in predicted_all]\n",
    "\n",
    "        total += len(tree)\n",
    "        tpu += len(set(golden_u).intersection(set(predicted_u)))\n",
    "        tpl += len(set(golden_all).intersection(set(predicted_all)))\n",
    "\n",
    "        if set(golden_all) == set(predicted_all):\n",
    "            full_match += 1\n",
    "\n",
    "    print('== Attachment score report ==')\n",
    "    print('Total: ', total)\n",
    "    print('Match labeled: ', tpl)\n",
    "    print('LAS: ', round(tpl/total, 2))\n",
    "    print(\"Full match:\", round(full_match/len(trees), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1574,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_model(trees):\n",
    "    words = []\n",
    "    for tree in trees:\n",
    "        words.append([x['lemma'] for x in tree])\n",
    "    model = Word2Vec(\n",
    "        words, size=300, min_count=1, workers=6,\n",
    "        window=5, alpha=0.030, negative=7, iter=5\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_pos_tag_map(trees):\n",
    "    pos_map = {'ROOT': 0, 'UNK': 1}\n",
    "    cnt = 1\n",
    "\n",
    "    for tree in trees:\n",
    "        for tok in tree:\n",
    "            if not pos_map.get(tok['upostag']):\n",
    "                pos_map[tok['upostag']] = cnt\n",
    "                cnt += 1\n",
    "    return pos_map\n",
    "    \n",
    "\n",
    "def oracle(stack, top_queue, relations):\n",
    "    top_stack = stack[-1]\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    elif top_queue['head'] == top_stack['id']:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack['head'] == top_queue['id']:\n",
    "        return Actions.LEFT\n",
    "    elif top_stack['id'] in [i[0] for i in relations] and \\\n",
    "        (top_queue['head'] < top_stack['id'] or\n",
    "         [s for s in stack if s['head'] == top_queue['id']]):\n",
    "        return Actions.REDUCE\n",
    "    else:\n",
    "        return Actions.SHIFT\n",
    "\n",
    "\n",
    "def get_data_for_tree(tree, pos_map):\n",
    "    res = []\n",
    "    stack, buffer, relations = [ROOT], tree[:], []\n",
    "    top_feats = 0\n",
    "    \n",
    "    while buffer or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        buffer[0] if len(buffer) > 0 else None,\n",
    "                        relations)\n",
    "        # we need 3 words from stack and buffer to train the LSTM model\n",
    "        if top_feats < 3 and len(stack) and len(buffer):\n",
    "            top_stack = stack[-1]\n",
    "            top_buff = buffer[0]\n",
    "            res.append((top_stack['lemma'], pos_map[top_stack['upostag'] or pos_map['UNK']],\n",
    "                        top_buff['lemma'], pos_map[top_buff['upostag'] or pos_map['UNK']],\n",
    "                        action.value))\n",
    "            top_feats += 1\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(buffer.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            rel = (stack[-1]['id'], buffer[0]['id'])\n",
    "            relations.append(rel)\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            rel = (buffer[0]['id'], stack[-1]['id'])\n",
    "            relations.append(rel)\n",
    "            stack.append(buffer.pop(0))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_data(trees, v2w_model, pos_map):\n",
    "    vectors, labels = [], []\n",
    "    for tree in trees:\n",
    "        t_vectors, t_labels = [], []\n",
    "        tree_data = get_data_for_tree(\n",
    "            [t for t in tree if type(t['id']) == int], pos_map)\n",
    "        for stack, stack_pos, buff, buff_pos, label in tree_data:\n",
    "            try:\n",
    "                stack_vect = v2w_model.wv[stack]\n",
    "                buff_vect = v2w_model.wv[buff]\n",
    "                stack_vect_pos = np.append(stack_vect, [stack_pos])\n",
    "                buff_vect_pos = np.append(buff_vect, [buff_pos])\n",
    "                vc = np.concatenate((stack_vect_pos, buff_vect_pos))\n",
    "                vectors.append(vc)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return np.dstack(vectors), np.dstack(labels)\n",
    "\n",
    "\n",
    "def get_predicted_label(labels):\n",
    "    l = labels[0][0]\n",
    "    return np.argmax(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(n_vocab, n_classes, X):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences=True, activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "    model.add(LSTM(512, return_sequences=True, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def to_cat(y_int, vocab_size):\n",
    "    return to_categorical(y_int, num_classes=vocab_size)\n",
    "\n",
    "\n",
    "def train_model(model, epochs, x, y, n_classes):\n",
    "    model.fit(x, y, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "python_random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 00:39:11 WARNING: under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "v2w_model = get_w2v_model(train_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1442,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_map = get_pos_tag_map(train_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1996,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def window_stack(a, stepsize=1, width=3):\n",
    "    return np.hstack(a[i:1+i-width or None:stepsize] for i in range(0, width))\n",
    "\n",
    "train_x, train_y = get_data(train_trees, v2w_model, pos_map)\n",
    "n_vocab = len(train_x)\n",
    "n_classes = 4\n",
    "x = np.moveaxis(train_x, -1, 0)\n",
    "y = np.moveaxis(train_y, -1, 0)\n",
    "y = np.array([to_cat(x, n_classes) for x in y])\n",
    "x = window_stack(x)\n",
    "y = window_stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_144\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_230 (LSTM)              (None, 3, 256)            879616    \n",
      "_________________________________________________________________\n",
      "lstm_231 (LSTM)              (None, 3, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 3, 64)             32832     \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 3, 4)              260       \n",
      "=================================================================\n",
      "Total params: 2,487,620\n",
      "Trainable params: 2,487,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = make_model(n_vocab, n_classes, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1994,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.3595 - accuracy: 0.8596\n",
      "Epoch 2/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.3397 - accuracy: 0.8690\n",
      "Epoch 3/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.3343 - accuracy: 0.8715\n",
      "Epoch 4/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.3358 - accuracy: 0.8722\n",
      "Epoch 5/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.3162 - accuracy: 0.8786\n",
      "Epoch 6/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.3125 - accuracy: 0.8810\n",
      "Epoch 7/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.3132 - accuracy: 0.8810\n",
      "Epoch 8/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2945 - accuracy: 0.8872\n",
      "Epoch 9/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2978 - accuracy: 0.8873\n",
      "Epoch 10/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2873 - accuracy: 0.8894\n",
      "Epoch 11/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2912 - accuracy: 0.8906\n",
      "Epoch 12/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2821 - accuracy: 0.8936\n",
      "Epoch 13/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2851 - accuracy: 0.8930\n",
      "Epoch 14/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2633 - accuracy: 0.9007\n",
      "Epoch 15/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2604 - accuracy: 0.9014\n",
      "Epoch 16/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2758 - accuracy: 0.8959\n",
      "Epoch 17/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2522 - accuracy: 0.9062\n",
      "Epoch 18/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2557 - accuracy: 0.9045\n",
      "Epoch 19/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2494 - accuracy: 0.9064\n",
      "Epoch 20/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2365 - accuracy: 0.9112\n",
      "Epoch 21/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2412 - accuracy: 0.9103\n",
      "Epoch 22/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2364 - accuracy: 0.9103\n",
      "Epoch 23/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2438 - accuracy: 0.9091\n",
      "Epoch 24/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2434 - accuracy: 0.9071\n",
      "Epoch 25/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2302 - accuracy: 0.9139\n",
      "Epoch 26/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2225 - accuracy: 0.9158\n",
      "Epoch 27/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2424 - accuracy: 0.9091\n",
      "Epoch 28/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2292 - accuracy: 0.9134\n",
      "Epoch 29/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2201 - accuracy: 0.9183\n",
      "Epoch 30/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2048 - accuracy: 0.9228\n",
      "Epoch 31/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2265 - accuracy: 0.9152\n",
      "Epoch 32/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.2223 - accuracy: 0.9171\n",
      "Epoch 33/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2088 - accuracy: 0.9229\n",
      "Epoch 34/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2132 - accuracy: 0.9204\n",
      "Epoch 35/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2116 - accuracy: 0.9194\n",
      "Epoch 36/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1989 - accuracy: 0.9253\n",
      "Epoch 37/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2107 - accuracy: 0.9216\n",
      "Epoch 38/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2042 - accuracy: 0.9223\n",
      "Epoch 39/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2013 - accuracy: 0.9248\n",
      "Epoch 40/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2002 - accuracy: 0.9238\n",
      "Epoch 41/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2200 - accuracy: 0.9181\n",
      "Epoch 42/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1938 - accuracy: 0.9252\n",
      "Epoch 43/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1966 - accuracy: 0.9255\n",
      "Epoch 44/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.1830 - accuracy: 0.9305\n",
      "Epoch 45/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1855 - accuracy: 0.9299\n",
      "Epoch 46/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1973 - accuracy: 0.9264\n",
      "Epoch 47/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.1857 - accuracy: 0.9272\n",
      "Epoch 48/50\n",
      "8802/8802 [==============================] - 15s 2ms/step - loss: 0.2039 - accuracy: 0.9235\n",
      "Epoch 49/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.1995 - accuracy: 0.9259\n",
      "Epoch 50/50\n",
      "8802/8802 [==============================] - 16s 2ms/step - loss: 0.1925 - accuracy: 0.9271\n"
     ]
    }
   ],
   "source": [
    "train_model(model, 50, x, y, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1995,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('oracle.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2011,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_token(stack, buff, pos_map):\n",
    "    vectors = []\n",
    "    try:\n",
    "        stack_vect = v2w_model[stack['lemma']]\n",
    "    except:\n",
    "        stack_vect = nlp_uk('unk')[0].vector\n",
    "    try:\n",
    "        buff_vect = v2w_model[buff['lemma']]\n",
    "    except:\n",
    "        buff_vect = nlp_uk('unk')[0].vector\n",
    "    stack_pos = pos_map[stack['upostag']] or pos_map['UNK']\n",
    "    buff_pos = pos_map[buff['upostag']] or pos_map['UNK']\n",
    "    stack_vect_pos = np.append(stack_vect, [stack_pos])\n",
    "    buff_vect_pos = np.append(buff_vect, [buff_pos])\n",
    "    return np.concatenate((stack_vect_pos, buff_vect_pos))\n",
    "\n",
    "\n",
    "def get_predicted_action(predicted):\n",
    "    print('^^^', predicted)\n",
    "    pred = predicted\n",
    "    mx = np.amax(pred)\n",
    "    result = np.where(pred == mx)\n",
    "    action = result[2][0]\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_deps_for_tree(tree, oracle, pos_map, timesteps):\n",
    "    stack, buffer, relations = [ROOT], tree[:], []\n",
    "    all_vectors = []\n",
    "\n",
    "    while buffer or stack:\n",
    "        if stack and not buffer:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            vects = vectorize_token(stack[-1], buffer[0], pos_map)\n",
    "            all_vectors.append(vects)\n",
    "            \n",
    "            '''\n",
    "            Якщо чесно, я витратила 100500 часу, але так і не розібралась, як воно має працювати :(\n",
    "            Особливо не зрозуміло, як працювати з таймстепами. Модель натренувати якось вдалось\n",
    "            (як мінімум воно не звалилось, хех), але використати predict вже не знаю, як,\n",
    "            бо не сходяться шейпи. Власне в результаті мені вертаються вектори замість лейблів\n",
    "            Але в мене вже закінчились час, сили, натхнення та сенс продовжувати воювати з цією бідою,\n",
    "            бо, здається, я з самого початку щось робила кардинально невірно...\n",
    "            '''\n",
    "            rep = np.repeat(vects[np.newaxis,:], timesteps)\n",
    "            vectors = rep.reshape(1, timesteps, 602)\n",
    "   \n",
    "            predicted = oracle.predict(vectors)\n",
    "            action = get_predicted_action(predicted)\n",
    "            \n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(buffer.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                rel = (stack[-1]['id'], buffer[0]['id'])\n",
    "                relations.append(rel)\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                rel = (buffer[0]['id'], stack[-1]['id'])\n",
    "                relations.append(rel)\n",
    "                stack.append(buffer.pop(0))\n",
    "\n",
    "    return all_vectors, relations\n",
    "\n",
    "\n",
    "def get_data_for_fnn(trees, oracle, pos_map, timesteps):\n",
    "    vectors, labels = [], []\n",
    "    for tree in trees:\n",
    "        t_vectors, t_labels = [], []\n",
    "        valid_tree = [t for t in tree if type(t['id']) == int]\n",
    "        t_vectors, t_deps = get_deps_for_tree(valid_tree, oracle, pos_map, timesteps)\n",
    "\n",
    "        vectors.append(t_vectors)\n",
    "        labels.append(t_deps)\n",
    "\n",
    "    return np.dstack(vectors), np.dstack(labels)\n",
    "\n",
    "\n",
    "def get_fnn_model(X):\n",
    "    model = Sequential()\n",
    "#     model.add(Dense(768, input_dim=(X.shape[1]), init=\"uniform\",\n",
    "#         activation=\"relu\"))\n",
    "    model.add(Dense(768, init=\"uniform\", activation=\"relu\"))\n",
    "    model.add(Dense(384, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    model.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^ [[[1.4313338e-02 2.2781935e-02 8.7641668e-01 8.6488016e-02]\n",
      "  [9.9857092e-02 8.4256709e-02 7.9049641e-01 2.5389804e-02]\n",
      "  [0.0000000e+00 1.5030543e-19 1.0000000e+00 3.5927656e-24]]]\n",
      "^^^ [[[3.7121399e-09 3.4096264e-11 7.9400919e-10 1.0000000e+00]\n",
      "  [1.1668019e-37 2.1712596e-21 2.1618922e-24 1.0000000e+00]\n",
      "  [1.1923295e-24 4.8614279e-22 7.1999466e-01 2.8000534e-01]]]\n",
      "^^^ [[[1.4313338e-02 2.2781935e-02 8.7641668e-01 8.6488016e-02]\n",
      "  [3.0464837e-06 6.5153345e-02 9.3434370e-01 4.9992185e-04]\n",
      "  [5.6024213e-10 7.4883234e-03 9.9251163e-01 5.5858216e-09]]]\n",
      "^^^ [[[6.9262641e-03 4.6219703e-04 5.7167590e-02 9.3544400e-01]\n",
      "  [9.3567633e-07 4.9102320e-05 4.6021715e-02 9.5392817e-01]\n",
      "  [1.7581284e-17 1.5059911e-21 1.2847116e-07 9.9999988e-01]]]\n",
      "^^^ [[[1.4313338e-02 2.2781935e-02 8.7641668e-01 8.6488016e-02]\n",
      "  [2.6165735e-06 5.9607465e-02 9.3987942e-01 5.1041640e-04]\n",
      "  [1.2052887e-11 1.9474865e-07 3.5815322e-01 6.4184660e-01]]]\n",
      "^^^ [[[1.0846695e-02 1.3200438e-03 1.1631918e-01 8.7151408e-01]\n",
      "  [8.7918011e-07 2.4081392e-06 9.9996829e-01 2.8415665e-05]\n",
      "  [2.9519014e-14 2.7319519e-15 6.2421325e-11 1.0000000e+00]]]\n",
      "^^^ [[[1.4313338e-02 2.2781935e-02 8.7641668e-01 8.6488016e-02]\n",
      "  [6.8703974e-07 3.1855658e-02 9.6738571e-01 7.5787579e-04]\n",
      "  [4.7904050e-09 4.2351303e-08 7.9918709e-06 9.9999201e-01]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2012-5a6664318edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_for_fnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2011-bad60511b0c6>\u001b[0m in \u001b[0;36mget_data_for_fnn\u001b[0;34m(trees, oracle, pos_map, timesteps)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mt_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mvalid_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mt_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_deps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_deps_for_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2011-bad60511b0c6>\u001b[0m in \u001b[0;36mget_deps_for_tree\u001b[0;34m(tree, oracle, pos_map, timesteps)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mvects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mall_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "knn_x = get_data_for_fnn(train_trees, model, pos_map, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Курсовий проект - працюю..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
