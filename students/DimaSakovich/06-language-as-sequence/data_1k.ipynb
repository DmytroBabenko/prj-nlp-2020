{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"06-language-as-sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as md:\n",
    "        content = md.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Мова як послідовність\n",
       "\n",
       "## Run-on Sentences\n",
       "\n",
       "### 1. Домен\n",
       "\n",
       "Цього тижня ви працюватимете над задачею виправлення помилок.\n",
       "\n",
       "Run-on речення - це речення, склеєне з двох чи більше речень без належної пунктуації. Таку помилку часто допускають механічно, коли швидко друкують текст, проте така помилка виникає і від незнання мови. Особливо часто ця помилка зустрічається в інтернет-спілкуванні.\n",
       "\n",
       "Наприклад:\n",
       "```\n",
       "Thanks for talking to me let's meet again tomorrow Bye.\n",
       "```\n",
       "\n",
       "У цьому реченні насправді три склеєні речення. Правильний варіант:\n",
       "```\n",
       "Thanks for talking to me. Let's meet again tomorrow. Bye.\n",
       "```\n",
       "\n",
       "Run-on речення важливо визначати не лише для виправлення помилок. Ця помилка впливає на якість визначення сутностей, машинного перекладу, об'єкта сентименту тощо.\n",
       "\n",
       "Більше інформації та прикладів можна знайти за посиланнями:\n",
       "- <http://www.bristol.ac.uk/arts/exercises/grammar/grammar_tutorial/page_37.htm>\n",
       "- <https://www.english-grammar-revolution.com/run-on-sentence.html>\n",
       "- <https://www.quickanddirtytips.com/education/grammar/what-are-run-on-sentences>\n",
       "\n",
       "### 2. Класифікатор\n",
       "\n",
       "Дані:\n",
       "- Згенеруйте тренувальні дані для моделі на основі відкритих корпусів. Тренувальними даними буде набір склеєних речень. Візьміть до уваги, що склеєних речень може бути кілька (зазвичай 2, але буває і 3-4), а перше слово наступного речення може писатися з великої чи малої літери.\n",
       "- Знайдіть у відкритому доступі чи зберіть самостійно базу енграмів на рівні слів чи частин мови. Завважте, що відкриті бази енграмів зазвичай містять статистику, зібрану на реченнях, а отже вони можуть не містити енграми на межі речень.\n",
       "\n",
       "Тестування:\n",
       "- Напишіть базове рішення та метрику для тестування якості.\n",
       "- Для тестування використайте корпус [run-on-test.json](run-on-test.json). Формат корпусу:\n",
       "```\n",
       "[\n",
       "  [\n",
       "    [\"Thanks\", false],\n",
       "    [\"for\", false],\n",
       "    [\"talking\", false],\n",
       "    [\"to\", false],\n",
       "    [\"me\", true],\n",
       "    [\"let\", false],\n",
       "    [\"'s\", false],\n",
       "    [\"meet\", false],\n",
       "    [\"again\", false],\n",
       "    [\"tomorrow\", true],\n",
       "    [\"Bye\", false],\n",
       "    [\".\", false]\n",
       "  ],\n",
       "...\n",
       "]\n",
       "```\n",
       "\n",
       "`true` позначає слово, після якого треба додати крапку. Тестовий корпус містить 200 токенізованих речень (~ 4700 токенів). 3% токенів мають клас `true`, а решта - `false`. Зверніть увагу, що корпус вже токенізований.\n",
       "\n",
       "Класифікатор:\n",
       "- Виділіть ознаки, які впливають на те, чи є слово на межі речень. Наприклад:\n",
       "  - правий/лівий контекст;\n",
       "  - написання слова;\n",
       "  - граматичні ознаки (чи може речення закінчитись на сполучник?);\n",
       "  - енграми (чи часто це слово і наступне йдуть поруч? чи ймовірні ці дві частини мови поруч?);\n",
       "  - глибина синтаксичного дерева чи найближчий спільний предок;\n",
       "  - ваші варіанти.\n",
       "- Побудуйте класифікатор на основі логістичної регресії чи умовних випадкових полів (CRF), який анотує послідовно слова у реченні на предмет закінчення речення.\n",
       "- Спробуйте покращити якість роботи класифікатора, змінюючи набір чи комбінацію ознак.\n",
       "- **Важливо:** під час покращення класифікатора перевіряйте його якість на своїх даних (train/test або кросвалідація).\n",
       "- Визначте фінальну якість класифікатора на тестовій вибірці.\n",
       "\n",
       "Запишіть ваші спостереження та результати в окремий файл.\n",
       "\n",
       "### Корисні посилання\n",
       "\n",
       "- [CRF tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)\n",
       "- [Google ngrams](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) (and [how to download](https://pypi.org/project/google-ngram-downloader/))\n",
       "- [Google syntactic ngrams](http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html)\n",
       "- [1 mln of 2/3/4/5-ngrams from COCA](https://www.ngrams.info/download_coca.asp)\n",
       "\n",
       "### Оцінювання\n",
       "\n",
       "100% за завдання.\n",
       "\n",
       "### Крайній термін\n",
       "\n",
       "18.04.2020\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(os.path.join(TASK_PATH, \"06-language-as-sequence.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki:\n",
    "https://dumps.wikimedia.org/simplewiki/latest/  \n",
    "Brown:\n",
    "https://www.kaggle.com/nltkdata/brown-corpus  \n",
    "Some corpus:\n",
    "https://www.kaggle.com/espn56/english-corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python WikiExtractor.py simplewiki-latest-pages-articles-multistream.xml -o wiki_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for folder in os.listdir('wiki_articles'):\n",
    "#     for fn in tqdm(os.listdir(f\"wiki_articles/{folder}\")):\n",
    "#         with open(f'wiki_articles/{folder}/{fn}') as file_:\n",
    "#             res = file_.readlines()\n",
    "#             res = \"\".join(res)\n",
    "#             res = BeautifulSoup(res, 'lxml')\n",
    "#             res = list(filter(lambda x: len(x.split()) > 10, res.get_text().split(\"\\n\")))\n",
    "#             lst.extend(res)\n",
    "\n",
    "# df = pd.DataFrame(lst, columns=['text'])\n",
    "# df.to_csv(\"simple_wiki.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428708, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki = pd.read_csv(\"simple_wiki.txt\")\n",
    "df_wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jean Bercher (known as Dauberval or D'Auberval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cri-Cri is a fictional talking cricket. The ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The character was created by Gabilondo Soler w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was made into a movie that was released on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baldwin I († 879), also known as \"Baldwin Iron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Jean Bercher (known as Dauberval or D'Auberval...\n",
       "1  Cri-Cri is a fictional talking cricket. The ch...\n",
       "2  The character was created by Gabilondo Soler w...\n",
       "3  It was made into a movie that was released on ...\n",
       "4  Baldwin I († 879), also known as \"Baldwin Iron..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TASK_PATH ,'run-on-test.json')) as file_:\n",
    "    test_js = json.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \" \".join([item[0] for item in test_js[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### number of sentence splits in one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    145\n",
       "0     50\n",
       "2      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([sum([int(item[1] == True) for item in sample]) for sample in test_js]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### class distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4542\n",
       "1     155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for sample in test_js:\n",
    "    lst.extend([int(item[1]) for item in sample])\n",
    "pd.Series(lst).value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### upper/lower letter after dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 80\n"
     ]
    }
   ],
   "source": [
    "up_count = 0\n",
    "low_count = 0\n",
    "\n",
    "for sample in test_js:\n",
    "    for index, item in enumerate(sample):\n",
    "        if item[1] == True:\n",
    "            if sample[index+1][0][0].isupper():\n",
    "                up_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "print(up_count, low_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(text, zipped=False):\n",
    "    doc = nlp(text)\n",
    "    sents = list(doc.sents)\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for index, sen in enumerate(sents):\n",
    "        tkns = [token.text for token in sen]\n",
    "        if index > 0 and np.random.rand() > 0.5:\n",
    "            tkns[0] = tkns[0].lower()\n",
    "        if index != len(sents)-1:\n",
    "            tkns = tkns[:-1]\n",
    "        tokens.extend(tkns)\n",
    "        lbls = [False for i in range(len(tkns)-1)] + [True]\n",
    "        labels.extend(lbls)\n",
    "    labels[-1] = False\n",
    "    if sum(labels) != len(sents) - 1:\n",
    "        raise ValueError(f\"there is a problem with sentence=*{text}*\")\n",
    "    if zipped:\n",
    "        return list(zip(tokens, labels))\n",
    "    else:\n",
    "        return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(tokens):\n",
    "    text = \" \".join(tokens).replace(\"-\", \"\")\n",
    "    text = re.sub(r\".*(\\\")\\w\", \"\", text)\n",
    "#     for item in [\"-\", \",\", \".\"]:\n",
    "#         text = text.replace(\" {item} \", \"{item}\")\n",
    "    for k, v in [(\"'m\", \"am\"), (\"'s\", \"is\"), (\"'re\", \"are\"), (\"'ve\", \"have\")]:\n",
    "        text = text.replace(k, v)\n",
    "#     print(text)\n",
    "\n",
    "    text = \"start_sent \" + text + \" end_sent\" #+ \" end_end_sent\"\n",
    "    doc = nlp(text)\n",
    "    doc_range = len(doc)\n",
    "    lst = []\n",
    "    for i in range(1, doc_range - 1):\n",
    "        prev_token = doc[i-1]\n",
    "        cur_token = doc[i]\n",
    "        next_token = doc[i+1]\n",
    "#         next_next_token = doc[i+2]\n",
    "        \n",
    "        features = {\n",
    "            \"prev_token_pos\": prev_token.pos_,\n",
    "            \"prev_token_lemma_\": prev_token.lemma_,\n",
    "            \"prev_token_ent_iob\": prev_token.ent_iob,\n",
    "            \"prev_token_is_alpha\": prev_token.is_alpha,\n",
    "            \"prev_token_is_digit\": prev_token.is_digit,\n",
    "            \"prev_token_is_lower\": prev_token.is_lower,\n",
    "            \"prev_token_is_upper\": prev_token.is_upper,\n",
    "            \"prev_token_is_title\": prev_token.is_title,\n",
    "            \"prev_token_is_punct\": prev_token.is_punct,\n",
    "            \"prev_token_dep_\": prev_token.is_punct,\n",
    "            \"prev_token_start_sen\": int(prev_token.text == 'start_sent'),\n",
    "            \n",
    "            \"cur_token_pos\": cur_token.pos_,\n",
    "            \"cur_token_lemma_\": cur_token.lemma_,\n",
    "            \"cur_token_ent_iob\": cur_token.ent_iob,\n",
    "            \"cur_token_is_alpha\": cur_token.is_alpha,\n",
    "            \"cur_token_is_digit\": cur_token.is_digit,\n",
    "            \"cur_token_is_lower\": cur_token.is_lower,\n",
    "            \"cur_token_is_upper\": cur_token.is_upper,\n",
    "            \"cur_token_is_title\": cur_token.is_title,\n",
    "            \"cur_token_is_punct\": cur_token.is_punct,\n",
    "            \"cur_token_dep_\": cur_token.is_punct,\n",
    "            \"cur_token_num\": i,\n",
    "            \n",
    "            \"next_token_pos\": next_token.pos_,\n",
    "            \"next_token_lemma_\": next_token.lemma_,\n",
    "            \"next_token_ent_iob\": next_token.ent_iob,\n",
    "            \"next_token_is_alpha\": next_token.is_alpha,\n",
    "            \"next_token_is_digit\": next_token.is_digit,\n",
    "            \"next_token_is_lower\": next_token.is_lower,\n",
    "            \"next_token_is_upper\": next_token.is_upper,\n",
    "            \"next_token_is_title\": next_token.is_title,\n",
    "            \"next_token_is_punct\": next_token.is_punct,\n",
    "            \"next_token_dep_\": next_token.is_punct,\n",
    "            \"next_token_end_sen\": int(next_token.text == 'end_sent'),\n",
    "            \n",
    "#             \"next_next_token_pos\": next_next_token.pos_,\n",
    "#             \"next_next_token_lemma_\": next_next_token.lemma_,\n",
    "#             \"next_next_token_ent_iob\": next_next_token.ent_iob,\n",
    "#             \"next_next_token_is_alpha\": next_next_token.is_alpha,\n",
    "#             \"next_next_token_is_digit\": next_next_token.is_digit,\n",
    "#             \"next_next_token_is_lower\": next_next_token.is_lower,\n",
    "#             \"next_next_token_is_upper\": next_next_token.is_upper,\n",
    "#             \"next_next_token_is_title\": next_next_token.is_title,\n",
    "#             \"next_next_token_is_punct\": next_next_token.is_punct,\n",
    "#             \"next_next_token_dep_\": next_next_token.is_punct,\n",
    "#             \"next_next_token_end_sen\": int(next_next_token.text == 'end_end_sent')\n",
    "        }\n",
    "        lst.append(features)\n",
    "    return lst\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### train data sentence count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for x in tqdm(df_wiki['text'].values):\n",
    "#     lst.append([sen for sen in nlp(x).sents])\n",
    "\n",
    "# df_wiki['sentences'] = lst\n",
    "# df_wiki['sen_num'] = df_wiki.sentences.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv('simple_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "df = df_wiki.loc[df_wiki.sen_num < 4].sample(1000)\n",
    "df['text'] = df['text'].map(lambda x: re.sub(r'\\s+', \" \", re.sub(r\"(\\(.+?\\))\", \" \", x)))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:24<00:00, 41.34it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "failed_sentences = []\n",
    "\n",
    "for text in tqdm(df.text.values):\n",
    "    try:\n",
    "        tokens, labels = prepare_train(text)\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        train_df = train_df.append(tmp_df)\n",
    "    except:\n",
    "        failed_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of failed sentences: 0.01 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of failed sentences: {len(failed_sentences)/ train_df.shape[0]*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 69.15it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "\n",
    "for sample in tqdm(test_js):\n",
    "    try:\n",
    "        tokens, labels = [item[0] for item in sample], [item[1] for item in sample]\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        test_df = test_df.append(tmp_df)\n",
    "    except Exception as e:\n",
    "        print(sample)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.concat([train_df.loc[train_df.target == False].sample(frac=0.5), \n",
    "#                       train_df.loc[train_df.target == True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.972181\n",
       "True     0.027819\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.967\n",
       "True     0.033\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur_token_pos</th>\n",
       "      <th>cur_token_lemma_</th>\n",
       "      <th>cur_token_ent_iob</th>\n",
       "      <th>cur_token_is_alpha</th>\n",
       "      <th>cur_token_is_digit</th>\n",
       "      <th>cur_token_is_lower</th>\n",
       "      <th>cur_token_is_upper</th>\n",
       "      <th>cur_token_is_title</th>\n",
       "      <th>cur_token_is_punct</th>\n",
       "      <th>cur_token_dep_</th>\n",
       "      <th>cur_token_num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>Suchitra</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>Sen</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUX</td>\n",
       "      <td>be</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DET</td>\n",
       "      <td>an</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>indian</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cur_token_pos cur_token_lemma_  cur_token_ent_iob  cur_token_is_alpha  \\\n",
       "0         PROPN         Suchitra                  1                True   \n",
       "1         PROPN              Sen                  1                True   \n",
       "2           AUX               be                  2                True   \n",
       "3           DET               an                  2                True   \n",
       "4           ADJ           indian                  3                True   \n",
       "\n",
       "   cur_token_is_digit  cur_token_is_lower  cur_token_is_upper  \\\n",
       "0               False               False               False   \n",
       "1               False               False               False   \n",
       "2               False                True               False   \n",
       "3               False                True               False   \n",
       "4               False               False               False   \n",
       "\n",
       "   cur_token_is_title  cur_token_is_punct  cur_token_dep_  cur_token_num  \\\n",
       "0                True               False           False              1   \n",
       "1                True               False           False              2   \n",
       "2               False               False           False              3   \n",
       "3               False               False           False              4   \n",
       "4                True               False           False              5   \n",
       "\n",
       "   target  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[item for item in train_df.columns if item.startswith('cur')]+['target']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('train_df.csv', index=False)\n",
    "# train_df = pd.concat([train_df.loc[train_df.target == False].sample(frac=0.1), \n",
    "#                       train_df.loc[train_df.target == True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(train_df.drop('target', 1), train_df['target'], \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=RANDOM_STATE,\n",
    "                                                  stratify=train_df['target'])\n",
    "X_test, y_test = test_df.drop('target', 1), test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27520 6881\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], X_dev.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train.to_dict('records'))\n",
    "X_dev_vec = vectorizer.transform(X_dev.to_dict('records'))\n",
    "X_test_vec = vectorizer.transform(X_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 1.0286312327128653, True: 35.92689295039164}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 / y_train.value_counts(normalize=True)).to_dict()\n",
    "# class_weights = {False: 1, True: 30}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solo lr/svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def train_eval(clf):\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    print(\"f1 macro:\", f1_macro(y_test, y_pred))\n",
    "#     print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "f1 macro: 0.7100101120719677\n",
      "1\n",
      "f1 macro: 0.788720719022568\n",
      "5\n",
      "f1 macro: 0.820832922540997\n",
      "10\n",
      "f1 macro: 0.8274808765017003\n",
      "100\n",
      "f1 macro: 0.839015280734039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "reg_interval = [0.1, 1, 5, 10, 100]\n",
    "\n",
    "for index, interval in enumerate(reg_interval):\n",
    "    print(reg_interval[index])\n",
    "#     train_eval(LinearSVC(C=interval, class_weight=class_weights, max_iter=2000))\n",
    "    train_eval(LogisticRegression(C=interval, class_weight=class_weights, max_iter=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LinearSVC(C=10, class_weight=class_weights, max_iter=2000)\n",
    "model = LogisticRegression(C=10, solver='liblinear', penalty='l1', class_weight=class_weights, max_iter=2000)\n",
    "\n",
    "model.fit(X_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      6690\n",
      "        True       0.68      0.65      0.67       191\n",
      "\n",
      "    accuracy                           0.98      6881\n",
      "   macro avg       0.83      0.82      0.83      6881\n",
      "weighted avg       0.98      0.98      0.98      6881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.99      4542\n",
      "        True       0.61      0.79      0.69       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.80      0.88      0.84      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=True\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +27.682\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=i\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +26.857\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=*\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +24.081\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=housecrown\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +23.291\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Cummings\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +23.165\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Pteranodon\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.47%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +22.937\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Jane\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +22.916\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=FDP\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +21.688\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=accord\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +21.684\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=euryale\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.804\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=Briey\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.756\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=schnitger\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.92%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.274\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=kitanoumi\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.232\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=but\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.087\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cur_token_lemma_=etc\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.06%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +20.015\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=boudica\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.511\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cur_token_lemma_=Vrak\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.116\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=muhlenberg\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.099\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=electoral\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.59%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.073\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=x\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +18.938\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Lies\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.67%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 555 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 342 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(model, vec=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline with svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  50 | elapsed:  5.1min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_union__pipe2__SVD__n_components': 500, 'LinearSVC__C': 20} 0.8409437145596508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "pipeline_svc = Pipeline([\n",
    "    (\"main_union\", FeatureUnion([\n",
    "        (\"pipe1\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "        ])),\n",
    "        (\"pipe2\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD())\n",
    "        ])),\n",
    "    ])),\n",
    "    ('LinearSVC', LinearSVC(class_weight=class_weights))\n",
    "])\n",
    "\n",
    "distributions = {\n",
    "    \"LinearSVC__C\": [5, 10, 20],\n",
    "    \"main_union__pipe2__SVD__n_components\": [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "svc_pipe = RandomizedSearchCV(pipeline_svc,\n",
    "                         distributions,\n",
    "                         random_state=RANDOM_STATE,\n",
    "                         scoring=make_scorer(f1_macro),\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=5,\n",
    "                         n_jobs=-1)\n",
    "search = svc_pipe.fit(X_train.to_dict('records'), y_train)\n",
    "print(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      6690\n",
      "        True       0.77      0.63      0.69       191\n",
      "\n",
      "    accuracy                           0.98      6881\n",
      "   macro avg       0.88      0.81      0.84      6881\n",
      "weighted avg       0.98      0.98      0.98      6881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_pipe.predict(X_dev.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      4542\n",
      "        True       0.71      0.72      0.71       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.85      0.85      0.85      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_pipe.predict(X_test.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline with lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  32 out of  45 | elapsed:  6.8min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  45 | elapsed:  8.1min remaining:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  8.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_union__pipe2__SVD__n_components': 300, 'LogReg__penalty': 'l1', 'LogReg__C': 5} 0.8431520632434317\n"
     ]
    }
   ],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"main_union\", FeatureUnion([\n",
    "        (\"pipe1\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "        ])),\n",
    "        (\"pipe2\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD())\n",
    "        ])),\n",
    "    ])),\n",
    "#     (\"LogReg\", LogisticRegression(max_iter=1000, class_weight=class_weights))\n",
    "    (\"LogReg\", LogisticRegression(max_iter=2000, solver='liblinear', class_weight=class_weights))\n",
    "])\n",
    "\n",
    "distributions = {\n",
    "    \"LogReg__C\": [5, 10, 20],\n",
    "    \"LogReg__penalty\": [\"l1\"],\n",
    "    \"main_union__pipe2__SVD__n_components\": [300, 400, 500]\n",
    "}\n",
    "\n",
    "lr_pipe = RandomizedSearchCV(pipeline_lr,\n",
    "                         distributions,\n",
    "                         random_state=RANDOM_STATE,\n",
    "                         scoring=make_scorer(f1_macro),\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=5,\n",
    "                         n_jobs=-1)\n",
    "search = lr_pipe.fit(X_train.to_dict('records'), y_train)\n",
    "print(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      6690\n",
      "        True       0.66      0.65      0.65       191\n",
      "\n",
      "    accuracy                           0.98      6881\n",
      "   macro avg       0.82      0.82      0.82      6881\n",
      "weighted avg       0.98      0.98      0.98      6881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_pipe.predict(X_dev.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.98      0.99      4542\n",
      "        True       0.61      0.78      0.69       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.80      0.88      0.84      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_pipe.predict(X_test.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ligthgbm solo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fscore(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    res = f1_score(y_true, y_pred, average='macro')\n",
    "    return 'macro_f1', res, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_rounds': 5000,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'lambda_l2': 0.7,\n",
    "    'feature_fraction': 1,\n",
    "    'metric': 'custom',\n",
    "    'imbalance': True,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "\n",
    "lgb_clf = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.795523\n",
      "[200]\tvalid_0's macro_f1: 0.862611\n",
      "[300]\tvalid_0's macro_f1: 0.8648\n",
      "[400]\tvalid_0's macro_f1: 0.870819\n",
      "[500]\tvalid_0's macro_f1: 0.871599\n",
      "[600]\tvalid_0's macro_f1: 0.876727\n",
      "[700]\tvalid_0's macro_f1: 0.876727\n",
      "Early stopping, best iteration is:\n",
      "[577]\tvalid_0's macro_f1: 0.876727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               early_stopping_rounds=200, feature_fraction=1, imbalance=True,\n",
       "               importance_type='split', lambda_l2=0.7, learning_rate=0.01,\n",
       "               max_depth=8, metric='custom', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=20, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, num_rounds=5000,\n",
       "               objective='binary', random_state=0, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, verbose=100)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.fit(\n",
    "    X=X_train_vec,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_dev_vec, y_dev)],\n",
    "    verbose=params['verbose'],\n",
    "    eval_metric=lgb_fscore,\n",
    "#     sample_weight=y_train.map(class_weights).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99      6690\n",
      "        True       0.92      0.64      0.76       191\n",
      "\n",
      "    accuracy                           0.99      6881\n",
      "   macro avg       0.96      0.82      0.88      6881\n",
      "weighted avg       0.99      0.99      0.99      6881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      4542\n",
      "        True       0.76      0.66      0.71       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.87      0.83      0.85      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ligthgbm out-of-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sample_weight = True\n",
    "N_FOLDS = 4\n",
    "num_threads = 12\n",
    "SVD_n_comp = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_rounds': 5000,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'lambda_l2': 0.7,\n",
    "    'feature_fraction': 1,\n",
    "    'metric': 'custom',\n",
    "    'imbalance': True,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "\n",
    "classifier = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = StratifiedKFold(n_splits=N_FOLDS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df\n",
    "\n",
    "sample_weight = train_df.target.map(class_weights).values\n",
    "\n",
    "test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = np.zeros(len(train), dtype=np.float32)\n",
    "pred_test = np.zeros((len(test), 2, N_FOLDS), dtype=np.float32)\n",
    "fold_metrics = np.zeros(N_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "\tTrain len: 25800\n",
      "\tVal len: 8601\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.721792\n",
      "[200]\tvalid_0's macro_f1: 0.750382\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's macro_f1: 0.773425\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.7734253576038566\n",
      "Fold: 2\n",
      "\tTrain len: 25801\n",
      "\tVal len: 8600\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.729363\n",
      "[200]\tvalid_0's macro_f1: 0.751599\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's macro_f1: 0.774069\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.7740690431312727\n",
      "Fold: 3\n",
      "\tTrain len: 25801\n",
      "\tVal len: 8600\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.699859\n",
      "[200]\tvalid_0's macro_f1: 0.732966\n",
      "[300]\tvalid_0's macro_f1: 0.749017\n",
      "[400]\tvalid_0's macro_f1: 0.772143\n",
      "[500]\tvalid_0's macro_f1: 0.785674\n",
      "[600]\tvalid_0's macro_f1: 0.800833\n",
      "[700]\tvalid_0's macro_f1: 0.807027\n",
      "[800]\tvalid_0's macro_f1: 0.819997\n",
      "[900]\tvalid_0's macro_f1: 0.825751\n",
      "[1000]\tvalid_0's macro_f1: 0.832531\n",
      "[1100]\tvalid_0's macro_f1: 0.835701\n",
      "[1200]\tvalid_0's macro_f1: 0.83728\n",
      "[1300]\tvalid_0's macro_f1: 0.835853\n",
      "[1400]\tvalid_0's macro_f1: 0.836651\n",
      "[1500]\tvalid_0's macro_f1: 0.839163\n",
      "[1600]\tvalid_0's macro_f1: 0.839262\n",
      "[1700]\tvalid_0's macro_f1: 0.840085\n",
      "[1800]\tvalid_0's macro_f1: 0.843414\n",
      "[1900]\tvalid_0's macro_f1: 0.842699\n",
      "[2000]\tvalid_0's macro_f1: 0.842699\n",
      "Early stopping, best iteration is:\n",
      "[1825]\tvalid_0's macro_f1: 0.844255\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.8442553343244527\n",
      "Fold: 4\n",
      "\tTrain len: 25801\n",
      "\tVal len: 8600\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.744861\n",
      "[200]\tvalid_0's macro_f1: 0.762676\n",
      "[300]\tvalid_0's macro_f1: 0.784158\n",
      "[400]\tvalid_0's macro_f1: 0.802673\n",
      "[500]\tvalid_0's macro_f1: 0.815514\n",
      "[600]\tvalid_0's macro_f1: 0.832356\n",
      "[700]\tvalid_0's macro_f1: 0.847585\n",
      "[800]\tvalid_0's macro_f1: 0.860362\n",
      "[900]\tvalid_0's macro_f1: 0.862366\n",
      "[1000]\tvalid_0's macro_f1: 0.866849\n",
      "[1100]\tvalid_0's macro_f1: 0.865453\n",
      "[1200]\tvalid_0's macro_f1: 0.868497\n",
      "[1300]\tvalid_0's macro_f1: 0.870792\n",
      "[1400]\tvalid_0's macro_f1: 0.871406\n",
      "[1500]\tvalid_0's macro_f1: 0.873165\n",
      "[1600]\tvalid_0's macro_f1: 0.873491\n",
      "[1700]\tvalid_0's macro_f1: 0.87382\n",
      "[1800]\tvalid_0's macro_f1: 0.874154\n",
      "[1900]\tvalid_0's macro_f1: 0.874154\n",
      "Early stopping, best iteration is:\n",
      "[1769]\tvalid_0's macro_f1: 0.875622\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.8756217363618821\n"
     ]
    }
   ],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "for i, (tr_ind, val_ind) in enumerate(strategy.split(X=np.ones(len(train)), y=train['target'])):\n",
    "    print(f'Fold: {i + 1}\\n\\tTrain len: {len(tr_ind)}\\n\\tVal len: {len(val_ind)}')\n",
    "    pipe = Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD(n_components=SVD_n_comp))\n",
    "        ])\n",
    "    pipe.fit(train.iloc[tr_ind].drop('target', 1).to_dict('records'))\n",
    "    \n",
    "    X = pipe.transform(train.iloc[tr_ind].drop('target', 1).copy().to_dict('records'))\n",
    "    y = train.iloc[tr_ind]['target'].copy()\n",
    "    X_val = pipe.transform(train.iloc[val_ind].drop('target', 1).copy().to_dict('records'))\n",
    "    y_val = train.iloc[val_ind]['target'].copy()\n",
    "    X_test_ = pipe.transform(test.drop('target', 1).to_dict('records'))\n",
    "    \n",
    "    # fit model\n",
    "    print('\\tFITTING MODEL...')\n",
    "    classifier.fit(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=params['early_stopping_rounds'],\n",
    "        verbose=params['verbose'],\n",
    "        eval_metric=lgb_fscore,\n",
    "        sample_weight=sample_weight[tr_ind] if use_sample_weight else None,\n",
    "    )\n",
    "    # predict OOF val\n",
    "    print('\\tPREDICT OOF...')\n",
    "    pred_oof[val_ind] = classifier.predict(X_val, num_threads=num_threads)\n",
    "    # predict test\n",
    "    print('\\tPREDICTING TEST...')\n",
    "    pred_test[..., i] = classifier.predict_proba(\n",
    "        X_test_, num_threads=num_threads)\n",
    "    fold_metrics[i] = f1_macro(y_val, pred_oof[val_ind])\n",
    "    print(f'\\tFold score: {fold_metrics[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score:  0.8129306317539045\n"
     ]
    }
   ],
   "source": [
    "print(f'Total score: ', f1_macro(train['target'], pred_oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      4542\n",
      "        True       0.69      0.68      0.69       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.84      0.84      0.84      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_raw = pred_test.mean(axis=-1)\n",
    "y_pred = y_pred_raw.argmax(axis=1).astype(np.int32)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36] *",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
