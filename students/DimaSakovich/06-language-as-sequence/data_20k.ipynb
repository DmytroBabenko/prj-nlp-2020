{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"06-language-as-sequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as md:\n",
    "        content = md.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Мова як послідовність\n",
       "\n",
       "## Run-on Sentences\n",
       "\n",
       "### 1. Домен\n",
       "\n",
       "Цього тижня ви працюватимете над задачею виправлення помилок.\n",
       "\n",
       "Run-on речення - це речення, склеєне з двох чи більше речень без належної пунктуації. Таку помилку часто допускають механічно, коли швидко друкують текст, проте така помилка виникає і від незнання мови. Особливо часто ця помилка зустрічається в інтернет-спілкуванні.\n",
       "\n",
       "Наприклад:\n",
       "```\n",
       "Thanks for talking to me let's meet again tomorrow Bye.\n",
       "```\n",
       "\n",
       "У цьому реченні насправді три склеєні речення. Правильний варіант:\n",
       "```\n",
       "Thanks for talking to me. Let's meet again tomorrow. Bye.\n",
       "```\n",
       "\n",
       "Run-on речення важливо визначати не лише для виправлення помилок. Ця помилка впливає на якість визначення сутностей, машинного перекладу, об'єкта сентименту тощо.\n",
       "\n",
       "Більше інформації та прикладів можна знайти за посиланнями:\n",
       "- <http://www.bristol.ac.uk/arts/exercises/grammar/grammar_tutorial/page_37.htm>\n",
       "- <https://www.english-grammar-revolution.com/run-on-sentence.html>\n",
       "- <https://www.quickanddirtytips.com/education/grammar/what-are-run-on-sentences>\n",
       "\n",
       "### 2. Класифікатор\n",
       "\n",
       "Дані:\n",
       "- Згенеруйте тренувальні дані для моделі на основі відкритих корпусів. Тренувальними даними буде набір склеєних речень. Візьміть до уваги, що склеєних речень може бути кілька (зазвичай 2, але буває і 3-4), а перше слово наступного речення може писатися з великої чи малої літери.\n",
       "- Знайдіть у відкритому доступі чи зберіть самостійно базу енграмів на рівні слів чи частин мови. Завважте, що відкриті бази енграмів зазвичай містять статистику, зібрану на реченнях, а отже вони можуть не містити енграми на межі речень.\n",
       "\n",
       "Тестування:\n",
       "- Напишіть базове рішення та метрику для тестування якості.\n",
       "- Для тестування використайте корпус [run-on-test.json](run-on-test.json). Формат корпусу:\n",
       "```\n",
       "[\n",
       "  [\n",
       "    [\"Thanks\", false],\n",
       "    [\"for\", false],\n",
       "    [\"talking\", false],\n",
       "    [\"to\", false],\n",
       "    [\"me\", true],\n",
       "    [\"let\", false],\n",
       "    [\"'s\", false],\n",
       "    [\"meet\", false],\n",
       "    [\"again\", false],\n",
       "    [\"tomorrow\", true],\n",
       "    [\"Bye\", false],\n",
       "    [\".\", false]\n",
       "  ],\n",
       "...\n",
       "]\n",
       "```\n",
       "\n",
       "`true` позначає слово, після якого треба додати крапку. Тестовий корпус містить 200 токенізованих речень (~ 4700 токенів). 3% токенів мають клас `true`, а решта - `false`. Зверніть увагу, що корпус вже токенізований.\n",
       "\n",
       "Класифікатор:\n",
       "- Виділіть ознаки, які впливають на те, чи є слово на межі речень. Наприклад:\n",
       "  - правий/лівий контекст;\n",
       "  - написання слова;\n",
       "  - граматичні ознаки (чи може речення закінчитись на сполучник?);\n",
       "  - енграми (чи часто це слово і наступне йдуть поруч? чи ймовірні ці дві частини мови поруч?);\n",
       "  - глибина синтаксичного дерева чи найближчий спільний предок;\n",
       "  - ваші варіанти.\n",
       "- Побудуйте класифікатор на основі логістичної регресії чи умовних випадкових полів (CRF), який анотує послідовно слова у реченні на предмет закінчення речення.\n",
       "- Спробуйте покращити якість роботи класифікатора, змінюючи набір чи комбінацію ознак.\n",
       "- **Важливо:** під час покращення класифікатора перевіряйте його якість на своїх даних (train/test або кросвалідація).\n",
       "- Визначте фінальну якість класифікатора на тестовій вибірці.\n",
       "\n",
       "Запишіть ваші спостереження та результати в окремий файл.\n",
       "\n",
       "### Корисні посилання\n",
       "\n",
       "- [CRF tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html)\n",
       "- [Google ngrams](http://storage.googleapis.com/books/ngrams/books/datasetsv2.html) (and [how to download](https://pypi.org/project/google-ngram-downloader/))\n",
       "- [Google syntactic ngrams](http://commondatastorage.googleapis.com/books/syntactic-ngrams/index.html)\n",
       "- [1 mln of 2/3/4/5-ngrams from COCA](https://www.ngrams.info/download_coca.asp)\n",
       "\n",
       "### Оцінювання\n",
       "\n",
       "100% за завдання.\n",
       "\n",
       "### Крайній термін\n",
       "\n",
       "18.04.2020\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(os.path.join(TASK_PATH, \"06-language-as-sequence.md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiki:\n",
    "https://dumps.wikimedia.org/simplewiki/latest/  \n",
    "Brown:\n",
    "https://www.kaggle.com/nltkdata/brown-corpus  \n",
    "Some corpus:\n",
    "https://www.kaggle.com/espn56/english-corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python WikiExtractor.py simplewiki-latest-pages-articles-multistream.xml -o wiki_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for folder in os.listdir('wiki_articles'):\n",
    "#     for fn in tqdm(os.listdir(f\"wiki_articles/{folder}\")):\n",
    "#         with open(f'wiki_articles/{folder}/{fn}') as file_:\n",
    "#             res = file_.readlines()\n",
    "#             res = \"\".join(res)\n",
    "#             res = BeautifulSoup(res, 'lxml')\n",
    "#             res = list(filter(lambda x: len(x.split()) > 10, res.get_text().split(\"\\n\")))\n",
    "#             lst.extend(res)\n",
    "\n",
    "# df = pd.DataFrame(lst, columns=['text'])\n",
    "# df.to_csv(\"simple_wiki.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428708, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki = pd.read_csv(\"simple_wiki.txt\")\n",
    "df_wiki.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jean Bercher (known as Dauberval or D'Auberval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cri-Cri is a fictional talking cricket. The ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The character was created by Gabilondo Soler w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was made into a movie that was released on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baldwin I († 879), also known as \"Baldwin Iron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Jean Bercher (known as Dauberval or D'Auberval...\n",
       "1  Cri-Cri is a fictional talking cricket. The ch...\n",
       "2  The character was created by Gabilondo Soler w...\n",
       "3  It was made into a movie that was released on ...\n",
       "4  Baldwin I († 879), also known as \"Baldwin Iron..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wiki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TASK_PATH ,'run-on-test.json')) as file_:\n",
    "    test_js = json.load(file_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \" \".join([item[0] for item in test_js[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### number of sentence splits in one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    145\n",
       "0     50\n",
       "2      5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([sum([int(item[1] == True) for item in sample]) for sample in test_js]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### class distrubution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4542\n",
       "1     155\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for sample in test_js:\n",
    "    lst.extend([int(item[1]) for item in sample])\n",
    "pd.Series(lst).value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### upper/lower letter after dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 80\n"
     ]
    }
   ],
   "source": [
    "up_count = 0\n",
    "low_count = 0\n",
    "\n",
    "for sample in test_js:\n",
    "    for index, item in enumerate(sample):\n",
    "        if item[1] == True:\n",
    "            if sample[index+1][0][0].isupper():\n",
    "                up_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "print(up_count, low_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train(text, zipped=False):\n",
    "    doc = nlp(text)\n",
    "    sents = list(doc.sents)\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    for index, sen in enumerate(sents):\n",
    "        tkns = [token.text for token in sen]\n",
    "        if index > 0 and np.random.rand() > 0.5:\n",
    "            tkns[0] = tkns[0].lower()\n",
    "        if index != len(sents)-1:\n",
    "            tkns = tkns[:-1]\n",
    "        tokens.extend(tkns)\n",
    "        lbls = [False for i in range(len(tkns)-1)] + [True]\n",
    "        labels.extend(lbls)\n",
    "    labels[-1] = False\n",
    "    if sum(labels) != len(sents) - 1:\n",
    "        raise ValueError(f\"there is a problem with sentence=*{text}*\")\n",
    "    if zipped:\n",
    "        return list(zip(tokens, labels))\n",
    "    else:\n",
    "        return tokens, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(tokens):\n",
    "    text = \" \".join(tokens).replace(\"-\", \"\")\n",
    "    text = re.sub(r\".*(\\\")\\w\", \"\", text)\n",
    "#     for item in [\"-\", \",\", \".\"]:\n",
    "#         text = text.replace(\" {item} \", \"{item}\")\n",
    "    for k, v in [(\"'m\", \"am\"), (\"'s\", \"is\"), (\"'re\", \"are\"), (\"'ve\", \"have\")]:\n",
    "        text = text.replace(k, v)\n",
    "#     print(text)\n",
    "\n",
    "    text = \"start_sent \" + text + \" end_sent\" #+ \" end_end_sent\"\n",
    "    doc = nlp(text)\n",
    "    doc_range = len(doc)\n",
    "    lst = []\n",
    "    for i in range(1, doc_range - 1):\n",
    "        prev_token = doc[i-1]\n",
    "        cur_token = doc[i]\n",
    "        next_token = doc[i+1]\n",
    "#         next_next_token = doc[i+2]\n",
    "        \n",
    "        features = {\n",
    "            \"prev_token_pos\": prev_token.pos_,\n",
    "            \"prev_token_lemma_\": prev_token.lemma_,\n",
    "            \"prev_token_ent_iob\": prev_token.ent_iob,\n",
    "            \"prev_token_is_alpha\": prev_token.is_alpha,\n",
    "            \"prev_token_is_digit\": prev_token.is_digit,\n",
    "            \"prev_token_is_lower\": prev_token.is_lower,\n",
    "            \"prev_token_is_upper\": prev_token.is_upper,\n",
    "            \"prev_token_is_title\": prev_token.is_title,\n",
    "            \"prev_token_is_punct\": prev_token.is_punct,\n",
    "            \"prev_token_dep_\": prev_token.is_punct,\n",
    "            \"prev_token_start_sen\": int(prev_token.text == 'start_sent'),\n",
    "            \"prev_token_num\": i-1,\n",
    "            \n",
    "            \"cur_token_pos\": cur_token.pos_,\n",
    "            \"cur_token_lemma_\": cur_token.lemma_,\n",
    "            \"cur_token_ent_iob\": cur_token.ent_iob,\n",
    "            \"cur_token_is_alpha\": cur_token.is_alpha,\n",
    "            \"cur_token_is_digit\": cur_token.is_digit,\n",
    "            \"cur_token_is_lower\": cur_token.is_lower,\n",
    "            \"cur_token_is_upper\": cur_token.is_upper,\n",
    "            \"cur_token_is_title\": cur_token.is_title,\n",
    "            \"cur_token_is_punct\": cur_token.is_punct,\n",
    "            \"cur_token_dep_\": cur_token.is_punct,\n",
    "            \"cur_token_num\": i,\n",
    "            \n",
    "            \"next_token_pos\": next_token.pos_,\n",
    "            \"next_token_lemma_\": next_token.lemma_,\n",
    "            \"next_token_ent_iob\": next_token.ent_iob,\n",
    "            \"next_token_is_alpha\": next_token.is_alpha,\n",
    "            \"next_token_is_digit\": next_token.is_digit,\n",
    "            \"next_token_is_lower\": next_token.is_lower,\n",
    "            \"next_token_is_upper\": next_token.is_upper,\n",
    "            \"next_token_is_title\": next_token.is_title,\n",
    "            \"next_token_is_punct\": next_token.is_punct,\n",
    "            \"next_token_dep_\": next_token.is_punct,\n",
    "            \"next_token_end_sen\": int(next_token.text == 'end_sent'),\n",
    "            \"next_token_num\": i+1,\n",
    "            \n",
    "#             \"next_next_token_pos\": next_next_token.pos_,\n",
    "#             \"next_next_token_lemma_\": next_next_token.lemma_,\n",
    "#             \"next_next_token_ent_iob\": next_next_token.ent_iob,\n",
    "#             \"next_next_token_is_alpha\": next_next_token.is_alpha,\n",
    "#             \"next_next_token_is_digit\": next_next_token.is_digit,\n",
    "#             \"next_next_token_is_lower\": next_next_token.is_lower,\n",
    "#             \"next_next_token_is_upper\": next_next_token.is_upper,\n",
    "#             \"next_next_token_is_title\": next_next_token.is_title,\n",
    "#             \"next_next_token_is_punct\": next_next_token.is_punct,\n",
    "#             \"next_next_token_dep_\": next_next_token.is_punct,\n",
    "#             \"next_next_token_end_sen\": int(next_next_token.text == 'end_end_sent')\n",
    "        }\n",
    "        lst.append(features)\n",
    "    return lst\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### train data sentence count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = []\n",
    "\n",
    "# for x in tqdm(df_wiki['text'].values):\n",
    "#     lst.append([sen for sen in nlp(x).sents])\n",
    "\n",
    "# df_wiki['sentences'] = lst\n",
    "# df_wiki['sen_num'] = df_wiki.sentences.map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wiki = pd.read_csv('simple_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "df = df_wiki.loc[df_wiki.sen_num < 4].sample(20000)\n",
    "df['text'] = df['text'].map(lambda x: re.sub(r'\\s+', \" \", re.sub(r\"(\\(.+?\\))\", \" \", x)))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [37:06<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame()\n",
    "failed_sentences = []\n",
    "\n",
    "for text in tqdm(df.text.values):\n",
    "    try:\n",
    "        tokens, labels = prepare_train(text)\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        train_df = train_df.append(tmp_df)\n",
    "    except:\n",
    "        failed_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of failed sentences: 0.01 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percentage of failed sentences: {len(failed_sentences)/ train_df.shape[0]*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:02<00:00, 80.89it/s]\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "\n",
    "for sample in tqdm(test_js):\n",
    "    try:\n",
    "        tokens, labels = [item[0] for item in sample], [item[1] for item in sample]\n",
    "        tmp_df = pd.DataFrame(make_features(tokens))\n",
    "        tmp_df['target'] = labels\n",
    "        test_df = test_df.append(tmp_df)\n",
    "    except Exception as e:\n",
    "        print(sample)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.971872\n",
       "True     0.028128\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.967\n",
       "True     0.033\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cur_token_pos</th>\n",
       "      <th>cur_token_lemma_</th>\n",
       "      <th>cur_token_ent_iob</th>\n",
       "      <th>cur_token_is_alpha</th>\n",
       "      <th>cur_token_is_digit</th>\n",
       "      <th>cur_token_is_lower</th>\n",
       "      <th>cur_token_is_upper</th>\n",
       "      <th>cur_token_is_title</th>\n",
       "      <th>cur_token_is_punct</th>\n",
       "      <th>cur_token_dep_</th>\n",
       "      <th>cur_token_num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>french</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>troop</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VERB</td>\n",
       "      <td>land</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>on</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROPN</td>\n",
       "      <td>Elba</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cur_token_pos cur_token_lemma_  cur_token_ent_iob  cur_token_is_alpha  \\\n",
       "0           ADJ           french                  3                True   \n",
       "1          NOUN            troop                  2                True   \n",
       "2          VERB             land                  2                True   \n",
       "3           ADP               on                  2                True   \n",
       "4         PROPN             Elba                  3                True   \n",
       "\n",
       "   cur_token_is_digit  cur_token_is_lower  cur_token_is_upper  \\\n",
       "0               False               False               False   \n",
       "1               False                True               False   \n",
       "2               False                True               False   \n",
       "3               False                True               False   \n",
       "4               False               False               False   \n",
       "\n",
       "   cur_token_is_title  cur_token_is_punct  cur_token_dep_  cur_token_num  \\\n",
       "0                True               False           False              1   \n",
       "1               False               False           False              2   \n",
       "2               False               False           False              3   \n",
       "3               False               False           False              4   \n",
       "4                True               False           False              5   \n",
       "\n",
       "   target  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[item for item in train_df.columns if item.startswith('cur')]+['target']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV, KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('train_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(train_df.drop('target', 1), train_df['target'], \n",
    "                                                  test_size=0.2, \n",
    "                                                  random_state=RANDOM_STATE,\n",
    "                                                  stratify=train_df['target'])\n",
    "X_test, y_test = test_df.drop('target', 1), test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542605 135652\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0], X_dev.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train.to_dict('records'))\n",
    "X_dev_vec = vectorizer.transform(X_dev.to_dict('records'))\n",
    "X_test_vec = vectorizer.transform(X_test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 1.0289413152350557, True: 35.552679858472025}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = (1 / y_train.value_counts(normalize=True)).to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### solo lr/svc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_macro(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def train_eval(clf):\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    print(\"f1 macro:\", f1_macro(y_test, y_pred))\n",
    "#     print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.7403618599476937\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.7486201933888015\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 macro: 0.7551480120196254\n",
      "25\n",
      "f1 macro: 0.7566385138706597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "reg_interval = [1, 5, 10, 25]\n",
    "\n",
    "for index, interval in enumerate(reg_interval):\n",
    "    print(reg_interval[index])\n",
    "#     train_eval(LinearSVC(C=interval, class_weight=class_weights, max_iter=2000))\n",
    "    train_eval(LogisticRegression(C=interval, class_weight=class_weights, max_iter=2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# model = LinearSVC(C=10, class_weight=class_weights, max_iter=2000)\n",
    "# model = LogisticRegression(C=10, solver='liblinear', penalty='l1', class_weight=class_weights, max_iter=2000)\n",
    "model = LogisticRegression(C=10, class_weight=class_weights, max_iter=2000)\n",
    "\n",
    "\n",
    "model.fit(X_train_vec, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.97      0.98    131836\n",
      "        True       0.44      0.79      0.57      3816\n",
      "\n",
      "    accuracy                           0.97    135652\n",
      "   macro avg       0.72      0.88      0.77    135652\n",
      "weighted avg       0.98      0.97      0.97    135652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.97      4542\n",
      "        True       0.39      0.85      0.54       155\n",
      "\n",
      "    accuracy                           0.95      4697\n",
      "   macro avg       0.69      0.90      0.76      4697\n",
      "weighted avg       0.97      0.95      0.96      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=True\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +19.233\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=GCIE\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +16.891\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=François\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +16.706\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=trouble\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.90%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +16.550\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Silas\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.48%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +15.746\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=bomis\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +14.947\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=kingman\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +14.625\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=hoc\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +14.125\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=sequel\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.01%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +13.706\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Len\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +13.532\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Stendal\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +13.368\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=yhe\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +13.185\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=antilles\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.60%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +12.941\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=Petty\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.67%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +12.852\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        prev_token_lemma_=academy\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.67%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 9110 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.49%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 117533 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -13.090\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cur_token_lemma_=where\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -14.684\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cur_token_lemma_=;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -16.454\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cur_token_lemma_=when\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -20.078\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_end_sen\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -20.078\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=end_sent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -20.694\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        next_token_lemma_=.\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import eli5\n",
    "\n",
    "eli5.show_weights(model, vec=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline with svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    }
   ],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "pipeline_svc = Pipeline([\n",
    "    (\"main_union\", FeatureUnion([\n",
    "        (\"pipe1\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "        ])),\n",
    "        (\"pipe2\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD())\n",
    "        ])),\n",
    "    ])),\n",
    "    ('LinearSVC', LinearSVC(class_weight=class_weights))\n",
    "])\n",
    "\n",
    "distributions = {\n",
    "    \"LinearSVC__C\": [1, 5, 10, 20],\n",
    "    \"main_union__pipe2__SVD__n_components\": [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "svc_pipe = RandomizedSearchCV(pipeline_svc,\n",
    "                         distributions,\n",
    "                         random_state=RANDOM_STATE,\n",
    "                         scoring=make_scorer(f1_macro),\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=5,\n",
    "                         n_jobs=-1)\n",
    "search = svc_pipe.fit(X_train.to_dict('records'), y_train)\n",
    "print(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_pipe.predict(X_dev.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc_pipe.predict(X_test.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pipeline with lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"main_union\", FeatureUnion([\n",
    "        (\"pipe1\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "        ])),\n",
    "        (\"pipe2\", Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD())\n",
    "        ])),\n",
    "    ])),\n",
    "#     (\"LogReg\", LogisticRegression(max_iter=1000, class_weight=class_weights))\n",
    "    (\"LogReg\", LogisticRegression(max_iter=2000, solver='liblinear', class_weight=class_weights))\n",
    "])\n",
    "\n",
    "distributions = {\n",
    "    \"LogReg__C\": [1, 5, 10, 20],\n",
    "    \"LogReg__penalty\": [\"l1\"],\n",
    "    \"main_union__pipe2__SVD__n_components\": [200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "lr_pipe = RandomizedSearchCV(pipeline_lr,\n",
    "                         distributions,\n",
    "                         random_state=RANDOM_STATE,\n",
    "                         scoring=make_scorer(f1_macro),\n",
    "                         n_iter=10,\n",
    "                         cv=5,\n",
    "                         verbose=5,\n",
    "                         n_jobs=-1)\n",
    "search = lr_pipe.fit(X_train.to_dict('records'), y_train)\n",
    "print(search.best_params_, search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_pipe.predict(X_dev.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_pipe.predict(X_test.to_dict('records'))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ligthgbm solo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_fscore(y_true, y_pred):\n",
    "    y_pred = np.round(y_pred)\n",
    "    res = f1_score(y_true, y_pred, average='macro')\n",
    "    return 'macro_f1', res, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_rounds': 5000,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'lambda_l2': 0.9,\n",
    "    'feature_fraction': 0.5,\n",
    "    'metric': 'custom',\n",
    "    'imbalance': True,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "\n",
    "lgb_clf = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.763776\n",
      "[200]\tvalid_0's macro_f1: 0.857911\n",
      "[300]\tvalid_0's macro_f1: 0.879627\n",
      "[400]\tvalid_0's macro_f1: 0.884272\n",
      "[500]\tvalid_0's macro_f1: 0.88722\n",
      "[600]\tvalid_0's macro_f1: 0.889048\n",
      "[700]\tvalid_0's macro_f1: 0.890434\n",
      "[800]\tvalid_0's macro_f1: 0.892111\n",
      "[900]\tvalid_0's macro_f1: 0.892357\n",
      "[1000]\tvalid_0's macro_f1: 0.894231\n",
      "[1100]\tvalid_0's macro_f1: 0.894774\n",
      "[1200]\tvalid_0's macro_f1: 0.895287\n",
      "[1300]\tvalid_0's macro_f1: 0.895437\n",
      "[1400]\tvalid_0's macro_f1: 0.895557\n",
      "[1500]\tvalid_0's macro_f1: 0.896606\n",
      "[1600]\tvalid_0's macro_f1: 0.897205\n",
      "[1700]\tvalid_0's macro_f1: 0.897503\n",
      "[1800]\tvalid_0's macro_f1: 0.897772\n",
      "[1900]\tvalid_0's macro_f1: 0.898159\n",
      "[2000]\tvalid_0's macro_f1: 0.898547\n",
      "[2100]\tvalid_0's macro_f1: 0.898637\n",
      "[2200]\tvalid_0's macro_f1: 0.898844\n",
      "[2300]\tvalid_0's macro_f1: 0.898904\n",
      "[2400]\tvalid_0's macro_f1: 0.899111\n",
      "[2500]\tvalid_0's macro_f1: 0.89935\n",
      "[2600]\tvalid_0's macro_f1: 0.899678\n",
      "[2700]\tvalid_0's macro_f1: 0.899767\n",
      "[2800]\tvalid_0's macro_f1: 0.899948\n",
      "[2900]\tvalid_0's macro_f1: 0.900187\n",
      "[3000]\tvalid_0's macro_f1: 0.900191\n",
      "[3100]\tvalid_0's macro_f1: 0.900158\n",
      "Early stopping, best iteration is:\n",
      "[2957]\tvalid_0's macro_f1: 0.900308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               early_stopping_rounds=200, feature_fraction=0.5, imbalance=True,\n",
       "               importance_type='split', lambda_l2=0.9, learning_rate=0.01,\n",
       "               max_depth=-1, metric='custom', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_data_in_leaf=30, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, num_rounds=5000,\n",
       "               objective='binary', random_state=0, reg_alpha=0.0,\n",
       "               reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0, verbose=100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_clf.fit(\n",
    "    X=X_train_vec,\n",
    "    y=y_train,\n",
    "    eval_set=[(X_dev_vec, y_dev)],\n",
    "    verbose=params['verbose'],\n",
    "    eval_metric=lgb_fscore,\n",
    "#     sample_weight=y_train.map(class_weights).values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99    131836\n",
      "        True       0.91      0.72      0.81      3816\n",
      "\n",
      "    accuracy                           0.99    135652\n",
      "   macro avg       0.95      0.86      0.90    135652\n",
      "weighted avg       0.99      0.99      0.99    135652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_dev_vec)\n",
    "\n",
    "print(classification_report(y_dev, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.99      0.99      4542\n",
      "        True       0.81      0.69      0.75       155\n",
      "\n",
      "    accuracy                           0.98      4697\n",
      "   macro avg       0.90      0.84      0.87      4697\n",
      "weighted avg       0.98      0.98      0.98      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgb_clf.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ligthgbm out-of-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sample_weight = True\n",
    "N_FOLDS = 4\n",
    "num_threads = 12\n",
    "SVD_n_comp = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'num_rounds': 5000,\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': 100,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'min_data_in_leaf': 30,\n",
    "    'lambda_l2': 0.9,\n",
    "    'feature_fraction': 0.5,\n",
    "    'metric': 'custom',\n",
    "    'imbalance': True,\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "\n",
    "classifier = LGBMClassifier(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = StratifiedKFold(n_splits=N_FOLDS, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df\n",
    "\n",
    "sample_weight = train_df.target.map(class_weights).values\n",
    "\n",
    "test = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_oof = np.zeros(len(train), dtype=np.float32)\n",
    "pred_test = np.zeros((len(test), 2, N_FOLDS), dtype=np.float32)\n",
    "fold_metrics = np.zeros(N_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "\tTrain len: 508692\n",
      "\tVal len: 169565\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.728239\n",
      "[200]\tvalid_0's macro_f1: 0.726031\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's macro_f1: 0.728298\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.7282982717086455\n",
      "Fold: 2\n",
      "\tTrain len: 508693\n",
      "\tVal len: 169564\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.723507\n",
      "[200]\tvalid_0's macro_f1: 0.725145\n",
      "[300]\tvalid_0's macro_f1: 0.72675\n",
      "[400]\tvalid_0's macro_f1: 0.731281\n",
      "[500]\tvalid_0's macro_f1: 0.733882\n",
      "[600]\tvalid_0's macro_f1: 0.73667\n",
      "[700]\tvalid_0's macro_f1: 0.739541\n",
      "[800]\tvalid_0's macro_f1: 0.742379\n",
      "[900]\tvalid_0's macro_f1: 0.744117\n",
      "[1000]\tvalid_0's macro_f1: 0.746279\n",
      "[1100]\tvalid_0's macro_f1: 0.748865\n",
      "[1200]\tvalid_0's macro_f1: 0.751438\n",
      "[1300]\tvalid_0's macro_f1: 0.754446\n",
      "[1400]\tvalid_0's macro_f1: 0.756635\n",
      "[1500]\tvalid_0's macro_f1: 0.759155\n",
      "[1600]\tvalid_0's macro_f1: 0.761133\n",
      "[1700]\tvalid_0's macro_f1: 0.762852\n",
      "[1800]\tvalid_0's macro_f1: 0.764939\n",
      "[1900]\tvalid_0's macro_f1: 0.767273\n",
      "[2000]\tvalid_0's macro_f1: 0.769663\n",
      "[2100]\tvalid_0's macro_f1: 0.772109\n",
      "[2200]\tvalid_0's macro_f1: 0.774647\n",
      "[2300]\tvalid_0's macro_f1: 0.777027\n",
      "[2400]\tvalid_0's macro_f1: 0.778573\n",
      "[2500]\tvalid_0's macro_f1: 0.780926\n",
      "[2600]\tvalid_0's macro_f1: 0.783346\n",
      "[2700]\tvalid_0's macro_f1: 0.785576\n",
      "[2800]\tvalid_0's macro_f1: 0.787505\n",
      "[2900]\tvalid_0's macro_f1: 0.790366\n",
      "[3000]\tvalid_0's macro_f1: 0.791803\n",
      "[3100]\tvalid_0's macro_f1: 0.79404\n",
      "[3200]\tvalid_0's macro_f1: 0.795972\n",
      "[3300]\tvalid_0's macro_f1: 0.79808\n",
      "[3400]\tvalid_0's macro_f1: 0.799511\n",
      "[3500]\tvalid_0's macro_f1: 0.802047\n",
      "[3600]\tvalid_0's macro_f1: 0.803927\n",
      "[3700]\tvalid_0's macro_f1: 0.805388\n",
      "[3800]\tvalid_0's macro_f1: 0.807308\n",
      "[3900]\tvalid_0's macro_f1: 0.808942\n",
      "[4000]\tvalid_0's macro_f1: 0.810468\n",
      "[4100]\tvalid_0's macro_f1: 0.811696\n",
      "[4200]\tvalid_0's macro_f1: 0.81357\n",
      "[4300]\tvalid_0's macro_f1: 0.814663\n",
      "[4400]\tvalid_0's macro_f1: 0.816629\n",
      "[4500]\tvalid_0's macro_f1: 0.81805\n",
      "[4600]\tvalid_0's macro_f1: 0.819841\n",
      "[4700]\tvalid_0's macro_f1: 0.821624\n",
      "[4800]\tvalid_0's macro_f1: 0.82307\n",
      "[4900]\tvalid_0's macro_f1: 0.824445\n",
      "[5000]\tvalid_0's macro_f1: 0.825721\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4988]\tvalid_0's macro_f1: 0.825802\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.825801659239044\n",
      "Fold: 3\n",
      "\tTrain len: 508693\n",
      "\tVal len: 169564\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.728072\n",
      "[200]\tvalid_0's macro_f1: 0.72799\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's macro_f1: 0.733978\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.7339781986136253\n",
      "Fold: 4\n",
      "\tTrain len: 508693\n",
      "\tVal len: 169564\n",
      "\tFITTING MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/lightgbm/engine.py:153: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\tvalid_0's macro_f1: 0.722005\n",
      "[200]\tvalid_0's macro_f1: 0.724913\n",
      "[300]\tvalid_0's macro_f1: 0.724944\n",
      "[400]\tvalid_0's macro_f1: 0.724871\n",
      "[500]\tvalid_0's macro_f1: 0.727131\n",
      "[600]\tvalid_0's macro_f1: 0.731255\n",
      "[700]\tvalid_0's macro_f1: 0.733473\n",
      "[800]\tvalid_0's macro_f1: 0.736143\n",
      "[900]\tvalid_0's macro_f1: 0.739605\n",
      "[1000]\tvalid_0's macro_f1: 0.742444\n",
      "[1100]\tvalid_0's macro_f1: 0.744458\n",
      "[1200]\tvalid_0's macro_f1: 0.746942\n",
      "[1300]\tvalid_0's macro_f1: 0.749609\n",
      "[1400]\tvalid_0's macro_f1: 0.752439\n",
      "[1500]\tvalid_0's macro_f1: 0.754606\n",
      "[1600]\tvalid_0's macro_f1: 0.756617\n",
      "[1700]\tvalid_0's macro_f1: 0.758341\n",
      "[1800]\tvalid_0's macro_f1: 0.760655\n",
      "[1900]\tvalid_0's macro_f1: 0.763066\n",
      "[2000]\tvalid_0's macro_f1: 0.765127\n",
      "[2100]\tvalid_0's macro_f1: 0.767326\n",
      "[2200]\tvalid_0's macro_f1: 0.7702\n",
      "[2300]\tvalid_0's macro_f1: 0.772894\n",
      "[2400]\tvalid_0's macro_f1: 0.774957\n",
      "[2500]\tvalid_0's macro_f1: 0.777247\n",
      "[2600]\tvalid_0's macro_f1: 0.779463\n",
      "[2700]\tvalid_0's macro_f1: 0.781898\n",
      "[2800]\tvalid_0's macro_f1: 0.784163\n",
      "[2900]\tvalid_0's macro_f1: 0.78595\n",
      "[3000]\tvalid_0's macro_f1: 0.787872\n",
      "[3100]\tvalid_0's macro_f1: 0.790282\n",
      "[3200]\tvalid_0's macro_f1: 0.792104\n",
      "[3300]\tvalid_0's macro_f1: 0.79419\n",
      "[3400]\tvalid_0's macro_f1: 0.795629\n",
      "[3500]\tvalid_0's macro_f1: 0.797502\n",
      "[3600]\tvalid_0's macro_f1: 0.799415\n",
      "[3700]\tvalid_0's macro_f1: 0.801134\n",
      "[3800]\tvalid_0's macro_f1: 0.802403\n",
      "[3900]\tvalid_0's macro_f1: 0.803931\n",
      "[4000]\tvalid_0's macro_f1: 0.805683\n",
      "[4100]\tvalid_0's macro_f1: 0.806622\n",
      "[4200]\tvalid_0's macro_f1: 0.807955\n",
      "[4300]\tvalid_0's macro_f1: 0.809433\n",
      "[4400]\tvalid_0's macro_f1: 0.811104\n",
      "[4500]\tvalid_0's macro_f1: 0.812603\n",
      "[4600]\tvalid_0's macro_f1: 0.813699\n",
      "[4700]\tvalid_0's macro_f1: 0.815068\n",
      "[4800]\tvalid_0's macro_f1: 0.816696\n",
      "[4900]\tvalid_0's macro_f1: 0.818126\n",
      "[5000]\tvalid_0's macro_f1: 0.819704\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\tvalid_0's macro_f1: 0.819732\n",
      "\tPREDICT OOF...\n",
      "\tPREDICTING TEST...\n",
      "\tFold score: 0.819731507186394\n"
     ]
    }
   ],
   "source": [
    "dict_vect = DictVectorizer()\n",
    "\n",
    "for i, (tr_ind, val_ind) in enumerate(strategy.split(X=np.ones(len(train)), y=train['target'])):\n",
    "    print(f'Fold: {i + 1}\\n\\tTrain len: {len(tr_ind)}\\n\\tVal len: {len(val_ind)}')\n",
    "    pipe = Pipeline([\n",
    "            ('dict_vect', dict_vect),\n",
    "            (\"SVD\", TruncatedSVD(n_components=SVD_n_comp))\n",
    "        ])\n",
    "    pipe.fit(train.iloc[tr_ind].drop('target', 1).to_dict('records'))\n",
    "    \n",
    "    X = pipe.transform(train.iloc[tr_ind].drop('target', 1).copy().to_dict('records'))\n",
    "    y = train.iloc[tr_ind]['target'].copy()\n",
    "    X_val = pipe.transform(train.iloc[val_ind].drop('target', 1).copy().to_dict('records'))\n",
    "    y_val = train.iloc[val_ind]['target'].copy()\n",
    "    X_test_ = pipe.transform(test.drop('target', 1).to_dict('records'))\n",
    "    \n",
    "    # fit model\n",
    "    print('\\tFITTING MODEL...')\n",
    "    classifier.fit(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        early_stopping_rounds=params['early_stopping_rounds'],\n",
    "        verbose=params['verbose'],\n",
    "        eval_metric=lgb_fscore,\n",
    "        sample_weight=sample_weight[tr_ind] if use_sample_weight else None,\n",
    "    )\n",
    "    # predict OOF val\n",
    "    print('\\tPREDICT OOF...')\n",
    "    pred_oof[val_ind] = classifier.predict(X_val, num_threads=num_threads)\n",
    "    # predict test\n",
    "    print('\\tPREDICTING TEST...')\n",
    "    pred_test[..., i] = classifier.predict_proba(\n",
    "        X_test_, num_threads=num_threads)\n",
    "    fold_metrics[i] = f1_macro(y_val, pred_oof[val_ind])\n",
    "    print(f'\\tFold score: {fold_metrics[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score:  0.7711281899568938\n"
     ]
    }
   ],
   "source": [
    "print(f'Total score: ', f1_macro(train['target'], pred_oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.96      0.98      4542\n",
      "        True       0.45      0.84      0.58       155\n",
      "\n",
      "    accuracy                           0.96      4697\n",
      "   macro avg       0.72      0.90      0.78      4697\n",
      "weighted avg       0.98      0.96      0.97      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_raw = pred_test.mean(axis=-1)\n",
    "y_pred = y_pred_raw.argmax(axis=1).astype(np.int32)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:p36] *",
   "language": "python",
   "name": "conda-env-p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
