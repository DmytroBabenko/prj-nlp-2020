{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"11-nn.md\")\n",
    "DATA_PATH = '/home/dima/Projects/UD_Ukrainian-IU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as fh:\n",
    "        content = fh.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# I. Нейромережі\n",
       "\n",
       "У цьому завданні вам треба спробувати покращити з використанням нейромереж одну з двох ваших попередніх робіт:\n",
       "\n",
       "1. Доробити парсер залежностей\n",
       "2. Доробити класифікатор звернень до служби 1551\n",
       "\n",
       "## Парсер залежностей\n",
       "\n",
       "На основі FNN створіть класифікатор типу залежності. Для цього використайте:\n",
       "- [UD-корпус для української мови](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
       "- парсер, який ви розробили в завданні 8 (або, якщо вам не вдалося реалізувати свій парсер, то можна взяти за основу [код із практичного заняття](../lectures/08-dep-parser-uk.ipynb))\n",
       "- [векторні представлення слів для української мови](http://lang.org.ua/en/models/#anchor4)\n",
       "\n",
       "Також переробіть свій парсер так, щоб замість використання ознак, визначених вручну, він покладався для вибору наступного переходу на передбачення LSTM-нейромережі, яка на вхід отримує поточні слова з тегами зі стеку та буферу (по 3 слова). Опис подібної мережі можна побачити у [цій статті](https://arxiv.org/pdf/1708.08959.pdf).\n",
       "\n",
       "Обрахуйте якість класифікації та LAS для вашого парсера.\n",
       "\n",
       "## Класифікатор звернень до служби 1551\n",
       "\n",
       "Переробіть класифікатор звернень, який ви розробляли у завданні 10, так, щоб він використовував FNN на векторі документу та LSTM на векторах окремих слів. Порівняйте результати.\n",
       "\n",
       "# II. Курсовий проєкт\n",
       "\n",
       "Для свого курсового проєкту побудуйте рішення (чи кілька рішень), що перевершують по якості ваше базове рішення. Якість міряйте розробленими раніше метриками.\n",
       "Код для курсового проєкту повинен бути у вашому репозиторії. У директорії `students/` в теці з вашим іменем збережіть файл з посиланням на код вашого рішення. Опишіть ваші результати.\n",
       "\n",
       "# Оцінка\n",
       "\n",
       "I. За виконання одного з завдань ви можете отримати 80 балів. Якщо бажаєте, то можете виконати обидва і отримати 120 балів :)\n",
       "\n",
       "II. За покращене рішення з курсового проєкту ви можете отримати 20 балів.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(TASK_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.02 s, sys: 136 ms, total: 3.15 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"uk_iu-ud-train.conllu\"), \"r\") as f:\n",
    "    train_trees = parse(f.read())\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"uk_iu-ud-dev.conllu\"), \"r\") as f:\n",
    "    test_trees = parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5496 672\n"
     ]
    }
   ],
   "source": [
    "print(len(train_trees), len(test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree):\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))\n",
    "\n",
    "def check_tree(tree):\n",
    "    for n in tree:\n",
    "        if not isinstance(n[\"id\"], int):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "tree = train_trees[0]\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad trees: \n",
      "Train: 197\n",
      "Test: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Bad trees: \" )\n",
    "print(\"Train:\", len(list(filter(check_tree, train_trees))))\n",
    "print(\"Test:\", len(list(filter(check_tree, test_trees))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5299 656\n"
     ]
    }
   ],
   "source": [
    "clean_train_trees = list(filter(lambda t: not check_tree(t), train_trees))\n",
    "clean_test_trees = list(filter(lambda t: not check_tree(t), test_trees))\n",
    "\n",
    "print(len(clean_train_trees), len(clean_test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersects(n1, n2):\n",
    "    s1 = n1['id'] if n1['head'] > n1['id'] else n1['head']\n",
    "    e1 = n1['head'] if n1['head'] > n1['id'] else n1['id']\n",
    "    s2 = n2['id'] if n2['head'] > n2['id'] else n2['head']\n",
    "    e2 = n2['head'] if n2['head'] > n2['id'] else n2['id']\n",
    "    \n",
    "    return (s1 < s2 and e1 > s2 and e2 > e1) or (s2 < s1 and e2 > s1 and e1 > e2)\n",
    "\n",
    "def non_projective(tree):\n",
    "    for n1 in tree:\n",
    "        for n2 in tree:\n",
    "            if n1['id'] < n2['id'] and intersects(n1, n2):\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 57\n"
     ]
    }
   ],
   "source": [
    "non_projective_train_trees = list(filter(non_projective, clean_train_trees))\n",
    "non_projective_test_trees = list(filter(non_projective, clean_test_trees))\n",
    "\n",
    "print(len(non_projective_train_trees), len(non_projective_test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Звісно <-- було\n",
      "не <-- було\n",
      "було <-- root\n",
      "жодного <-- способу\n",
      "способу <-- було\n",
      "дізнатись <-- способу\n",
      "чи <-- спостерігають\n",
      "спостерігають <-- дізнатись\n",
      "за <-- вами\n",
      "вами <-- спостерігають\n",
      "саме <-- цей\n",
      "у <-- проміжок\n",
      "цей <-- проміжок\n",
      "проміжок <-- спостерігають\n",
      "часу <-- проміжок\n",
      ". <-- було\n"
     ]
    }
   ],
   "source": [
    "np_tree = non_projective_train_trees[21]\n",
    "print_tree(np_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4885 599\n"
     ]
    }
   ],
   "source": [
    "projective_train_trees = list(filter(lambda t: not non_projective(t), clean_train_trees))\n",
    "projective_test_trees = list(filter(lambda t: not non_projective(t), clean_test_trees))\n",
    "\n",
    "print(len(projective_train_trees), len(projective_test_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design actions and the oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()           \n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show prohectiva and non-projective trees result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_actions(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_actions(np_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue, relations):\n",
    "    \n",
    "    features = dict()\n",
    "    \n",
    "    if len(stack) > 1:        \n",
    "        features[\"s0-word\"] = stack[-2][\"form\"]\n",
    "        features[\"s0-lemma\"] = stack[-2][\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack[-2][\"upostag\"]\n",
    "        features[\"s0-rchildren-num\"] = len([r for r in relations if r[1] == stack[-2]['id']])\n",
    "        features[\"s0-lchildren-num\"] = len([r for r in relations if r[0] == stack[-2]['id']])\n",
    "        if stack[-2][\"feats\"]:\n",
    "            for k, v in stack[-2][\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    \n",
    "    if len(stack) > 2:\n",
    "        features[\"s1-word\"] = stack[-3][\"form\"]\n",
    "        features[\"s1-tag\"] = stack[-3][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 3:\n",
    "        features[\"s2-tag\"] = stack[-4][\"upostag\"]\n",
    "        \n",
    "    if len(stack) > 4:\n",
    "        features[\"s3-tag\"] = stack[-5][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 1:\n",
    "        queue_top = stack[-1]\n",
    "        features[\"q0-word\"] = stack[-1][\"form\"]\n",
    "        features[\"q0-lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"q0-tag\"] = stack[-1][\"upostag\"]\n",
    "        features[\"q0-rchildren-num\"] = len([r for r in relations if r[1] == stack[-1]['id']])\n",
    "        features[\"q0-lchildren-num\"] = len([r for r in relations if r[0] == stack[-1]['id']])\n",
    "        if stack[-1][\"feats\"]:\n",
    "            for k, v in stack[-1][\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    \n",
    "    if len(queue) > 0:        \n",
    "        features[\"q1-word\"] = queue[0][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[0][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 1:\n",
    "        features[\"q2-tag\"] = queue[1][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 2:\n",
    "        features[\"q3-tag\"] = queue[2][\"upostag\"]\n",
    "       \n",
    "    if len(stack) > 1:\n",
    "        features[\"distance\"] = stack[-1][\"id\"] - stack[-2][\"id\"]\n",
    "    \n",
    "    features['q-empty'] = not bool(queue)    \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_features_v2(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        features[\"s0-word\"] = stack[-1][\"form\"]\n",
    "        features[\"s0-lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack[-1][\"upostag\"]\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue[0][\"form\"]\n",
    "        features[\"q0-lemma\"] = queue[0][\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue[0][\"upostag\"]\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue[1][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[1][\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features_v2(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = extract_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_features)\n",
    "train_df['target'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190298, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = extract_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_features)\n",
    "test_df['target'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25820, 12)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "N_COMP = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111126\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C=2, solver=\"sag\", multi_class=\"multinomial\", max_iter=1000, \n",
    "                            verbose=1, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([('vec', vec), ('lr_clf', lr_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 332 epochs took 43 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='sag',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.fit(train_features_vectorized, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.86      0.86      0.86      6371\n",
      "      reduce       0.85      0.78      0.81      6875\n",
      "       right       0.75      0.79      0.76      5996\n",
      "       shift       0.84      0.87      0.85      6578\n",
      "\n",
      "   micro avg       0.82      0.82      0.82     25820\n",
      "   macro avg       0.82      0.82      0.82     25820\n",
      "weighted avg       0.82      0.82      0.82     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = lr_clf.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feedforward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = dict(zip(np.unique(train_labels), range(4)))\n",
    "label_mapping_inversed = {v: k for k, v in label_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ohe = tf.keras.utils.to_categorical(list(map(lambda x: label_mapping.get(x), train_labels)))\n",
    "test_labels_ohe = tf.keras.utils.to_categorical(list(map(lambda x: label_mapping.get(x), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(word_index=None):\n",
    "    word_2_vec = {}\n",
    "    with bz2.open(\"ubercorpus.lowercased.tokenized.300d.bz2\", \"rt\") as f:\n",
    "        words, ndim = map(int, f.readline().strip().split())\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if words:\n",
    "                if word in word_index:\n",
    "                    vec = np.asarray(values[1:], dtype=np.float32)\n",
    "                    word_2_vec[word] = vec\n",
    "            else:\n",
    "                vec = np.asarray(values[1:], dtype=np.float32)\n",
    "                word_2_vec[word] = vec\n",
    "    return word_2_vec, ndim, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_childs(word, tree):\n",
    "    return [w for w in tree if w[\"head\"]==word[\"id\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heights(tree, res=None, word=None, k=0):\n",
    "    if res is None:\n",
    "        res = {0: 0}\n",
    "        k = 1\n",
    "    if word is None:\n",
    "        word = [w for w in tree if not w[\"head\"]][0]\n",
    "        res[word[\"id\"]] = k\n",
    "    for child in get_childs(word, tree):\n",
    "        res[child[\"id\"]] = k + 1\n",
    "        get_heights(tree, res, child, k+1)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(trees, form=\"form\"):\n",
    "    word_index = {}\n",
    "    pos_index = {}\n",
    "    label_index = {}\n",
    "    labels = []\n",
    "    for tree in trees:\n",
    "        tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "        for word in tree:\n",
    "            deprel = word[\"deprel\"]\n",
    "            word_id = len(word_index)+1\n",
    "            pos_id = len(pos_index)+1\n",
    "            word_t = word[form].lower()\n",
    "            word_pos = word[\"upostag\"]\n",
    "            word_index[word_t] = word_index.get(word_t, word_id)\n",
    "            pos_index[word_pos] = pos_index.get(word_pos, pos_id)\n",
    "            if deprel not in label_index:\n",
    "                label_id = len(label_index)\n",
    "                label_index[deprel] = label_id\n",
    "            else:\n",
    "                label_id = label_index.get(deprel)\n",
    "            labels.append(label_id)\n",
    "    word_index[ROOT[\"form\"]] = len(word_index)+1\n",
    "    pos_index[ROOT[\"upostag\"]] = len(pos_index)+1\n",
    "    return word_index, pos_index, label_index, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(tree, word_index, pos_index, form=\"form\"):\n",
    "    label_index = {}\n",
    "    records = []\n",
    "    labels = []\n",
    "    heights = get_heights(tree)\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    for word in tree:\n",
    "        deprel = word[\"deprel\"]\n",
    "        word_t = word[form].lower()\n",
    "        head = tree[word[\"head\"]-1] if word[\"head\"] else ROOT\n",
    "        head_t = head[form].lower() if word[\"head\"] else \"ROOT\"\n",
    "        word_pos = word[\"upostag\"]\n",
    "        head_pos = head[\"upostag\"]\n",
    "\n",
    "        dist = word[\"id\"] - head[\"id\"]\n",
    "        height_diff = heights.get(word[\"id\"], 0) - heights.get(head[\"id\"], 0)\n",
    "        n_l_child_word = len([_ for w in tree if w[\"head\"]==word[\"id\"] and w[\"id\"]<word[\"id\"]])\n",
    "        n_r_child_word = len([_ for w in tree if w[\"head\"]==word[\"id\"] and w[\"id\"]>word[\"id\"]])\n",
    "        n_l_child_head = len([_ for w in tree if w[\"head\"]==head[\"id\"] and w[\"id\"]<head[\"id\"]])\n",
    "        n_r_child_head = len([_ for w in tree if w[\"head\"]==head[\"id\"] and w[\"id\"]>head[\"id\"]])\n",
    "\n",
    "        # children\n",
    "        w_children = [w for w in tree if w[\"head\"]==word[\"id\"]]\n",
    "        if w_children:\n",
    "            lm = min(w_children, key=lambda x: x[\"id\"])\n",
    "            rm = max(w_children, key=lambda x: x[\"id\"])\n",
    "            w_lr = [word_index.get(lm[form].lower()), word_index.get(rm[form].lower())]\n",
    "            pos_lr = [pos_index.get(lm[\"upostag\"]), pos_index.get(rm[\"upostag\"])]\n",
    "        else:\n",
    "            w_lr = [0, 0]\n",
    "            pos_lr = [0, 0]\n",
    "               \n",
    "        # construct final feature vector\n",
    "        num_features = [dist, height_diff, heights.get(word[\"id\"], 0), \n",
    "                        n_l_child_word, n_r_child_word, \n",
    "                        n_r_child_head, n_l_child_head\n",
    "                       ]\n",
    "        words = [word_index.get(word_t), word_index.get(head_t), *w_lr]\n",
    "        tags = [pos_index.get(word_pos), pos_index.get(head_pos), *pos_lr]\n",
    "        records.append((*words, *tags, *num_features))\n",
    "    return records, len(words), len(tags), len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(trees, word_index, pos_index, form=\"form\"):\n",
    "    records = []\n",
    "    for tree in trees:\n",
    "        feats, n_w, n_t, n_f = build_features(tree, word_index, pos_index, form)\n",
    "        records.extend(feats)\n",
    "    return records, n_w, n_t, n_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# w2v_model = KeyedVectors.load_word2vec_format(\"ubercorpus.lowercased.tokenized.word2vec.300d\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = np.sum([len(tree) for tree in train_trees])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index, pos_index, label_index, labels = build_vocabulary(train_trees+test_trees)\n",
    "# labels = tf.keras.utils.to_categorical(np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_label = {v:k for k,v in label_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "records, n_words, n_tags, n_feat = process_data(train_trees+test_trees, word_index, pos_index)\n",
    "X = np.asarray(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = labels[:n_train], labels[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2_vec, ndim, _ = read_embeddings(word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((92635, 15), (92635, 57))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12340, 15), (12340, 57))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_VEC = np.zeros(ndim, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index)+1, ndim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_matrix[i] = word_2_vec.get(word, DEFAULT_VEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_layer = tf.keras.layers.Embedding(len(word_index)+1,\n",
    "                            ndim,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=n_words,\n",
    "                            trainable=0\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embedding_layer = tf.keras.layers.Embedding(len(pos_index)+1,\n",
    "                                ndim,\n",
    "                                input_length=n_tags,\n",
    "                                trainable=1\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_sequence_input = tf.keras.layers.Input(shape=(n_words,), dtype='int32')\n",
    "word_embedded_sequences = word_embedding_layer(word_sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sequence_input = tf.keras.layers.Input(shape=(n_tags,), dtype='int32')\n",
    "pos_embedded_sequences = pos_embedding_layer(pos_sequence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tf.keras.layers.Input(shape=(n_feat,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "left = tf.keras.layers.Flatten()(word_embedded_sequences)\n",
    "right = tf.keras.layers.Flatten()(pos_embedded_sequences)\n",
    "x = tf.keras.layers.concatenate(inputs=[left, right, features])\n",
    "x = tf.keras.layers.Dense(192)(x)\n",
    "x = tf.keras.layers.Dense(96, activation='relu')(x)\n",
    "preds = tf.keras.layers.Dense(len(label_index), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(inputs=[word_sequence_input, pos_sequence_input, features], outputs=preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 92635 samples, validate on 12340 samples\n",
      "Epoch 1/6\n",
      "92635/92635 [==============================] - 3s 35us/sample - loss: 0.3387 - acc: 0.9058 - val_loss: 0.2017 - val_acc: 0.9344\n",
      "Epoch 2/6\n",
      "92635/92635 [==============================] - 3s 31us/sample - loss: 0.1793 - acc: 0.9435 - val_loss: 0.2014 - val_acc: 0.9370\n",
      "Epoch 3/6\n",
      "92635/92635 [==============================] - 3s 31us/sample - loss: 0.1406 - acc: 0.9556 - val_loss: 0.2026 - val_acc: 0.9425\n",
      "Epoch 4/6\n",
      "92635/92635 [==============================] - 3s 31us/sample - loss: 0.1139 - acc: 0.9631 - val_loss: 0.2130 - val_acc: 0.9395\n",
      "Epoch 5/6\n",
      "92635/92635 [==============================] - 3s 32us/sample - loss: 0.0920 - acc: 0.9706 - val_loss: 0.2388 - val_acc: 0.9370\n",
      "Epoch 6/6\n",
      "92635/92635 [==============================] - 3s 32us/sample - loss: 0.0762 - acc: 0.9753 - val_loss: 0.2514 - val_acc: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe1066676a0>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit([X_train[:, :n_words], X_train[:, n_words:n_words+n_tags], X_train[:, n_words+n_tags:]], y_train, \n",
    "          validation_data=([X_test[:, :n_words], X_test[:, n_words:n_words+n_tags], X_test[:, n_words+n_tags:]], y_test), \n",
    "          epochs=6, \n",
    "          batch_size=128, \n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([X_test[:, :n_words], X_test[:, n_words:n_words+n_tags], X_test[:, n_words+n_tags:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1135\n",
      "           1       0.96      0.96      0.96       824\n",
      "           2       1.00      0.98      0.99      1030\n",
      "           3       0.96      0.96      0.96      1190\n",
      "           4       0.78      0.76      0.77       185\n",
      "           5       1.00      1.00      1.00       656\n",
      "           6       0.90      0.90      0.90       778\n",
      "           7       1.00      1.00      1.00      2363\n",
      "           8       0.54      0.46      0.50       115\n",
      "           9       0.99      1.00      0.99       438\n",
      "          10       0.82      0.82      0.82       554\n",
      "          11       0.98      0.97      0.98       598\n",
      "          12       0.56      0.71      0.63       101\n",
      "          13       0.97      0.91      0.94       190\n",
      "          14       0.96      0.94      0.95       114\n",
      "          15       0.88      0.86      0.87       591\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       1.00      0.98      0.99       281\n",
      "          18       0.72      0.52      0.61        63\n",
      "          19       1.00      0.99      0.99       237\n",
      "          20       0.92      0.92      0.92        59\n",
      "          21       1.00      0.93      0.97        15\n",
      "          22       0.73      0.83      0.78        36\n",
      "          23       0.58      0.55      0.56       128\n",
      "          24       0.65      1.00      0.78        20\n",
      "          25       0.85      0.89      0.87       158\n",
      "          26       0.52      0.87      0.65        31\n",
      "          27       0.75      1.00      0.86         3\n",
      "          28       0.87      1.00      0.93        53\n",
      "          29       0.84      0.88      0.86        66\n",
      "          30       0.35      0.62      0.44        13\n",
      "          31       0.85      0.68      0.75        68\n",
      "          32       1.00      0.71      0.83        28\n",
      "          33       0.78      0.87      0.82        69\n",
      "          34       0.07      0.14      0.10         7\n",
      "          35       0.33      0.38      0.36        13\n",
      "          36       0.93      1.00      0.96        27\n",
      "          37       0.50      1.00      0.67         2\n",
      "          38       0.88      0.59      0.71        71\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.38      0.60      0.46         5\n",
      "          41       0.67      0.25      0.36         8\n",
      "          42       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.25      1.00      0.40         1\n",
      "          48       0.75      1.00      0.86         3\n",
      "          49       0.17      0.50      0.25         2\n",
      "          52       0.50      0.70      0.58        10\n",
      "          54       0.00      0.00      0.00         0\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     12340\n",
      "   macro avg       0.65      0.70      0.66     12340\n",
      "weighted avg       0.94      0.94      0.94     12340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(pred, axis=1), np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#         tf.keras.callbacks.EarlyStopping(monitor='val_loss',  min_delta=0.001, patience=5),\n",
    "#         tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
    "#         tf.keras.callbacks.ModelCheckpoint('fnn.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the unlabeled attachment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle, vectorizer=None, t_svd=None, log=False):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue, relations)\n",
    "            if vectorizer:\n",
    "                features = vectorizer.transform([features])\n",
    "            if t_svd:\n",
    "                features = t_svd.transform(features)\n",
    "            action = oracle.predict(features)[0]\n",
    "            if log:\n",
    "                print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "                print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "                print(\"Relations:\", relations)\n",
    "                print(action)\n",
    "                print(\"========================\")\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in tqdm(test_trees):\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lgb_clf, vec, t_svd)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
