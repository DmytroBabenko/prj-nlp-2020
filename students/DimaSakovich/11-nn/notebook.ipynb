{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_PATH = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "TASK_PATH = os.path.join(REPO_PATH, \"tasks\", \"11-nn.md\")\n",
    "DATA_PATH = '/home/dima/Projects/UD_Ukrainian-IU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_markdown(path):\n",
    "    with open(path, 'r') as fh:\n",
    "        content = fh.read()\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# I. Нейромережі\n",
       "\n",
       "У цьому завданні вам треба спробувати покращити з використанням нейромереж одну з двох ваших попередніх робіт:\n",
       "\n",
       "1. Доробити парсер залежностей\n",
       "2. Доробити класифікатор звернень до служби 1551\n",
       "\n",
       "## Парсер залежностей\n",
       "\n",
       "На основі FNN створіть класифікатор типу залежності. Для цього використайте:\n",
       "- [UD-корпус для української мови](https://github.com/UniversalDependencies/UD_Ukrainian-IU/)\n",
       "- парсер, який ви розробили в завданні 8 (або, якщо вам не вдалося реалізувати свій парсер, то можна взяти за основу [код із практичного заняття](../lectures/08-dep-parser-uk.ipynb))\n",
       "- [векторні представлення слів для української мови](http://lang.org.ua/en/models/#anchor4)\n",
       "\n",
       "Також переробіть свій парсер так, щоб замість використання ознак, визначених вручну, він покладався для вибору наступного переходу на передбачення LSTM-нейромережі, яка на вхід отримує поточні слова з тегами зі стеку та буферу (по 3 слова). Опис подібної мережі можна побачити у [цій статті](https://arxiv.org/pdf/1708.08959.pdf).\n",
       "\n",
       "Обрахуйте якість класифікації та LAS для вашого парсера.\n",
       "\n",
       "## Класифікатор звернень до служби 1551\n",
       "\n",
       "Переробіть класифікатор звернень, який ви розробляли у завданні 10, так, щоб він використовував FNN на векторі документу та LSTM на векторах окремих слів. Порівняйте результати.\n",
       "\n",
       "# II. Курсовий проєкт\n",
       "\n",
       "Для свого курсового проєкту побудуйте рішення (чи кілька рішень), що перевершують по якості ваше базове рішення. Якість міряйте розробленими раніше метриками.\n",
       "Код для курсового проєкту повинен бути у вашому репозиторії. У директорії `students/` в теці з вашим іменем збережіть файл з посиланням на код вашого рішення. Опишіть ваші результати.\n",
       "\n",
       "# Оцінка\n",
       "\n",
       "I. За виконання одного з завдань ви можете отримати 80 балів. Якщо бажаєте, то можете виконати обидва і отримати 120 балів :)\n",
       "\n",
       "II. За покращене рішення з курсового проєкту ви можете отримати 20 балів.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_markdown(TASK_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependancy parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 133 ms, total: 3.23 s\n",
      "Wall time: 3.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"uk_iu-ud-train.conllu\"), \"r\") as f:\n",
    "    train_trees = parse(f.read())\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"uk_iu-ud-dev.conllu\"), \"r\") as f:\n",
    "    test_trees = parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5496 672\n"
     ]
    }
   ],
   "source": [
    "print(len(train_trees), len(test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(tree):\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))\n",
    "\n",
    "def check_tree(tree):\n",
    "    for n in tree:\n",
    "        if not isinstance(n[\"id\"], int):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "tree = train_trees[0]\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad trees: \n",
      "Train: 197\n",
      "Test: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"Bad trees: \" )\n",
    "print(\"Train:\", len(list(filter(check_tree, train_trees))))\n",
    "print(\"Test:\", len(list(filter(check_tree, test_trees))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5299 656\n"
     ]
    }
   ],
   "source": [
    "clean_train_trees = list(filter(lambda t: not check_tree(t), train_trees))\n",
    "clean_test_trees = list(filter(lambda t: not check_tree(t), test_trees))\n",
    "\n",
    "print(len(clean_train_trees), len(clean_test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersects(n1, n2):\n",
    "    s1 = n1['id'] if n1['head'] > n1['id'] else n1['head']\n",
    "    e1 = n1['head'] if n1['head'] > n1['id'] else n1['id']\n",
    "    s2 = n2['id'] if n2['head'] > n2['id'] else n2['head']\n",
    "    e2 = n2['head'] if n2['head'] > n2['id'] else n2['id']\n",
    "    \n",
    "    return (s1 < s2 and e1 > s2 and e2 > e1) or (s2 < s1 and e2 > s1 and e1 > e2)\n",
    "\n",
    "def non_projective(tree):\n",
    "    for n1 in tree:\n",
    "        for n2 in tree:\n",
    "            if n1['id'] < n2['id'] and intersects(n1, n2):\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414 57\n"
     ]
    }
   ],
   "source": [
    "non_projective_train_trees = list(filter(non_projective, clean_train_trees))\n",
    "non_projective_test_trees = list(filter(non_projective, clean_test_trees))\n",
    "\n",
    "print(len(non_projective_train_trees), len(non_projective_test_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Звісно <-- було\n",
      "не <-- було\n",
      "було <-- root\n",
      "жодного <-- способу\n",
      "способу <-- було\n",
      "дізнатись <-- способу\n",
      "чи <-- спостерігають\n",
      "спостерігають <-- дізнатись\n",
      "за <-- вами\n",
      "вами <-- спостерігають\n",
      "саме <-- цей\n",
      "у <-- проміжок\n",
      "цей <-- проміжок\n",
      "проміжок <-- спостерігають\n",
      "часу <-- проміжок\n",
      ". <-- було\n"
     ]
    }
   ],
   "source": [
    "np_tree = non_projective_train_trees[21]\n",
    "print_tree(np_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4885 599\n"
     ]
    }
   ],
   "source": [
    "projective_train_trees = list(filter(lambda t: not non_projective(t), clean_train_trees))\n",
    "projective_test_trees = list(filter(lambda t: not non_projective(t), clean_test_trees))\n",
    "\n",
    "print(len(projective_train_trees), len(projective_test_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design actions and the oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree, log=True):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if log:\n",
    "            print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "            print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "            print(\"Relations:\", relations)\n",
    "            print(action)\n",
    "            print(\"========================\")\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()           \n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    if log:\n",
    "        print(\"Gold relations:\")\n",
    "        print([(node[\"id\"], node[\"head\"]) for node in tree])\n",
    "        print(\"Retrieved relations:\")\n",
    "        print(sorted(relations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show prohectiva and non-projective trees result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_actions(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trace_actions(np_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue, relations=None):\n",
    "    \n",
    "    features = dict()\n",
    "    \n",
    "    if len(stack) > 1:        \n",
    "        features[\"s0-word\"] = stack[-2][\"form\"]\n",
    "        features[\"s0-lemma\"] = stack[-2][\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack[-2][\"upostag\"]\n",
    "#         features[\"s0-rchildren-num\"] = len([r for r in relations if r[1] == stack[-2]['id']])\n",
    "#         features[\"s0-lchildren-num\"] = len([r for r in relations if r[0] == stack[-2]['id']])\n",
    "        if stack[-2][\"feats\"]:\n",
    "            for k, v in stack[-2][\"feats\"].items():\n",
    "                features[\"s0-\" + k] = v\n",
    "    \n",
    "    if len(stack) > 2:\n",
    "        features[\"s1-word\"] = stack[-3][\"form\"]\n",
    "        features[\"s1-tag\"] = stack[-3][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 3:\n",
    "        features[\"s2-tag\"] = stack[-4][\"upostag\"]\n",
    "        \n",
    "    if len(stack) > 4:\n",
    "        features[\"s3-tag\"] = stack[-5][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 1:\n",
    "        queue_top = stack[-1]\n",
    "        features[\"q0-word\"] = stack[-1][\"form\"]\n",
    "        features[\"q0-lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"q0-tag\"] = stack[-1][\"upostag\"]\n",
    "#         features[\"q0-rchildren-num\"] = len([r for r in relations if r[1] == stack[-1]['id']])\n",
    "#         features[\"q0-lchildren-num\"] = len([r for r in relations if r[0] == stack[-1]['id']])\n",
    "        if stack[-1][\"feats\"]:\n",
    "            for k, v in stack[-1][\"feats\"].items():\n",
    "                features[\"q0-\" + k] = v\n",
    "    \n",
    "    if len(queue) > 0:        \n",
    "        features[\"q1-word\"] = queue[0][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[0][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 1:\n",
    "        features[\"q2-tag\"] = queue[1][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 2:\n",
    "        features[\"q3-tag\"] = queue[2][\"upostag\"]\n",
    "       \n",
    "    if len(stack) > 1:\n",
    "        features[\"distance\"] = stack[-1][\"id\"] - stack[-2][\"id\"]\n",
    "    \n",
    "    features['q-empty'] = not bool(queue)    \n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def extract_features_v2(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        features[\"s0-word\"] = stack[-1][\"form\"]\n",
    "        features[\"s0-lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack[-1][\"upostag\"]\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue[0][\"form\"]\n",
    "        features[\"q0-lemma\"] = queue[0][\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue[0][\"upostag\"]\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue[1][\"form\"]\n",
    "        features[\"q1-tag\"] = queue[1][\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = extract_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_features)\n",
    "train_df['target'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190298, 69)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = extract_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_features)\n",
    "test_df['target'] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25820, 68)\n"
     ]
    }
   ],
   "source": [
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train clasifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 0\n",
    "N_COMP = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  115611\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(C=2, solver=\"sag\", multi_class=\"multinomial\", max_iter=1000, \n",
    "                            verbose=1, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([('vec', vec), ('lr_clf', lr_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 153 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dima/anaconda3/envs/p36/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', DictVectorizer(dtype=<class 'numpy.float64'>, separator='=', sort=True,\n",
       "        sparse=True)), ('lr_clf', LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='sag',\n",
       "          tol=0.0001, verbose=1, warm_start=False))])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lr_clf.fit(train_features_vectorized, train_labels)\n",
    "lr_pipe.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.88      0.90      0.89      6371\n",
      "      reduce       0.86      0.81      0.83      6875\n",
      "       right       0.77      0.80      0.79      5996\n",
      "       shift       0.85      0.87      0.86      6578\n",
      "\n",
      "   micro avg       0.84      0.84      0.84     25820\n",
      "   macro avg       0.84      0.84      0.84     25820\n",
      "weighted avg       0.84      0.84      0.84     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicted = lr_clf.predict(test_features_vectorized)\n",
    "predicted = lr_pipe.predict(test_features)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_nn(stack, queue):\n",
    "    \n",
    "    features = {\n",
    "        \"s0-lemma\": None,\n",
    "        \"s0-tag\": None,\n",
    "        \"s1-lemma\": None,\n",
    "        \"s1-tag\": None,\n",
    "        \"s2-lemma\": None,\n",
    "        \"s2-tag\": None,\n",
    "        \"q0-lemma\": None,\n",
    "        \"q0-tag\": None,\n",
    "        \"q1-lemma\": None,\n",
    "        \"q1-tag\": None,\n",
    "        \"q2-lemma\": None,\n",
    "        \"q2-tag\": None\n",
    "    }\n",
    "    \n",
    "    if len(stack) > 1:        \n",
    "        features[\"s0-lemma\"] = stack[-2][\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack[-2][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 2:\n",
    "        features[\"s1-lemma\"] = stack[-3][\"lemma\"]\n",
    "        features[\"s1-tag\"] = stack[-3][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 3:\n",
    "        features[\"s2-lemma\"] = stack[-4][\"lemma\"]\n",
    "        features[\"s2-tag\"] = stack[-4][\"upostag\"]\n",
    "    \n",
    "    if len(stack) > 1:\n",
    "        queue_top = stack[-1]\n",
    "        features[\"q0-lemma\"] = stack[-1][\"lemma\"]\n",
    "        features[\"q0-tag\"] = stack[-1][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 0:        \n",
    "        features[\"q1-lemma\"] = queue[0][\"lemma\"]\n",
    "        features[\"q1-tag\"] = queue[0][\"upostag\"]\n",
    "    \n",
    "    if len(queue) > 1:\n",
    "        features[\"q2-lemma\"] = queue[1][\"lemma\"]\n",
    "        features[\"q2-tag\"] = queue[1][\"upostag\"]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_nn(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            features.append(extract_features_nn(stack, queue))\n",
    "            labels.append(stack[-1][\"deprel\"])\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            features.append(extract_features_nn(stack, queue))\n",
    "            labels.append(queue[0][\"deprel\"])\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(\"ubercorpus.lowercased.tokenized.word2vec.300d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = extract_data_nn([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = extract_data_nn([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2df(feat_dict, labels=None):\n",
    "    df = pd.DataFrame(feat_dict)\n",
    "    df.columns = sorted(df.columns)\n",
    "    if labels:\n",
    "        df['deprel'] = labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dict2df(train_features, train_labels)\n",
    "test_df = dict2df(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q0-lemma</th>\n",
       "      <th>q0-tag</th>\n",
       "      <th>q1-lemma</th>\n",
       "      <th>q1-tag</th>\n",
       "      <th>q2-lemma</th>\n",
       "      <th>q2-tag</th>\n",
       "      <th>s0-lemma</th>\n",
       "      <th>s0-tag</th>\n",
       "      <th>s1-lemma</th>\n",
       "      <th>s1-tag</th>\n",
       "      <th>s2-lemma</th>\n",
       "      <th>s2-tag</th>\n",
       "      <th>deprel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дідусь</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>той</td>\n",
       "      <td>DET</td>\n",
       "      <td>що</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>той</td>\n",
       "      <td>DET</td>\n",
       "      <td>дідусь</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>що</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>атестувати</td>\n",
       "      <td>VERB</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>дідусь</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>той</td>\n",
       "      <td>DET</td>\n",
       "      <td>атестувати</td>\n",
       "      <td>VERB</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>acl:relcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>той</td>\n",
       "      <td>DET</td>\n",
       "      <td>дідусь</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>атестувати</td>\n",
       "      <td>VERB</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>посміхнутися</td>\n",
       "      <td>VERB</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>дідусь</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>той</td>\n",
       "      <td>DET</td>\n",
       "      <td>посміхнутися</td>\n",
       "      <td>VERB</td>\n",
       "      <td>й</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>dislocated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  q0-lemma q0-tag q1-lemma q1-tag q2-lemma q2-tag    s0-lemma s0-tag  \\\n",
       "0   дідусь   NOUN     ROOT   ROOT     None   None           ,  PUNCT   \n",
       "1      той    DET   дідусь   NOUN     ROOT   ROOT          що  SCONJ   \n",
       "2   дідусь   NOUN     ROOT   ROOT     None   None         той    DET   \n",
       "3      той    DET   дідусь   NOUN     ROOT   ROOT  атестувати   VERB   \n",
       "4   дідусь   NOUN     ROOT   ROOT     None   None         той    DET   \n",
       "\n",
       "       s1-lemma s1-tag      s2-lemma s2-tag      deprel  \n",
       "0           той    DET            що  SCONJ       punct  \n",
       "1    атестувати   VERB             ,  PUNCT        mark  \n",
       "2    атестувати   VERB             ,  PUNCT   acl:relcl  \n",
       "3             ,  PUNCT  посміхнутися   VERB       punct  \n",
       "4  посміхнутися   VERB             й  CCONJ  dislocated  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df.head()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_columns = sorted([item for item in train_df.columns if item.endswith('tag')])\n",
    "# pos_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_columns = sorted([item for item in train_df.columns if item.endswith('lemma')])\n",
    "# lemma_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags = list(sorted(filter(lambda x: isinstance(x, str), set(np.hstack(train_df[pos_columns].values)))))\n",
    "pos_tags_mapping = dict(zip(pos_tags, range(1, len(pos_tags)+1)))\n",
    "# pos_tags_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "deprel = train_df['deprel'].unique()\n",
    "deprel_mapping = dict(zip(deprel, range(len(deprel))))\n",
    "inverse_deprel_mapping = {v:k for k, v in deprel_mapping.items()}\n",
    "# deprel_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_ohe(x):\n",
    "    res = np.zeros((1, len(pos_tags_mapping)))\n",
    "    pos_idx = pos_tags_mapping.get(x)\n",
    "    if pos_idx:\n",
    "        res[:,pos_idx-1] = 1\n",
    "    return res\n",
    "    \n",
    "def word_embed(x):\n",
    "    if x in w2v_model.vocab:\n",
    "        return w2v_model.__getitem__([x])\n",
    "    else:\n",
    "        return np.zeros((1, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nn_features(feats, labels=None):\n",
    "    df = dict2df(feats, labels)\n",
    "    \n",
    "    res = []\n",
    "    for col in lemma_columns:\n",
    "        res.append(np.vstack(df[col].fillna('').map(word_embed).values))\n",
    "    X_lemma = np.stack(res, axis=1)\n",
    "    \n",
    "    res = []\n",
    "    for col in pos_columns:\n",
    "        res.append(np.vstack(df[col].fillna('').map(pos_ohe).values))\n",
    "    X_pos = np.stack(res, axis=1)\n",
    "    \n",
    "    if labels:\n",
    "        y = df['deprel'].map(deprel_mapping)\n",
    "        y = tf.keras.utils.to_categorical(y)\n",
    "        return X_lemma, X_pos, y\n",
    "    else:\n",
    "        return X_lemma, X_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90880, 6, 300) (90880, 6, 18) (90880, 56)\n"
     ]
    }
   ],
   "source": [
    "X_lemma_train, X_pos_train, y_train = make_nn_features(train_features, train_labels)\n",
    "X_lemma_test, X_pos_test, y_test = make_nn_features(test_features, test_labels)\n",
    "\n",
    "print(X_lemma_train.shape, X_pos_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_input = tf.keras.layers.Input(shape=X_lemma_train.shape[1:])\n",
    "pos_emb_input = tf.keras.layers.Input(shape=X_pos_train.shape[1:])\n",
    "\n",
    "lstm_pos = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(pos_emb_input)\n",
    "lstm_word = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(word_emb_input)\n",
    "\n",
    "flat_pos = tf.keras.layers.Flatten()(lstm_pos)\n",
    "flat_word = tf.keras.layers.Flatten()(lstm_word)\n",
    "\n",
    "flat_concat = tf.keras.layers.concatenate([flat_pos, flat_word], axis=-1)\n",
    "# flat = tf.keras.layers.Flatten()(lstm_concat)\n",
    "\n",
    "flat_concat = tf.keras.layers.Dropout(0.3)(flat_concat)\n",
    "\n",
    "dense_layer = tf.keras.layers.Dense(128, activation='relu')(flat_concat)\n",
    "\n",
    "dense_output = tf.keras.layers.Dense(len(deprel_mapping), activation='softmax')(dense_layer)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[word_emb_input, pos_emb_input], outputs=dense_output, name='lemma_pos_lstm')\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lemma_pos_lstm\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6, 18)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 6, 300)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 6, 128)       42496       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 6, 128)       186880      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 768)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 768)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1536)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1536)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          196736      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 56)           7224        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 433,336\n",
      "Trainable params: 433,336\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.2, verbose=True),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3, verbose=True), \n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='lemma_pos_lstm.h5', save_best_only=True, verbose=True)\n",
    "]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90880 samples, validate on 12367 samples\n",
      "Epoch 1/100\n",
      "90720/90880 [============================>.] - ETA: 0s - loss: 0.7200 - categorical_accuracy: 0.7866\n",
      "Epoch 00001: val_loss improved from inf to 0.54487, saving model to lemma_pos_lstm.h5\n",
      "90880/90880 [==============================] - 17s 191us/sample - loss: 0.7195 - categorical_accuracy: 0.7866 - val_loss: 0.5449 - val_categorical_accuracy: 0.8251\n",
      "Epoch 2/100\n",
      "90624/90880 [============================>.] - ETA: 0s - loss: 0.5099 - categorical_accuracy: 0.8356\n",
      "Epoch 00002: val_loss improved from 0.54487 to 0.51708, saving model to lemma_pos_lstm.h5\n",
      "90880/90880 [==============================] - 15s 169us/sample - loss: 0.5101 - categorical_accuracy: 0.8355 - val_loss: 0.5171 - val_categorical_accuracy: 0.8342\n",
      "Epoch 3/100\n",
      "90752/90880 [============================>.] - ETA: 0s - loss: 0.4491 - categorical_accuracy: 0.8524\n",
      "Epoch 00003: val_loss did not improve from 0.51708\n",
      "90880/90880 [==============================] - 16s 174us/sample - loss: 0.4491 - categorical_accuracy: 0.8524 - val_loss: 0.5182 - val_categorical_accuracy: 0.8342\n",
      "Epoch 4/100\n",
      "90752/90880 [============================>.] - ETA: 0s - loss: 0.4040 - categorical_accuracy: 0.8640\n",
      "Epoch 00004: val_loss did not improve from 0.51708\n",
      "90880/90880 [==============================] - 16s 174us/sample - loss: 0.4040 - categorical_accuracy: 0.8640 - val_loss: 0.5188 - val_categorical_accuracy: 0.8371\n",
      "Epoch 5/100\n",
      "90560/90880 [============================>.] - ETA: 0s - loss: 0.3638 - categorical_accuracy: 0.8765\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51708\n",
      "90880/90880 [==============================] - 16s 175us/sample - loss: 0.3638 - categorical_accuracy: 0.8765 - val_loss: 0.5328 - val_categorical_accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "90720/90880 [============================>.] - ETA: 0s - loss: 0.2755 - categorical_accuracy: 0.9053\n",
      "Epoch 00006: val_loss did not improve from 0.51708\n",
      "90880/90880 [==============================] - 16s 178us/sample - loss: 0.2754 - categorical_accuracy: 0.9054 - val_loss: 0.5496 - val_categorical_accuracy: 0.8396\n",
      "Epoch 7/100\n",
      "90752/90880 [============================>.] - ETA: 0s - loss: 0.2409 - categorical_accuracy: 0.9167\n",
      "Epoch 00007: val_loss did not improve from 0.51708\n",
      "90880/90880 [==============================] - 16s 178us/sample - loss: 0.2409 - categorical_accuracy: 0.9167 - val_loss: 0.5724 - val_categorical_accuracy: 0.8392\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_lemma_train, X_pos_train], y=y_train,\n",
    "                    class_weight='balanced',\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=([X_lemma_test, X_pos_test], y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_pos_lstm_model = tf.keras.models.load_model('lemma_pos_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "               case       1.00      1.00      1.00      1154\n",
      "               amod       0.97      0.93      0.95      1065\n",
      "               nmod       0.93      0.74      0.82      1516\n",
      "         flat:title       0.51      0.62      0.56       149\n",
      "                obl       0.57      0.62      0.59       753\n",
      "               root       1.00      1.00      1.00       647\n",
      "              nsubj       0.69      0.61      0.65       888\n",
      "              punct       1.00      1.00      1.00      2359\n",
      "              appos       0.07      0.21      0.10        28\n",
      "                 cc       0.98      1.00      0.99       435\n",
      "               conj       0.38      0.56      0.46       380\n",
      "             advmod       0.97      0.90      0.93       658\n",
      "              advcl       0.19      0.49      0.27        45\n",
      "          discourse       0.89      0.92      0.91       175\n",
      "              xcomp       0.74      0.76      0.75       111\n",
      "                obj       0.68      0.61      0.65       636\n",
      "           advcl:sp       0.00      0.00      0.00         0\n",
      "                det       0.99      0.92      0.95       300\n",
      "                acl       0.43      0.62      0.51        32\n",
      "               mark       1.00      0.98      0.99       242\n",
      "          flat:name       1.00      0.51      0.68       115\n",
      "         det:numgov       1.00      0.78      0.88        18\n",
      "           xcomp:sp       0.37      0.48      0.42        31\n",
      "          parataxis       0.09      0.17      0.12        58\n",
      "              fixed       0.61      0.90      0.73        21\n",
      "          acl:relcl       0.58      0.71      0.64       129\n",
      "         nummod:gov       0.35      0.82      0.49        22\n",
      "         det:nummod       0.00      0.00      0.00         0\n",
      "                cop       1.00      0.98      0.99        63\n",
      "              csubj       0.67      0.78      0.72        60\n",
      "parataxis:discourse       0.00      0.00      0.00         6\n",
      "              ccomp       0.45      0.57      0.51        44\n",
      "                aux       0.95      1.00      0.97        19\n",
      "           compound       0.51      0.67      0.58        58\n",
      "             orphan       0.00      0.00      0.00         2\n",
      "               iobj       0.07      0.33      0.12         3\n",
      "       flat:foreign       1.00      0.91      0.95        32\n",
      "         advmod:det       1.00      0.67      0.80         6\n",
      "             nummod       0.90      0.53      0.67        81\n",
      "      parataxis:rel       0.00      0.00      0.00         0\n",
      "               expl       0.56      0.71      0.63         7\n",
      "        flat:repeat       0.00      0.00      0.00         0\n",
      "           vocative       0.00      0.00      0.00         1\n",
      "          flat:sibl       0.00      0.00      0.00         3\n",
      "         dislocated       0.00      0.00      0.00         0\n",
      "            acl:adv       0.00      0.00      0.00         0\n",
      "           flat:abs       0.50      0.50      0.50         4\n",
      "          advcl:svc       0.00      0.00      0.00         0\n",
      "         flat:range       0.36      0.50      0.42        10\n",
      "               list       0.00      0.00      0.00         1\n",
      "  parataxis:newsent       0.00      0.00      0.00         0\n",
      "           goeswith       0.00      0.00      0.00         0\n",
      "\n",
      "          micro avg       0.83      0.83      0.83     12367\n",
      "          macro avg       0.50      0.52      0.50     12367\n",
      "       weighted avg       0.87      0.83      0.85     12367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lemma_pos_lstm_model.predict([X_lemma_test, X_pos_test])\n",
    "target_names = list(map(\n",
    "    lambda x: inverse_deprel_mapping.get(x), \n",
    "    sorted(list(set((list(np.argmax(y_test, axis=1)) + list(np.argmax(pred, axis=1))))))\n",
    "))\n",
    "\n",
    "print(classification_report(np.argmax(pred, axis=1), \n",
    "                            np.argmax(y_test, axis=1),\n",
    "                            target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the labeled attachment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_parse(sentence, oracle=lr_pipe, deprel_model=lemma_pos_lstm_model, log=False):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features_act = extract_features(stack, queue)\n",
    "            action = oracle.predict(features_act)[0]\n",
    "            if log:\n",
    "                print(\"Stack:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in stack])\n",
    "                print(\"Queue:\", [i[\"form\"]+\"_\"+str(i[\"id\"]) for i in queue])\n",
    "                print(\"Relations:\", relations)\n",
    "                print(action)\n",
    "                print(\"========================\")\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                feat_lemma, feat_pos = make_nn_features([extract_features_nn(stack, queue)])\n",
    "                deprel_pred = inverse_deprel_mapping.get(\n",
    "                    np.argmax(deprel_model.predict([feat_lemma, feat_pos]))\n",
    "                )\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"], deprel_pred))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                feat_lemma, feat_pos = make_nn_features([extract_features_nn(stack, queue)])\n",
    "                deprel_pred = inverse_deprel_mapping.get(\n",
    "                    np.argmax(deprel_model.predict([feat_lemma, feat_pos]))\n",
    "                )\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"], deprel_pred))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 672/672 [05:07<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correctly defined: 7717\n",
      "LAS: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total, tp = 0, 0\n",
    "for tree in tqdm(test_trees):\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"], node[\"deprel\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lr_pipe, lemma_pos_lstm_model)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"LAS:\", round(tp/total, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
