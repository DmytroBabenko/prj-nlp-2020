{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework-10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM_GpU3n7X57",
        "colab_type": "text"
      },
      "source": [
        "# Infrastructure setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6otNhXODAyb",
        "colab_type": "text"
      },
      "source": [
        "## Initilizing the runtime (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCAEQDxSaiPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ac836e3-6cdb-401f-928f-3424b1a53f6a"
      },
      "source": [
        "# Google collab restarts the VMs after some time and drops all the files stored on VM,\n",
        "# so some files would be persisted on mounted Google Drive to persist the progress\n",
        "# between the sessions\n",
        "\n",
        "GDRIVE_PATH = '/content/drive/My Drive/Colab/homework-10/'\n",
        "\n",
        "# 1551 Dataset has lots of small files. Reading them from mounted Google Drive\n",
        "# sometimes takes significant time, so I have decided to checkout it to VM\n",
        "# DATA_1551_PATH = '/content/drive/My  Drive/Colab/homework-10/1551.gov.ua/raw/'\n",
        "DATA_1551_PATH = '/content/1551.gov.ua/raw/'\n",
        "\n",
        "\n",
        "#\n",
        "# Working with word2vec models\n",
        "#\n",
        "\n",
        "models_path = '/content/drive/My Drive/Colab/homework-10/vec_models/'\n",
        "\n",
        "# news.cased.tokenized.word2vec.300d\n",
        "news_cased_tokenized_word2vec_300d_path = models_path +'news.cased.tokenized.word2vec.300d' \n",
        "# news.lowercased.tokenized.word2vec.300d\n",
        "news_lowercased_tokenized_word2vec_300d_path = models_path +'news.lowercased.tokenized.word2vec.300d' \n",
        "# news.cased.lemmatized.word2vec.300d\n",
        "news_cased_lemmatized_word2vec_300d_path = models_path +'news.cased.lemmatized.word2vec.300d' \n",
        "# news.lowercased.lemmatized.word2vec.300d\n",
        "news_lowercased_lemmatized_word2vec_300d_path = models_path +'news.lowercased.lemmatized.word2vec.300d' \n",
        "\n",
        "# ubercorpus.cased.tokenized.word2vec.300d\n",
        "ubercorpus_cased_tokenized_word2vec_300d_path = models_path + 'ubercorpus.cased.tokenized.word2vec.300d'\n",
        "\n",
        "# ubercorpus.lowercased.tokenized.word2vec.300d\n",
        "ubercorpus_lowercased_tokenized_word2vec_300d_path = models_path + 'ubercorpus.lowercased.tokenized.word2vec.300d'\n",
        "\n",
        "# ubercorpus.cased.lemmatized.word2vec.300d\n",
        "ubercorpus_cased_lemmatized_word2vec_300d_path = models_path + 'ubercorpus.cased.lemmatized.word2vec.300d'\n",
        "\n",
        "# ubercorpus.lowercased.lemmatized.word2vec.300d\n",
        "ubercorpus_lowercased_lemmatized_word2vec_300d_path = models_path + 'ubercorpus.lowercased.lemmatized.word2vec.300d'\n",
        "\n",
        "\n",
        "#\n",
        "# An amazing progress bar function\n",
        "#\n",
        "\n",
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "\n",
        "    print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '')\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()\n",
        "\n",
        "printProgressBar(1, 10, prefix = 'Progress:', suffix = 'Complete', length = 50)        \n",
        "printProgressBar(1, 100, prefix = 'Progress:', suffix = 'Complete', length = 50)   "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rProgress: |█████---------------------------------------------| 10.0% Complete\rProgress: |--------------------------------------------------| 1.0% Complete"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynSz3En5969y",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the data (once)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ego73YOhhNGv",
        "colab_type": "text"
      },
      "source": [
        "### Donwloading 1551 data to VMs drive (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAC4Q8UM4dLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c3b9881f-c561-479b-f6f3-ec9ad7dd919e"
      },
      "source": [
        "!git clone https://github.com/lang-uk/1551.gov.ua '/content/1551.gov.ua'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/1551.gov.ua'...\n",
            "remote: Enumerating objects: 127370, done.\u001b[K\n",
            "remote: Total 127370 (delta 0), reused 0 (delta 0), pack-reused 127370\u001b[K\n",
            "Receiving objects: 100% (127370/127370), 108.40 MiB | 29.48 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Checking out files: 100% (127332/127332), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwy8Z2r6hSkd",
        "colab_type": "text"
      },
      "source": [
        "### Downloading 1551 data to Google Drive (once)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7BPmbyBaoXP",
        "colab_type": "code",
        "outputId": "709f69f4-e492-4e95-b2ca-80fdf34a1b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/lang-uk/1551.gov.ua '/content/drive/My Drive/Colab/homework-10/1551.gov.ua'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/drive/My Drive/Colab/homework-10/1551.gov.ua'...\n",
            "remote: Enumerating objects: 127370, done.\u001b[K\n",
            "remote: Total 127370 (delta 0), reused 0 (delta 0), pack-reused 127370\u001b[K\n",
            "Receiving objects: 100% (127370/127370), 108.40 MiB | 3.41 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "Checking out files: 100% (127332/127332), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c96o98c-gqvw",
        "colab_type": "text"
      },
      "source": [
        "### Downloading **news** corpus to GDrive (once)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vn4w3qyUgaEZ",
        "colab_type": "text"
      },
      "source": [
        "https://lang.org.ua/static/downloads/models/news.cased.tokenized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/news.lowercased.tokenized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/news.cased.lemmatized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/news.lowercased.lemmatized.word2vec.300d.bz2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYsmVUx2hm7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "66f4089b-4bb5-4133-c2d0-64b94c2996eb"
      },
      "source": [
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/news.cased.tokenized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/news.lowercased.tokenized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/news.cased.lemmatized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/news.lowercased.lemmatized.word2vec.300d.bz2\n",
        "\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/news.lowercased.tokenized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/news.lowercased.lemmatized.word2vec.300d.bz2'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 08:51:53--  https://lang.org.ua/static/downloads/models/news.cased.tokenized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 343843428 (328M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d.bz2’\n",
            "\n",
            "news.cased.tokenize 100%[===================>] 327.91M  10.2MB/s    in 35s     \n",
            "\n",
            "2020-05-15 08:52:31 (9.33 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d.bz2’ saved [343843428/343843428]\n",
            "\n",
            "--2020-05-15 08:52:41--  https://lang.org.ua/static/downloads/models/news.lowercased.tokenized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 310107678 (296M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/news.lowercased.tokenized.word2vec.300d.bz2’\n",
            "\n",
            "news.lowercased.tok 100%[===================>] 295.74M  10.3MB/s    in 31s     \n",
            "\n",
            "2020-05-15 08:53:14 (9.46 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/news.lowercased.tokenized.word2vec.300d.bz2’ saved [310107678/310107678]\n",
            "\n",
            "--2020-05-15 08:53:24--  https://lang.org.ua/static/downloads/models/news.cased.lemmatized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167917510 (160M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d.bz2’\n",
            "\n",
            "news.cased.lemmatiz 100%[===================>] 160.14M  10.1MB/s    in 18s     \n",
            "\n",
            "2020-05-15 08:53:44 (9.07 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d.bz2’ saved [167917510/167917510]\n",
            "\n",
            "--2020-05-15 08:53:54--  https://lang.org.ua/static/downloads/models/news.lowercased.lemmatized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 164041435 (156M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/news.lowercased.lemmatized.word2vec.300d.bz2’\n",
            "\n",
            "news.lowercased.lem 100%[===================>] 156.44M  10.0MB/s    in 18s     \n",
            "\n",
            "2020-05-15 08:54:14 (8.66 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/news.lowercased.lemmatized.word2vec.300d.bz2’ saved [164041435/164041435]\n",
            "\n",
            "bzip2: Output file /content/drive/My Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d already exists.\n",
            "bzip2: Output file /content/drive/My Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PP_s5xVgzlc",
        "colab_type": "text"
      },
      "source": [
        "### Downloading **ubercorpus** to GDrive (once)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1B7f8khBDr",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "https://lang.org.ua/static/downloads/models/ubercorpus.cased.tokenized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.tokenized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/ubercorpus.cased.lemmatized.word2vec.300d.bz2\n",
        "\n",
        "https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErzD1O8uiXuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "2ef68ac2-695c-4fb6-8b14-0a751ddc8975"
      },
      "source": [
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/ubercorpus.cased.tokenized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.tokenized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/ubercorpus.cased.lemmatized.word2vec.300d.bz2\n",
        "!wget -P '/content/drive/My Drive/Colab/homework-10/' https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2\n",
        "\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.tokenized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.tokenized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.lemmatized.word2vec.300d.bz2'\n",
        "!bzip2 -d '/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2'\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-15 08:57:33--  https://lang.org.ua/static/downloads/models/ubercorpus.cased.tokenized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 555203899 (529M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.tokenized.word2vec.300d.bz2’\n",
            "\n",
            "ubercorpus.cased.to 100%[===================>] 529.48M  10.1MB/s    in 55s     \n",
            "\n",
            "2020-05-15 08:58:30 (9.69 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.tokenized.word2vec.300d.bz2’ saved [555203899/555203899]\n",
            "\n",
            "--2020-05-15 08:58:31--  https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.tokenized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 502679218 (479M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.tokenized.word2vec.300d.bz2’\n",
            "\n",
            "ubercorpus.lowercas 100%[===================>] 479.39M  10.2MB/s    in 50s     \n",
            "\n",
            "2020-05-15 08:59:23 (9.56 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.tokenized.word2vec.300d.bz2’ saved [502679218/502679218]\n",
            "\n",
            "--2020-05-15 08:59:24--  https://lang.org.ua/static/downloads/models/ubercorpus.cased.lemmatized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 308316382 (294M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.lemmatized.word2vec.300d.bz2’\n",
            "\n",
            "ubercorpus.cased.le 100%[===================>] 294.03M  10.2MB/s    in 32s     \n",
            "\n",
            "2020-05-15 08:59:58 (9.32 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.lemmatized.word2vec.300d.bz2’ saved [308316382/308316382]\n",
            "\n",
            "--2020-05-15 09:00:00--  https://lang.org.ua/static/downloads/models/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2\n",
            "Resolving lang.org.ua (lang.org.ua)... 95.216.74.77\n",
            "Connecting to lang.org.ua (lang.org.ua)|95.216.74.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 302005067 (288M) [application/octet-stream]\n",
            "Saving to: ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2’\n",
            "\n",
            "ubercorpus.lowercas 100%[===================>] 288.01M  10.3MB/s    in 30s     \n",
            "\n",
            "2020-05-15 09:00:32 (9.49 MB/s) - ‘/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d.bz2’ saved [302005067/302005067]\n",
            "\n",
            "bzip2: Output file /content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5qAC84Om1Hs",
        "colab_type": "text"
      },
      "source": [
        "## Initializing models on GDrive (once)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYh7LjC6nIvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "758f9767-6d7b-4fc5-9bd2-bdf72d132fdb"
      },
      "source": [
        "!rm -r '/content/drive/My Drive/Colab/homework-10/vec_models'\n",
        "!mkdir '/content/drive/My Drive/Colab/homework-10/vec_models'\n",
        "\n",
        "# news.cased.tokenized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/news.cased.tokenized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d'\n",
        "# news.lowercased.tokenized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/news.lowercased.tokenized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/news.lowercased.tokenized.word2vec.300d'\n",
        "# news.cased.lemmatized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/news.cased.lemmatized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d'\n",
        "# news.lowercased.lemmatized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/news.lowercased.lemmatized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/news.lowercased.lemmatized.word2vec.300d'\n",
        "\n",
        "# ubercorpus.cased.tokenized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/ubercorpus.cased.tokenized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.tokenized.word2vec.300d'\n",
        "# ubercorpus.lowercased.tokenized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/ubercorpus.lowercased.tokenized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.tokenized.word2vec.300d'\n",
        "# ubercorpus.cased.lemmatized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/ubercorpus.cased.lemmatized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/ubercorpus.cased.lemmatized.word2vec.300d'\n",
        "# ubercorpus.lowercased.lemmatized.word2vec.300d\n",
        "!python -m spacy init-model uk '/content/drive/My Drive/Colab/homework-10/vec_models/ubercorpus.lowercased.lemmatized.word2vec.300d' --vectors-loc '/content/drive/My Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d'\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "365319it [00:38, 9528.11it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/news.cased.tokenized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "365495 entries, 365319 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "328958it [00:35, 9198.26it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/news.lowercased.tokenized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "329134 entries, 328958 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "178460it [00:19, 9054.59it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/news.cased.lemmatized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "178636 entries, 178460 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "174311it [00:19, 9101.24it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/news.lowercased.lemmatized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "174487 entries, 174311 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "595119it [01:01, 9674.14it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/ubercorpus.cased.tokenized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "595290 entries, 595119 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "538431it [01:00, 8870.88it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/ubercorpus.lowercased.tokenized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "538605 entries, 538431 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "331944it [00:39, 8307.24it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/ubercorpus.cased.lemmatized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "332115 entries, 331944 vectors\n",
            "\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "325250it [00:36, 8891.88it/s] \n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from /content/drive/My\n",
            "Drive/Colab/homework-10/ubercorpus.lowercased.lemmatized.word2vec.300d\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "325424 entries, 325250 vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcVgFQPqle7c",
        "colab_type": "text"
      },
      "source": [
        "## Installing pymorphy (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-gigYGcjufa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "3e1b433f-0c7f-4de5-89b3-9eed7dd06365"
      },
      "source": [
        "!pip uninstall pymorphy2-dicts-uk -y\n",
        "!pip uninstall pymorphy2 -y\n",
        "!pip install git+https://github.com/kmike/pymorphy2.git \n",
        "!pip install pymorphy2-dicts-uk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling pymorphy2-dicts-uk-2.4.1.1.1460299261:\n",
            "  Successfully uninstalled pymorphy2-dicts-uk-2.4.1.1.1460299261\n",
            "Uninstalling pymorphy2-0.8:\n",
            "  Successfully uninstalled pymorphy2-0.8\n",
            "Collecting git+https://github.com/kmike/pymorphy2.git\n",
            "  Cloning https://github.com/kmike/pymorphy2.git to /tmp/pip-req-build-pp19282g\n",
            "  Running command git clone -q https://github.com/kmike/pymorphy2.git /tmp/pip-req-build-pp19282g\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8) (2.4.404381.4453942)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8) (0.6.2)\n",
            "Building wheels for collected packages: pymorphy2\n",
            "  Building wheel for pymorphy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymorphy2: filename=pymorphy2-0.8-cp36-none-any.whl size=54982 sha256=984f0976610fb1facf22b82c6d5a66114e20814d0dd7be70409ff7a4adc0c251\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ma2oixg7/wheels/0f/c8/2e/9d912793948be59c5fdd670697fe29a3bd1882eaa268eba90d\n",
            "Successfully built pymorphy2\n",
            "Installing collected packages: pymorphy2\n",
            "Successfully installed pymorphy2-0.8\n",
            "Collecting pymorphy2-dicts-uk\n",
            "  Using cached https://files.pythonhosted.org/packages/37/af/3ac5e9f1d9c31c934beeea852d3af743da561713b03470316f997a5938e1/pymorphy2_dicts_uk-2.4.1.1.1460299261-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts-uk\n",
            "Successfully installed pymorphy2-dicts-uk-2.4.1.1.1460299261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULpS27_EtHxY",
        "colab_type": "text"
      },
      "source": [
        "### Testing if pymorphy models work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIa7JDFCteoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "751e8c73-8439-4163-e463-d4c8dea862dd"
      },
      "source": [
        "import spacy\n",
        "news_cased_tokenized_model = spacy.load(news_cased_tokenized_word2vec_300d_path)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W019] Changing vectors name from uk_model.vectors to uk_model.vectors_365319, to avoid clash with previously loaded vectors. See Issue #3853.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfPu6JG6zXCd",
        "colab_type": "code",
        "outputId": "5353937a-769b-4ddd-b8f0-03c28990c120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "w1 = news_cased_tokenized_model('кіт')\n",
        "w2 = news_cased_tokenized_model('собака')\n",
        "print(w1.similarity(w2))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7224378959711921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iKDhKIfyT6p",
        "colab_type": "text"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5-TR8rGvSCJ",
        "colab_type": "text"
      },
      "source": [
        "## Doc2Vec (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agHZDsININwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_without_stopwords(text, model):\n",
        "    words = model(text)\n",
        "    filtered_words = []\n",
        "\n",
        "    for w in words:\n",
        "      if w not in spacy.lang.uk.stop_words.STOP_WORDS:\n",
        "        filtered_words.append(w.text)\n",
        "\n",
        "    words = model(' '.join(filtered_words))\n",
        "    return words.vector\n",
        "\n",
        "def vectorize_with_stopwords(text, model):\n",
        "    words = model(text)\n",
        "    return words.vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvgadytcuOZ6",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data in memory (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXHXyDfNzl71",
        "colab_type": "code",
        "outputId": "b9c57354-0b92-4b71-de4e-8badc857c35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import gzip\n",
        "import json\n",
        "import glob\n",
        "\n",
        "import time\n",
        "\n",
        "def read_file(f):\n",
        "    with gzip.open(f, 'rt', encoding='utf-8') as inf:\n",
        "        j = json.load(inf)\n",
        "        return j[0]\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "data = []\n",
        "files = []\n",
        "\n",
        "for f in glob.glob(DATA_1551_PATH+'*/*'):\n",
        "  files.append(f)\n",
        "\n",
        "print('Files count', len(files))\n",
        "counter = 0\n",
        "for file in files:\n",
        "  data.append(read_file(file))\n",
        "  counter+=1\n",
        "  if counter%100 ==0:\n",
        "    #print (len(files) - counter,'/',len(files))\n",
        "    printProgressBar(counter, len(files), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "\n",
        "printProgressBar(counter, len(files), prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "print()\n",
        "print ('Data loaded:',len(data))\n",
        "\n",
        "end = time.time()\n",
        "print('Time elapsed:', end - start, 'seconds')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files count 127329\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete\n",
            "\n",
            "Data loaded: 127329\n",
            "Time elapsed: 28.41733145713806 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eg2gzBYxc3m",
        "colab_type": "text"
      },
      "source": [
        "## Selecting a subset of data for fest processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OKXPw4sxtRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_id = {}\n",
        "\n",
        "def get_top_categories (n_categories):\n",
        "  categories_count = {}\n",
        "  counter = 0\n",
        "\n",
        "  for data_item in data:\n",
        "    if data_item['CallZType'] not in categories_count:\n",
        "      categories_count[data_item['CallZType']] = 0\n",
        "      category_id[data_item['CallZType']] = counter\n",
        "      counter+=1\n",
        "    categories_count[data_item['CallZType']]+=1\n",
        "\n",
        "\n",
        "  def takeSecond(elem):\n",
        "      return elem[1]\n",
        "\n",
        "\n",
        "  category_statistics = []\n",
        "\n",
        "  for category in categories_count:\n",
        "    category_statistics.append((category, categories_count[category]))\n",
        "\n",
        "  category_statistics.sort(key=takeSecond, reverse=True)\n",
        "\n",
        "  selected_categories = {}\n",
        "\n",
        "  for category in category_statistics[:n_categories]:\n",
        "      selected_categories[category[0]] = []\n",
        "\n",
        "  for data_item in data:\n",
        "      if data_item['CallZType'] in selected_categories:\n",
        "          selected_categories[data_item['CallZType']].append(data_item['CallZText'])\n",
        "  \n",
        "  return selected_categories\n",
        "\n",
        "filtered_data = get_top_categories(10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7CYZ-tAjH6Y",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the small corpus (runtime)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AODrMycfGBf0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87d0ec59-6cbc-4d80-cfa9-d9332048b893"
      },
      "source": [
        "def get_vectorized_data(source_data, vectorizer, model):\n",
        "\n",
        "  features = []\n",
        "  labels = []\n",
        "\n",
        "  for category in source_data:\n",
        "    for data_item in source_data[category]:\n",
        "      vectorized_data = vectorizer(data_item, model)\n",
        "      if vectorized_data is not None:\n",
        "        features.append(vectorized_data)\n",
        "        labels.append(category_id[category])\n",
        "\n",
        "  return features, labels"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44895 44895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9-UQu_lu4s4",
        "colab_type": "text"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9dxQXZAMJJI",
        "colab_type": "text"
      },
      "source": [
        "This is a prettified version of our classroom baseline KNeighborsClassifier is rather slow and it does not provide any verbose output. It is not quite fun to play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsskq1fXKIGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b3954556-623e-4904-ebb5-2d8c160a023f"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "filtered_data = get_top_categories(10)\n",
        "\n",
        "X, y = get_vectorized_data(filtered_data, vectorizer = vectorize_with_stopwords, model = news_cased_tokenized_model)\n",
        "\n",
        "print (len(X), len(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "neighbors = KNeighborsClassifier(n_neighbors=3, n_jobs = -1)\n",
        "neighbors.fit(np.array(X_train), np.array(y_train))\n",
        "\n",
        "y_pred = neighbors.predict(X_test)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "print()\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44895 44895\n",
            "Accuracy: 0.562702483801296\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.58      0.82      0.68      4450\n",
            "           3       0.48      0.49      0.49      1071\n",
            "           4       0.43      0.43      0.43       761\n",
            "           7       0.57      0.47      0.52      1946\n",
            "          15       0.37      0.32      0.34       714\n",
            "          16       0.58      0.48      0.53      2155\n",
            "          18       0.63      0.58      0.60      1190\n",
            "          23       0.43      0.26      0.33       820\n",
            "          46       0.71      0.42      0.53       857\n",
            "          57       0.69      0.43      0.53       852\n",
            "\n",
            "    accuracy                           0.56     14816\n",
            "   macro avg       0.55      0.47      0.50     14816\n",
            "weighted avg       0.56      0.56      0.55     14816\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fkGw0RHM4Az",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 1 (MLPClassifier + GridSearchCV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLHVs6TaMfOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7e66961-35ba-40a9-f53b-72ce26e7afbe"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "filtered_data = get_top_categories(10)\n",
        "\n",
        "X, y = get_vectorized_data(filtered_data, vectorizer = vectorize_with_stopwords, model = news_cased_tokenized_model)\n",
        "\n",
        "print (len(X), len(y))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "parameters = {'solver': ['lbfgs'], 'max_iter': [300,400,500], 'alpha': 10.0 ** -np.arange(1, 5), 'hidden_layer_sizes':np.arange(10, 15)}\n",
        "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, verbose = 100)\n",
        "clf.fit(np.array(X_train), np.array(y_train))\n",
        "\n",
        "print(clf.score(X_train, y_train))\n",
        "print(clf.best_params_)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "print()\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44895 44895\n",
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.1min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.2min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24064,), dtype=int64).\n",
            "Pickling array (shape=(6015,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.2min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.3min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  3.2min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  3.7min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  4.6min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24064,), dtype=int64).\n",
            "Pickling array (shape=(6015,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  5.2min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  6.0min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  6.7min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  7.8min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24063,), dtype=int64).\n",
            "Pickling array (shape=(6016,), dtype=int64).\n",
            "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  8.5min\n",
            "Memmapping (shape=(30079, 300), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_390_1568765816/390-139852888724144-a0cdaac5b8e84678b01201776a4044f5.pkl\n",
            "Pickling array (shape=(30079,), dtype=int64).\n",
            "Pickling array (shape=(24064,), dtype=int64).\n",
            "Pickling array (shape=(6015,), dtype=int64).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j06tgEIwOu93",
        "colab_type": "text"
      },
      "source": [
        "# Iteration 2 (no stop words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLVwvfw2xwUR",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHTXjIlGOA_e",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO8iu7s-ODAp",
        "colab_type": "text"
      },
      "source": [
        "1. I've learned how to use MLPClassifier, GridSearchCV, and KNeighborsClassifier\n",
        "2. I've used various pre-trained Word2Vec models\n",
        "3. I've learned how to use TSNE for data visualization "
      ]
    }
  ]
}