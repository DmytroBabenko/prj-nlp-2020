{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTRIBUTING.md  LICENSE.txt  stats.xml\t\t   uk_iu-ud-test.conllu\n",
      "eval.log\t README.md    uk_iu-ud-dev.conllu  uk_iu-ud-train.conllu\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../UD_Ukrainian-IU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../../../UD_Ukrainian-IU/'\n",
    "train_filename = PATH + 'uk_iu-ud-train.conllu'\n",
    "dev_filename = PATH + 'uk_iu-ud-dev.conllu'\n",
    "test_filename = PATH + 'uk_iu-ud-test.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', 1), ('form', 'У'), ('lemma', 'у'), ('upostag', 'ADP'), ('xpostag', 'Spsl'), ('feats', OrderedDict([('Case', 'Loc')])), ('head', 2), ('deprel', 'case'), ('deps', [('case', 2)]), ('misc', OrderedDict([('Id', '0003'), ('LTranslit', 'u'), ('Translit', 'U')]))])\n",
      "У <-- домі\n",
      "домі <-- була\n",
      "римського <-- патриція\n",
      "патриція <-- домі\n",
      "Руфіна <-- патриція\n",
      "була <-- root\n",
      "прегарна <-- фреска\n",
      "фреска <-- була\n",
      ", <-- зображення\n",
      "зображення <-- фреска\n",
      "Венери <-- зображення\n",
      "та <-- Адоніса\n",
      "Адоніса <-- Венери\n",
      ". <-- була\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "\n",
    "with open(train_filename) as f:\n",
    "    data = f.read()\n",
    "\n",
    "trees = parse(data)\n",
    "tree = trees[0]\n",
    "print(tree[0])\n",
    "\n",
    "for node in tree:\n",
    "    head = node[\"head\"]\n",
    "    print(\"{} <-- {}\".format(node[\"form\"],\n",
    "                             tree[head - 1][\"form\"]\n",
    "                             if head > 0 else \"root\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>],\n",
       " [(1, 2),\n",
       "  (3, 4),\n",
       "  (4, 2),\n",
       "  (5, 4),\n",
       "  (2, 6),\n",
       "  (6, 0),\n",
       "  (7, 8),\n",
       "  (8, 6),\n",
       "  (9, 10),\n",
       "  (10, 8),\n",
       "  (11, 10),\n",
       "  (12, 13),\n",
       "  (13, 11),\n",
       "  (14, 6)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "\n",
    "def oracle(stack, queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    top_queue = queue[0]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT\n",
    "\n",
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_actions(tree):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    actions = []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue if len(queue) > 0 else [None],\n",
    "                        relations)\n",
    "        actions.append(action)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return actions, relations\n",
    "\n",
    "trace_actions(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(stack, queue):\n",
    "    features = {}\n",
    "    if stack:\n",
    "        stack_elem = stack[-1]\n",
    "        features['s0_word'] = stack_elem['form']\n",
    "        features['s0_lemma'] = stack_elem['lemma']\n",
    "        features['s0_tag'] = stack_elem['upostag']\n",
    "    if len(stack) > 1:\n",
    "        stack_elem = stack[-2]\n",
    "        features['s1_tag'] = stack_elem['upostag']\n",
    "    if queue:\n",
    "        queue_elem = queue[0]\n",
    "        features['q0_word'] = queue_elem['form']\n",
    "        features['q0_lemma'] = queue_elem['lemma']\n",
    "        features['q0_tag'] = queue_elem['upostag']\n",
    "    if len(queue) > 1:\n",
    "        queue_elem = queue[1]\n",
    "        features['q1_word'] = queue_elem['form']\n",
    "        features['q1_tag'] = queue_elem['upostag']\n",
    "    if len(queue) > 2:\n",
    "        queue_elem = queue[2]\n",
    "        features['q2_tag'] = queue_elem['upostag']\n",
    "    if len(queue) > 3:\n",
    "        queue_elem = queue[3]\n",
    "        features['q3_tag'] = queue_elem['upostag']\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190298, 190298)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_data(tree, feature_extractor, oracle):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    labels = []\n",
    "    features = []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue if len(queue) > 0 else [None],\n",
    "                        relations)\n",
    "        features.append(feature_extractor(stack, queue))\n",
    "        labels.append(action.name.lower())\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels\n",
    "\n",
    "train_labels = []\n",
    "train_features = []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t['id']) == int], extract_features, oracle)\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "len(train_labels), len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25820, 25820)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(dev_filename) as f:\n",
    "    data = f.read()\n",
    "\n",
    "test_trees = parse(data)\n",
    "\n",
    "test_labels = []\n",
    "test_features = []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t['id']) == int], extract_features, oracle)\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "len(test_labels), len(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  111126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "print(\"Total number of features: \", len(vec.get_feature_names()))\n",
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.86      0.87      0.86      6371\n",
      "      reduce       0.85      0.78      0.81      6875\n",
      "       right       0.75      0.79      0.77      5996\n",
      "       shift       0.85      0.87      0.86      6578\n",
      "\n",
      "    accuracy                           0.83     25820\n",
      "   macro avg       0.83      0.83      0.83     25820\n",
      "weighted avg       0.83      0.83      0.83     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr = LogisticRegression(random_state=1, solver='sag', multi_class=\"multinomial\", max_iter=1000, n_jobs=-1)\n",
    "lr.fit(train_features_vectorized, train_labels)\n",
    "y_pred = lr.predict(test_features_vectorized)\n",
    "\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['right',\n",
       " 'right',\n",
       " 'shift',\n",
       " 'shift',\n",
       " 'shift',\n",
       " 'left',\n",
       " 'left',\n",
       " 'shift',\n",
       " 'reduce',\n",
       " 'reduce',\n",
       " 'left',\n",
       " 'left',\n",
       " 'right',\n",
       " 'shift',\n",
       " 'left',\n",
       " 'right',\n",
       " 'reduce',\n",
       " 'right',\n",
       " 'reduce',\n",
       " 'reduce',\n",
       " 'reduce']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = test_trees[0]\n",
    "tree_features, tree_labels = get_data([t for t in tree if type(t['id']) == int], extract_features, oracle)\n",
    "tree_features_vectorized = vec.transform(tree_features)\n",
    "y_pred = lr.predict(tree_features_vectorized)\n",
    "list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correct: 8717\n"
     ]
    }
   ],
   "source": [
    "def build_relations(tree, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while (queue or stack):\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        features = extract_features(stack, queue)\n",
    "        action = model.predict(vectorizer.transform(features))[0]\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action:\", action)\n",
    "    return sorted(relations)\n",
    "\n",
    "total, tp = 0, 0\n",
    "for i, tree in enumerate(test_trees):\n",
    "    tree2 = [t for t in tree if type(t['id']) == int]\n",
    "    golden = [(node['id'], node['head']) for node in tree2]\n",
    "    try:\n",
    "        predicted = build_relations(tree2, lr, vec)\n",
    "    except:\n",
    "        print(i, [t['id'] for t in tree2])\n",
    "        raise\n",
    "    total += len(tree2)\n",
    "    tp += len(set(predicted).intersection(set(golden)))\n",
    "\n",
    "print('Total: {}'.format(total))\n",
    "print('Correct: {}'.format(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try to improve features\n",
    "\n",
    "According to https://books.google.com.ua/books?id=k3iiup7HB9UC&pg=PA31&lpg=PA31&dq=typical+feature+model+of+transition+based+parsing&source=bl&ots=z9QdIRGfz_&sig=ACfU3U1TvLWCgAL0PGu5plpoi09iTHyJ6w&hl=uk&sa=X&ved=2ahUKEwjLr_mM7ZLpAhUIuIsKHYw5Dp0Q6AEwAXoECAoQAQ#v=onepage&q&f=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_right_deps(element):\n",
    "    elem_id = element['id']\n",
    "    if type(elem_id) == tuple:\n",
    "        elem_id = elem_id[0] + 0.1 * elem_id[-1]\n",
    "\n",
    "    left_deps, right_deps = [], []\n",
    "    for dep in (element['deps'] or []):\n",
    "        dep_id = dep[1]\n",
    "        if type(dep_id) == tuple:\n",
    "            dep_id = dep_id[0] + 0.1 * dep_id[-1]\n",
    "        if dep_id > elem_id:\n",
    "            right_deps.append((dep, dep_id))\n",
    "        else:\n",
    "            left_deps.append((dep, dep_id))\n",
    "    leftmost_dep = None\n",
    "    rightmost_dep = None\n",
    "    if left_deps:\n",
    "        leftmost_dep = list(sorted(left_deps, key=lambda x:x[1]))[0]\n",
    "    if right_deps:\n",
    "        rightmost_dep = list(sorted(right_deps, key=lambda x:x[1], reverse=True))[0]\n",
    "    return leftmost_dep, rightmost_dep\n",
    "\n",
    "def extract_more_features(stack, queue):\n",
    "    features = {}\n",
    "    if stack:\n",
    "        stack_elem = stack[-1]\n",
    "        features['s0_word'] = stack_elem['form']\n",
    "        features['s0_lemma'] = stack_elem['lemma']\n",
    "        features['s0_tag'] = stack_elem['upostag']\n",
    "        leftmost_dep, rightmost_dep = get_left_right_deps(stack_elem)\n",
    "        if leftmost_dep:\n",
    "            features['ldep_s0_deprel'] = leftmost_dep[0][0]\n",
    "        if rightmost_dep:\n",
    "            features['rdep_s0_deprel'] = rightmost_dep[0][0]\n",
    "    if len(stack) > 1:\n",
    "        stack_elem = stack[-2]\n",
    "        features['s1_tag'] = stack_elem['upostag']\n",
    "        leftmost_dep, rightmost_dep = get_left_right_deps(stack_elem)\n",
    "        if leftmost_dep:\n",
    "            features['ldep_s1_deprel'] = leftmost_dep[0][0]\n",
    "        if rightmost_dep:\n",
    "            features['rdep_s1_deprel'] = rightmost_dep[0][0]\n",
    "    if queue:\n",
    "        queue_elem = queue[0]\n",
    "        features['q0_word'] = queue_elem['form']\n",
    "        features['q0_lemma'] = queue_elem['lemma']\n",
    "        features['q0_tag'] = queue_elem['upostag']\n",
    "        leftmost_dep, rightmost_dep = get_left_right_deps(stack_elem)\n",
    "        if leftmost_dep:\n",
    "            features['ldep_q0_deprel'] = leftmost_dep[0][0]\n",
    "        if rightmost_dep:\n",
    "            features['rdep_q0_deprel'] = rightmost_dep[0][0]\n",
    "    if len(queue) > 1:\n",
    "        queue_elem = queue[1]\n",
    "        features['q1_word'] = queue_elem['form']\n",
    "        features['q1_tag'] = queue_elem['upostag']\n",
    "        leftmost_dep, rightmost_dep = get_left_right_deps(queue_elem)\n",
    "        if leftmost_dep:\n",
    "            features['ldep_q1_deprel'] = leftmost_dep[0][0]\n",
    "        if rightmost_dep:\n",
    "            features['rdep_q1_deprel'] = rightmost_dep[0][0]\n",
    "    if len(queue) > 2:\n",
    "        queue_elem = queue[2]\n",
    "        features['q2_tag'] = queue_elem['upostag']\n",
    "    if len(queue) > 3:\n",
    "        queue_elem = queue[3]\n",
    "        features['q3_tag'] = queue_elem['upostag']\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels & features: 190298 190298\n",
      "Test labels & features: 25820 25820\n"
     ]
    }
   ],
   "source": [
    "train_labels = []\n",
    "train_features = []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t['id']) == int], extract_more_features, oracle)\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print('Train labels & features:', len(train_labels), len(train_features))\n",
    "\n",
    "with open(dev_filename) as f:\n",
    "    data = f.read()\n",
    "\n",
    "test_trees = parse(data)\n",
    "\n",
    "test_labels = []\n",
    "test_features = []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t['id']) == int], extract_more_features, oracle)\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print('Test labels & features:', len(test_labels), len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features:  111523\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "print(\"Total number of features: \", len(vec.get_feature_names()))\n",
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.94      0.95      0.94      6371\n",
      "      reduce       0.90      0.85      0.88      6875\n",
      "       right       0.80      0.83      0.82      5996\n",
      "       shift       0.87      0.87      0.87      6578\n",
      "\n",
      "    accuracy                           0.88     25820\n",
      "   macro avg       0.88      0.88      0.88     25820\n",
      "weighted avg       0.88      0.88      0.88     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lrf = LogisticRegression(random_state=1, solver='sag', multi_class=\"multinomial\", max_iter=1000, n_jobs=-1)\n",
    "lrf.fit(train_features_vectorized, train_labels)\n",
    "y_pred = lrf.predict(test_features_vectorized)\n",
    "\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correct: 9735\n"
     ]
    }
   ],
   "source": [
    "def build_relations(tree, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while (queue or stack):\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        features = extract_more_features(stack, queue)\n",
    "        action = model.predict(vectorizer.transform(features))[0]\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action:\", action)\n",
    "    return sorted(relations)\n",
    "\n",
    "total, tp = 0, 0\n",
    "for i, tree in enumerate(test_trees):\n",
    "    tree2 = [t for t in tree if type(t['id']) == int]\n",
    "    golden = [(node['id'], node['head']) for node in tree2]\n",
    "    try:\n",
    "        predicted = build_relations(tree2, lrf, vec)\n",
    "    except Exception as e:\n",
    "        print(i, [t['id'] for t in tree2])\n",
    "        raise\n",
    "    total += len(tree2)\n",
    "    tp += len(set(predicted).intersection(set(golden)))\n",
    "\n",
    "print('Total: {}'.format(total))\n",
    "print('Correct: {}'.format(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try XGBoost (just a basic one w/o meta arguments optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.94      0.96      0.95      6371\n",
      "      reduce       0.93      0.85      0.89      6875\n",
      "       right       0.82      0.88      0.85      5996\n",
      "       shift       0.89      0.89      0.89      6578\n",
      "\n",
      "    accuracy                           0.89     25820\n",
      "   macro avg       0.89      0.89      0.89     25820\n",
      "weighted avg       0.90      0.89      0.89     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(random_state=42, n_estimators=1000, n_jobs=-1)\n",
    "model.fit(train_features_vectorized, train_labels)\n",
    "test_pred = model.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total, tp = 0, 0\n",
    "for i, tree in enumerate(test_trees):\n",
    "    tree2 = [t for t in tree if type(t['id']) == int]\n",
    "    golden = [(node['id'], node['head']) for node in tree2]\n",
    "    try:\n",
    "        predicted = build_relations(tree2, model, vec)\n",
    "    except Exception as e:\n",
    "        print(i, [t['id'] for t in tree2])\n",
    "        raise\n",
    "    total += len(tree2)\n",
    "    tp += len(set(predicted).intersection(set(golden)))\n",
    "\n",
    "print('Total: {}'.format(total))\n",
    "print('Correct: {}'.format(tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "works for ages......\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just Anything Else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<Actions.SHIFT: 'shift'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.SHIFT: 'shift'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.LEFT: 'left'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.RIGHT: 'right'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>,\n",
       "  <Actions.REDUCE: 'reduce'>],\n",
       " [(2, 3),\n",
       "  (1, 3),\n",
       "  (5, 4),\n",
       "  (4, 6),\n",
       "  (7, 8),\n",
       "  (6, 8),\n",
       "  (3, 8),\n",
       "  (8, 0),\n",
       "  (9, 8),\n",
       "  (11, 12),\n",
       "  (10, 12),\n",
       "  (12, 8),\n",
       "  (13, 12),\n",
       "  (14, 8)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "    RIGHT2 = \"right2\"\n",
    "\n",
    "def adhoc_oracle(stack, queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    top_queue = queue[0]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    elif len(queue) > 1 and queue[1][\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT2\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT\n",
    "\n",
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def trace_adhoc_actions(tree):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    actions = []\n",
    "    while queue or stack:\n",
    "        action = adhoc_oracle(stack if len(stack) > 0 else None,\n",
    "                        queue if len(queue) > 0 else [None],\n",
    "                        relations)\n",
    "        actions.append(action)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.RIGHT2:\n",
    "            relations.append((queue[1][\"id\"], stack[0][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return actions, relations\n",
    "\n",
    "trace_adhoc_actions(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels & features: 190298 190298\n",
      "Test labels & features: 25820 25820\n"
     ]
    }
   ],
   "source": [
    "def get_data_adhoc(tree, feature_extractor, oracle):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "    labels = []\n",
    "    features = []\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue if len(queue) > 0 else [None],\n",
    "                        relations)\n",
    "        features.append(feature_extractor(stack, queue))\n",
    "        labels.append(action.name.lower())\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.RIGHT2:\n",
    "            relations.append((queue[1][\"id\"], stack[0][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels\n",
    "\n",
    "train_labels = []\n",
    "train_features = []\n",
    "for tree in trees:\n",
    "    tree_features, tree_labels = get_data_adhoc(\n",
    "        [t for t in tree if type(t['id']) == int], extract_more_features, adhoc_oracle\n",
    "    )\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print('Train labels & features:', len(train_labels), len(train_features))\n",
    "\n",
    "with open(dev_filename) as f:\n",
    "    data = f.read()\n",
    "\n",
    "test_trees = parse(data)\n",
    "\n",
    "test_labels = []\n",
    "test_features = []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data_adhoc([t for t in tree if type(t['id']) == int], extract_more_features, adhoc_oracle)\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print('Test labels & features:', len(test_labels), len(test_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.93      0.95      0.94      6371\n",
      "      reduce       0.90      0.86      0.88      6875\n",
      "       right       0.80      0.84      0.82      5996\n",
      "      right2       0.81      0.84      0.82      1265\n",
      "       shift       0.83      0.81      0.82      5313\n",
      "\n",
      "    accuracy                           0.86     25820\n",
      "   macro avg       0.85      0.86      0.86     25820\n",
      "weighted avg       0.87      0.86      0.86     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrf = LogisticRegression(random_state=1, solver='sag', multi_class=\"multinomial\", max_iter=1000, n_jobs=-1)\n",
    "lrf.fit(train_features_vectorized, train_labels)\n",
    "y_pred = lrf.predict(test_features_vectorized)\n",
    "\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correct: 9771\n",
      "LAS: 0.7770796882455862\n"
     ]
    }
   ],
   "source": [
    "def build_adhoc_relations(tree, model, vectorizer):\n",
    "    \"\"\"\n",
    "    Try out the oracle to verify it's returning the right actions.\n",
    "    \"\"\"\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while (queue or stack):\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "            continue\n",
    "\n",
    "        features = extract_more_features(stack, queue)\n",
    "        action = model.predict(vectorizer.transform(features))[0]\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.RIGHT2:\n",
    "            relations.append((queue[1][\"id\"], stack[0][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action:\", action)\n",
    "    return sorted(relations)\n",
    "\n",
    "\n",
    "total, tp = 0, 0\n",
    "for i, tree in enumerate(test_trees):\n",
    "    tree2 = [t for t in tree if type(t['id']) == int]\n",
    "    golden = [(node['id'], node['head']) for node in tree2]\n",
    "    try:\n",
    "        predicted = build_adhoc_relations(tree2, lrf, vec)\n",
    "    except Exception as e:\n",
    "        print(i, [t['id'] for t in tree2])\n",
    "        raise\n",
    "    total += len(tree2)\n",
    "    tp += len(set(predicted).intersection(set(golden)))\n",
    "\n",
    "print('Total: {}'.format(total))\n",
    "print('Correct: {}'.format(tp))\n",
    "print('LAS: {}'.format(tp/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Перевірка на нових даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import tokenize_uk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang='uk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "DET = ['будь-який', 'ваш', 'ввесь', 'весь', 'все', 'всенький', 'всякий',\n",
    "       'всілякий', 'деякий', 'другий', 'жадний', 'жодний', 'ин.', 'ін.',\n",
    "       'інакший', 'інш.', 'інший', 'їх', 'їхній', 'її', 'його', 'кожний',\n",
    "       'кожній', 'котрий', 'котрийсь', 'кілька', 'мій', 'наш', 'небагато',\n",
    "       'ніякий', 'отакий', 'отой', 'оцей', 'сам', 'самий', 'свій', 'сей',\n",
    "       'скільки', 'такий', 'тамтой', 'твій', 'те', 'той', 'увесь', 'усякий',\n",
    "       'усілякий', 'це', 'цей', 'чий', 'чийсь', 'який', 'якийсь']\n",
    "\n",
    "PREP = [\"до\", \"на\"]\n",
    "\n",
    "mapping = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PRED\": \"ADV\", \"PREP\": \"ADP\", \"PRCL\": \"PART\"}\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if \"coord\" in word.tag:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    elif \"PNCT\" in word.tag:\n",
    "        return \"PUNCT\"\n",
    "    elif word.normal_form in PREP:\n",
    "        return \"PREP\"\n",
    "    elif word.normal_form in DET:\n",
    "        return \"DET\"\n",
    "    else:\n",
    "        return mapping.get(word.tag.POS, word.tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Не працюй неохоче або без турбот про загальне добро, без належної уважливости або в розсіяності.\n",
      "працюй <- Не\n",
      "ROOT <- працюй\n",
      "працюй <- неохоче\n",
      "загальне <- добро\n",
      "належної <- уважливости\n",
      "розсіяності <- або\n",
      "розсіяності <- в\n",
      "уважливости <- розсіяності\n",
      "працюй <- .\n",
      "Зробивши кілька ковтків, я поглянув на обриси хмар.\n",
      "ROOT <- Зробивши\n",
      "кілька <- ковтків\n",
      "Зробивши <- поглянув\n",
      "обриси <- хмар\n",
      "Зробивши <- .\n",
      "На хвилину маємо перервати історію про студентів і лотерею, тому що, коли ми заговорили про адитивність очікуваної цінності, я не можу не розповісти про одне з найкрасивіших з відомих мені доведень.\n",
      "маємо <- На\n",
      "ROOT <- маємо\n",
      "маємо <- перервати\n",
      "перервати <- історію\n",
      "історію <- про\n",
      "про <- студентів\n",
      "тому <- що\n",
      "ми <- заговорили\n",
      "заговорили <- про\n",
      "про <- адитивність\n",
      "очікуваної <- цінності\n",
      "можу <- не\n",
      "я <- можу\n",
      "розповісти <- не\n",
      "можу <- розповісти\n",
      "розповісти <- про\n",
      "розповісти <- одне\n",
      "відомих <- мені\n",
      "мені <- доведень\n",
      "можу <- .\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "sentences = [\n",
    "    'Не працюй неохоче або без турбот про загальне добро, без належної уважливости або в розсіяності.',\n",
    "    'Зробивши кілька ковтків, я поглянув на обриси хмар.',\n",
    "    'На хвилину маємо перервати історію про студентів і лотерею, тому що, коли ми заговорили про адитивність очікуваної цінності, я не можу не розповісти про одне з найкрасивіших з відомих мені доведень.'\n",
    "]\n",
    "\n",
    "for sentence in sentences:\n",
    "    print(sentence)\n",
    "    parsed_sentence = OrderedDict()\n",
    "    i = 1\n",
    "    for word in tokenize_uk.tokenize_words(sentence):\n",
    "        parsed_word = morph.parse(word)[0]\n",
    "        parsed_sentence[i] = {\n",
    "            'id': i,\n",
    "            'form': word,\n",
    "            'lemma': parsed_word.normal_form,\n",
    "            'upostag': normalize_pos(parsed_word),\n",
    "            'deps': [], # Here our new advanced feature set breaks\n",
    "        }\n",
    "        i += 1\n",
    "    predicted = build_relations(list(parsed_sentence.values()), lrf, vec)\n",
    "    parsed_sentence[0] = {'id': 0, 'form': 'ROOT', 'lemma': 'ROOT'}\n",
    "    for pair in predicted:\n",
    "        from_, to_ = pair\n",
    "        print('{} <- {}'.format(parsed_sentence[to_]['form'], parsed_sentence[from_]['form']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
