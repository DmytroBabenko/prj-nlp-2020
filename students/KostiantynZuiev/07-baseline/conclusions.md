### Посилання на baseline

Код - https://github.com/holdbar/techsup-email-classifier
Поклацати - http://167.99.195.171:8870/

### Про baseline
Я зміг дістати ще листів для мого датасету щоб трохи його збільшити й зробити більш різноманітним\збалансованим.
В даний момент в мене 167 листів(+67 порівняно з початком).
Для побудови базового рішення я переклав їх на англійську скориставшись допомогою волонтерів та googletranslate.
Щоб виділити основні фічі\маркери я зробив мінімальний препроцесинг(прибрав пунктуацію) 
і зібрав частотну статистику по n-граммам(від уні до пента). Код препроцесингу та збору n-грамм відсутній у проєкті,
я це просто швиденько зробив в shell.
Виписавши основні фічі я сформував словник домену розділивши їх на кілька груп:

CRUD_VERBS - сюди входять дієслова, які відображають переважно типові дії(create,read,update,delete) які користувач просить виконати. 
CRUD_WORDS - сюди входять слова які відображають доменні сутності на які направлені CRUD_VERBS, або ж які йдуть з ними у парі в тексті.

Запити сформовані з використанням CRUD_VERBS та CRUD_WORDS зазвичай стосуються змін, що вносяться не дуже массово(через програмний інтерфейс), уточнення простої інформації, додавання нових користувачів, тощо. Ці запити оброблюються першою лінією технічної підтримки(L1). 
Наприклад: 
```
Please send<B-CRUD_VERBS> me my login<B-CRUD_WORDS> and password<B-CRUD_WORDS>.
```
INVESTIGATION_VERBS - сюди входять дієслова, які відображають переважно менш типові запити користувача і говорять про ситуацію яка потребує розбору, додаткової технічної експертизи.
INVESTIGATION_WORDS - сюди входять слова які відображають доменні сутності на які направлені INVESTIGATION_VERBS, або ж які йдуть з ними у парі в тексті.

Запити сформовані з використанням INVESTIGATION_VERBS та INVESTIGATION_WORDS зазвичай пов'язані із массовими змінами, помилками та некорректною роботою програми, стосуються додаткових сервісів(звіти, тестування користувачів) і оброблюються другою лінією технічної підтримки(L2). 

Наприклад:
```
Please fill<B-INVESTIGATION_VERBS> the client<B-CRUD_WORDS> base<I-CRUD_WORDS> of SR<B-CRUD_WORDS> Chekhov from the attached file.
```
Як можна помітити звернення до другої лінії можуть містити довільну кількість маркерів для першої лінії, оскільки серед них є й загальнодоменні. Також наявність хоча б одного маркера для другої лінії домінує і визначає направлення листа, оскільки лист не ділиться на підзавдання і спеціаліст другої лінії в разі чого може виконати завдання першої лінії, а навпаки ні. Так бувають кейси коли в одному листі є одразу два таски і для першої і для другої лінії.

URGENCY_WORDS - слова які говорять про те що цей лист необхідно обробити швидше за інші. Переважно тут містяться слова про повторюваність проблеми, або її давність.

Наприклад:
```
I have a constant<B-URGENCY_WORDS> error<B-INVESTIGATION_WORDS> when I open<B-CRUD_VERBS> the program<B-CRUD_WORDS>.
```
### Висновки. Оцінка якості
На даний момент я ще не робив розділення датасету на train/test оскільки він скоріше за все не достатньо великий для тренування і як я розумію треба спершу його розширити за рахунок семплінгу. Також я ще не провів кількісний аналіз його різноманітності.

На даний момент результат роботи класифікатора виглядає так:
```
Email:

Hello!

I have a constant error when I open the program. Please call me.

Sincerely,
Kostiantyn

Result:

{'line': 'L2', 'is_urgent': 'Yes', 'possible_actions': ['open'], 'possible_objects': ['error'], 'urgency_markers': ['constant']}
```

Тобто класифікатор видає лінію, чи є лист терміновим, а також список дієслівних та інших маркерів які говорять про ймовірні дії та сутності які цікавлять користувача.

Враховуючи що маркери для класифікації другої лінії підтримки не дуже об'ємні та являються домінантними у мене є ідея згрупувати пари дієслів та сутностей у типи звернень які також будуть визначатися класифікатором як імовірний тип звернення. Щоб отримувати більше корисної інформації і трохи ускладнити собі задачу (:

З приводу якості:
я та мій волонтер розмітили датасет вручну за лінією технічної підтримки. Я прогнав свій класифікатор по датасету і отримав рузультат автоматичної розмітки.
Я звірив і порахував помилкові кейси і отримав наступні результати:
Всього листів = 167
Розмічено невірно = 47
Розмічено вірно = 120
Точність = 0,71

Варто зазначити що переважно помилкові результати були через хибну ручну аннотацію (: а також через те що не всі фічі які були виділені при аналізі данних я вніс до своєї БД.
Тобто виправивши помилки еталонної розмітки і доповнивши список фіч до більш актуально можна покращити результат відносно наявного датасету.
Окрім цього для покращення можна спробувати використати лемматизацію(наприклад для дієслів), а також можливо синоніми(зараз використовуються тільки для URGENCY_WORDS).
Також серед ідей для покращення є пошук дати та часу для визначення терміновості, але тут треба корректно підібрати прийменники, щоб не чіпляти хибні результати.

Якщо дорозмітити датасет по типу та всім наявним маркерам, можна буде виміряти якість роботи і з цією додатковою інформацією.