#### Висновки

Я зробив всього 2 покращення: використав feats та спробував інший класифікатор(Decision Tree). 
Я пробував розібратися з імплементацією swap, навіть знайшов відносно зрозумілий пейпер :D (https://www.aclweb.org/anthology/W17-6313.pdf),
але все ж не зміг імплементувати його.
Вибір іншого класифікатора в цілому дав більш суттєве покращення ніж використання feats. І разом з цим при зміні класифікатора
я стикнувся з тим що оракул пропонує операцію REDUCE на порожньому стеку при повній черзі. Через це довелося модифікувати функцію яка застосовує оракул
при підрахунку UAS, щоб скіпнути такі кейси. Наскільки я зрозумів таким чином у мене мала збільшитися доля нерозібраних зовсім або розібраних не до кінця дерев,
але при цьому мої показники зросли. Ймовірно при цьому суттєво зросла якість розбору інших дерев, що переважило ці втрати. Хоча скоріше я щось зробив не так,
бо зрозуміти причини такої поведінки оракула мені так і не вдалося.
Загалом на тестових даних з корпусу decision tree показав себе трохи краще за логістичну регресію.

На моїх власних реченнях ситуація вийшла ще цікавіша, бо згаданий вище кейс з хибними пророцтвами виліз і на класифікаторі на базі логістичної регресії.
Є підозра що справа в даних і я чогось не зрозумів ):
При цьому на мій суб'єктивний погляд класифікатор на базі логістичної регресії дав кращі результати ніж класифікатор на базі дерева прийняття рішень.
Хоча загалом обидва видали недорозібрані дерева (:



#### Start data
Total number of features:  111126
              precision    recall  f1-score   support

        left       0.86      0.87      0.86      6371
      reduce       0.85      0.78      0.81      6875
       right       0.75      0.79      0.77      5996
       shift       0.85      0.87      0.86      6578

    accuracy                           0.83     25820
   macro avg       0.83      0.83      0.83     25820
weighted avg       0.83      0.83      0.83     25820

Total: 12574
Correctly defined: 8717
UAS: 0.69
Full match: 0.09


#### Add feats
Total number of features:  111327
              precision    recall  f1-score   support

        left       0.86      0.88      0.87      6371
      reduce       0.86      0.80      0.83      6875
       right       0.77      0.81      0.79      5996
       shift       0.86      0.87      0.87      6578

    accuracy                           0.84     25820
   macro avg       0.84      0.84      0.84     25820
weighted avg       0.84      0.84      0.84     25820

Total: 12574
Correctly defined: 8921
UAS: 0.71
Full match: 0.1

#### Other classifier - Decision Tree
              precision    recall  f1-score   support

        left       0.89      0.91      0.90      6371
      reduce       0.86      0.83      0.85      6875
       right       0.83      0.83      0.83      5996
       shift       0.90      0.91      0.90      6578

    accuracy                           0.87     25820
   macro avg       0.87      0.87      0.87     25820
weighted avg       0.87      0.87      0.87     25820

Total: 12574
Correctly defined: 9373
UAS: 0.75
Full match: 0.13

#### Results on corpus test data

Decision tree final test:
              precision    recall  f1-score   support

        left       0.89      0.91      0.90      8658
      reduce       0.85      0.81      0.83      9350
       right       0.82      0.83      0.83      8291
       shift       0.90      0.90      0.90      8825

    accuracy                           0.87     35124
   macro avg       0.86      0.87      0.87     35124
weighted avg       0.87      0.87      0.87     35124

Total: 17116
Correctly defined: 12702
UAS: 0.74
Full match: 0.2

Logistic regression final test:
              precision    recall  f1-score   support

        left       0.87      0.88      0.88      8658
      reduce       0.85      0.78      0.81      9350
       right       0.77      0.81      0.79      8291
       shift       0.86      0.87      0.87      8825

    accuracy                           0.84     35124
   macro avg       0.84      0.84      0.84     35124
weighted avg       0.84      0.84      0.84     35124

Total: 17116
Correctly defined: 12255
UAS: 0.72
Full match: 0.17

#### Trees from my sentences
Decision tree classifier:

долини <-- none
падають <-- none
і <-- туляться
туляться <-- падають
до <-- ніг
ніг <-- туляться
, <-- звивають
звивають <-- туляться
завої <-- звивають
, <-- відсахуючись
відсахуючись <-- звивають
, <-- гори
гори <-- відсахуючись
. <-- root

наш <-- none
пружний <-- none
крок <-- none
тверда <-- none
земля <-- none
доріг <-- none
стрічає <-- none
стогоном <-- none
покори <-- none
. <-- none

чи <-- підіб'єм
ж <-- none
не <-- підіб'єм
підіб'єм <-- none
, <-- зірвемо
не <-- зірвемо
зірвемо <-- підіб'єм
ми <-- зірвемо
і <-- обрій
обрій <-- цей
цей <-- хмари
, <-- хмари
і <-- хмари
хмари <-- зірвемо
ці <-- none
рожеві <-- хмари
?! <-- підіб'єм

і <-- none
вогкий <-- none
вітер <-- none
дужими <-- none
грудьми <-- none
співає <-- none
на <-- none
моїм <-- none
мечеві <-- none
. <-- none

я <-- none
приготував <-- none
смачний <-- обід
обід <-- приготував
. <-- root

Logistic regression classifier:

долини <-- падають
падають <-- падають
і <-- none
туляться <-- падають
до <-- none
ніг <-- падають
, <-- падають
звивають <-- падають
завої <-- падають
, <-- none
відсахуючись <-- падають
, <-- none
гори <-- падають
. <-- падають

наш <-- крок
пружний <-- крок
крок <-- стрічає
тверда <-- none
земля <-- крок
доріг <-- крок
стрічає <-- крок
стогоном <-- стрічає
покори <-- стрічає
. <-- стрічає

чи <-- підіб'єм
ж <-- підіб'єм
не <-- підіб'єм
підіб'єм <-- підіб'єм
, <-- підіб'єм
не <-- зірвемо
зірвемо <-- підіб'єм
ми <-- підіб'єм
і <-- обрій
обрій <-- підіб'єм
цей <-- none
, <-- підіб'єм
і <-- хмари
хмари <-- підіб'єм
ці <-- none
рожеві <-- підіб'єм
?! <-- підіб'єм

і <-- вітер
вогкий <-- вітер
вітер <-- none
дужими <-- none
грудьми <-- none
співає <-- none
на <-- none
моїм <-- none
мечеві <-- none
. <-- none

я <-- приготував
приготував <-- приготував
смачний <-- none
обід <-- приготував
. <-- приготував