{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from conllu import parse\n",
    "from enum import Enum\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "\n",
    "PATH = \"/home/holdbar/projects/UD_Ukrainian-IU\"\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-train.conllu\", \"r\") as f:\n",
    "    train_trees = parse(f.read())\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-dev.conllu\", \"r\") as f:\n",
    "    test_trees = parse(f.read())\n",
    "\n",
    "with open(PATH + \"/uk_iu-ud-test.conllu\", \"r\") as f:\n",
    "    final_test_trees = parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design actions and the oracle\n",
    "    \n",
    "class Actions(str, Enum):\n",
    "    SHIFT = \"shift\"\n",
    "    REDUCE = \"reduce\"\n",
    "    RIGHT = \"right\"\n",
    "    LEFT = \"left\"\n",
    "\n",
    "\n",
    "def oracle(stack, top_queue, relations):\n",
    "    \"\"\"\n",
    "    Make a decision on the right action to do.\n",
    "    \"\"\"\n",
    "    top_stack = stack[-1]\n",
    "    # check if both stack and queue are non-empty\n",
    "    if top_stack and not top_queue:\n",
    "        return Actions.REDUCE\n",
    "    # check if there are any clear dependencies\n",
    "    elif top_queue[\"head\"] == top_stack[\"id\"]:\n",
    "        return Actions.RIGHT\n",
    "    elif top_stack[\"head\"] == top_queue[\"id\"]:\n",
    "        return Actions.LEFT\n",
    "    # check if we can reduce the top of the stack\n",
    "    elif top_stack[\"id\"] in [i[0] for i in relations] and \\\n",
    "         (top_queue[\"head\"] < top_stack[\"id\"] or \\\n",
    "          [s for s in stack if s[\"head\"] == top_queue[\"id\"]]):\n",
    "        return Actions.REDUCE\n",
    "    # default option\n",
    "    else:\n",
    "        return Actions.SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "\n",
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare train and test data\n",
    "\n",
    "ROOT = OrderedDict([('id', 0), ('form', 'ROOT'), ('lemma', 'ROOT'), ('upostag', 'ROOT'),\n",
    "                    ('xpostag', None), ('feats', None), ('head', None), ('deprel', None),\n",
    "                    ('deps', None), ('misc', None)])\n",
    "\n",
    "def get_data(tree):\n",
    "    features, labels = [], []\n",
    "    stack, queue, relations = [ROOT], tree[:], []\n",
    "\n",
    "    while queue or stack:\n",
    "        action = oracle(stack if len(stack) > 0 else None,\n",
    "                        queue[0] if len(queue) > 0 else None,\n",
    "                        relations)\n",
    "        features.append(extract_features(stack, queue))\n",
    "        labels.append(action.value)\n",
    "        if action == Actions.SHIFT:\n",
    "            stack.append(queue.pop(0))\n",
    "        elif action == Actions.REDUCE:\n",
    "            stack.pop()\n",
    "        elif action == Actions.LEFT:\n",
    "            relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "            stack.pop()\n",
    "        elif action == Actions.RIGHT:\n",
    "            relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "            stack.append(queue.pop(0))\n",
    "        else:\n",
    "            print(\"Unknown action.\")\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190298 190298\n",
      "25820 25820\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A simple hack would be to check the type of the node id\n",
    "\n",
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))\n",
    "\n",
    "\n",
    "# Test data\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.86      0.87      0.86      6371\n",
      "      reduce       0.85      0.78      0.81      6875\n",
      "       right       0.75      0.79      0.77      5996\n",
      "       shift       0.85      0.87      0.86      6578\n",
      "\n",
      "    accuracy                           0.83     25820\n",
      "   macro avg       0.83      0.83      0.83     25820\n",
      "weighted avg       0.83      0.83      0.83     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))\n",
    "\n",
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "\n",
    "# print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))\n",
    "\n",
    "lrc = LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\", max_iter=600)\n",
    "lrc.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correctly defined: 8717\n",
      "UAS: 0.69\n",
      "Full match: 0.09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the unlabeled attachment score\n",
    "# UAS - the percentage of words in an input that are assigned the correct head.\n",
    "\n",
    "def dep_parse(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)\n",
    "\n",
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-projective trees is 100.0 (5496 out of 5496).\n",
      "IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Find non-projective trees\n",
    "\n",
    "def is_non_projective(tree):\n",
    "    relations = [[i['id'], i['head']] for i in tree if type(i[\"id\"])==int]\n",
    "    for rel in relations:\n",
    "        for ref_rel in relations:\n",
    "            a, c = sorted(rel)\n",
    "            b, d = sorted(ref_rel)\n",
    "            if a < b and b < c and c < d:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "total_non_pr = 0\n",
    "tree_ids = []\n",
    "for i in range(len(train_trees)):\n",
    "    total_non_pr += 1\n",
    "    tree_ids.append(i)\n",
    "\n",
    "# 8% (e.g., tree no. 28)\n",
    "print(\"The number of non-projective trees is {} ({} out of {}).\".\n",
    "      format(round(total_non_pr * 100 / len(train_trees), 2), total_non_pr, len(train_trees)))\n",
    "\n",
    "print(\"IDs:\", tree_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################## Add more features:\n"
     ]
    }
   ],
   "source": [
    "############## Add more features\n",
    "print(\"################## Add more features:\")\n",
    "\n",
    "\n",
    "def get_feats(token, key):\n",
    "    features = dict()\n",
    "    feats = token[\"feats\"]\n",
    "    if isinstance(feats, str):\n",
    "        feats = eval(feats)\n",
    "    if isinstance(feats, OrderedDict):\n",
    "        for k,v in feats.items():\n",
    "            features[f'{key}-{k}'] = v\n",
    "\n",
    "    return features\n",
    "            \n",
    "def extract_features(stack, queue):\n",
    "    features = dict()\n",
    "    if len(stack) > 0:\n",
    "        stack_top = stack[-1]\n",
    "        features[\"s0-word\"] = stack_top[\"form\"]\n",
    "        features[\"s0-lemma\"] = stack_top[\"lemma\"]\n",
    "        features[\"s0-tag\"] = stack_top[\"upostag\"]\n",
    "        features.update(get_feats(stack_top,\"s0\"))\n",
    "    if len(stack) > 1:\n",
    "        features[\"s1-tag\"] = stack[-2][\"upostag\"]\n",
    "    if queue:\n",
    "        queue_top = queue[0]\n",
    "        features[\"q0-word\"] = queue_top[\"form\"]\n",
    "        features[\"q0-lemma\"] = queue_top[\"lemma\"]\n",
    "        features[\"q0-tag\"] = queue_top[\"upostag\"]\n",
    "        features.update(get_feats(queue_top,\"q0\"))\n",
    "    if len(queue) > 1:\n",
    "        queue_next = queue[1]\n",
    "        features[\"q1-word\"] = queue_next[\"form\"]\n",
    "        features[\"q1-tag\"] = queue_next[\"upostag\"]\n",
    "        features.update(get_feats(queue_next,\"q1\"))\n",
    "    if len(queue) > 2:\n",
    "        features[\"q2-tag\"] = queue[2][\"upostag\"]\n",
    "    if len(queue) > 3:\n",
    "        features[\"q3-tag\"] = queue[3][\"upostag\"]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190298 190298\n",
      "25820 25820\n",
      "35124 35124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_features, train_labels = [], []\n",
    "for tree in train_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    train_features += tree_features\n",
    "    train_labels += tree_labels\n",
    "\n",
    "print(len(train_features), len(train_labels))\n",
    "\n",
    "\n",
    "# Test data\n",
    "\n",
    "test_features, test_labels = [], []\n",
    "for tree in test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    test_features += tree_features\n",
    "    test_labels += tree_labels\n",
    "\n",
    "print(len(test_features), len(test_labels))\n",
    "\n",
    "final_test_features, final_test_labels = [], []\n",
    "for tree in final_test_trees:\n",
    "    tree_features, tree_labels = get_data([t for t in tree if type(t[\"id\"])==int])\n",
    "    final_test_features += tree_features\n",
    "    final_test_labels += tree_labels\n",
    "\n",
    "print(len(final_test_features), len(final_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of features:  111327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.86      0.88      0.87      6371\n",
      "      reduce       0.86      0.80      0.83      6875\n",
      "       right       0.77      0.81      0.79      5996\n",
      "       shift       0.86      0.87      0.87      6578\n",
      "\n",
      "    accuracy                           0.84     25820\n",
      "   macro avg       0.84      0.84      0.84     25820\n",
      "weighted avg       0.84      0.84      0.84     25820\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holdbar/projects/prj-nlp-2020/.env/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train a classifier\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "vec = vectorizer.fit(train_features)\n",
    "\n",
    "print(\"\\nTotal number of features: \", len(vec.get_feature_names()))\n",
    "\n",
    "train_features_vectorized = vec.transform(train_features)\n",
    "test_features_vectorized = vec.transform(test_features)\n",
    "final_test_features_vectorized = vec.transform(final_test_features)\n",
    "\n",
    "# print(len(train_features_vectorized.toarray()), len(test_features_vectorized.toarray()))\n",
    "\n",
    "lrc = LogisticRegression(random_state=42, solver=\"saga\", multi_class=\"multinomial\", max_iter=600)\n",
    "lrc.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "predicted = lrc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correctly defined: 8921\n",
      "UAS: 0.71\n",
      "Full match: 0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Decision tree classifier with all features:\n"
     ]
    }
   ],
   "source": [
    "# other classifier - decision tree classifier with all features and decomposition\n",
    "\n",
    "print(\"#### Decision tree classifier with all features:\")\n",
    "\n",
    "def dep_parse2(sentence, oracle, vectorizer, log=True):\n",
    "    stack, queue, relations = [ROOT], sentence[:], []\n",
    "    while queue or stack:\n",
    "        if stack and not queue:\n",
    "            stack.pop()\n",
    "        else:\n",
    "            features = extract_features(stack, queue)\n",
    "            action = oracle.predict(vectorizer.transform([features]))[0]\n",
    "            # actual parsing\n",
    "            if action == Actions.SHIFT:\n",
    "                stack.append(queue.pop(0))\n",
    "            elif action == Actions.REDUCE:\n",
    "                if not stack:\n",
    "                    break\n",
    "                stack.pop()\n",
    "            elif action == Actions.LEFT:\n",
    "                if not stack:\n",
    "                    break\n",
    "                relations.append((stack[-1][\"id\"], queue[0][\"id\"]))\n",
    "                stack.pop()\n",
    "            elif action == Actions.RIGHT:\n",
    "                relations.append((queue[0][\"id\"], stack[-1][\"id\"]))\n",
    "                stack.append(queue.pop(0))\n",
    "            else:\n",
    "                print(\"Unknown action.\")\n",
    "    return sorted(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.89      0.91      0.90      6371\n",
      "      reduce       0.86      0.83      0.85      6875\n",
      "       right       0.83      0.83      0.83      5996\n",
      "       shift       0.90      0.91      0.90      6578\n",
      "\n",
      "    accuracy                           0.87     25820\n",
      "   macro avg       0.87      0.87      0.87     25820\n",
      "weighted avg       0.87      0.87      0.87     25820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(train_features_vectorized, train_labels)\n",
    "\n",
    "\n",
    "predicted = dtc.predict(test_features_vectorized)\n",
    "print(classification_report(test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 12574\n",
      "Correctly defined: 9373\n",
      "UAS: 0.75\n",
      "Full match: 0.13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse2(tree, dtc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(test_trees), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree final test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.89      0.91      0.90      8658\n",
      "      reduce       0.85      0.81      0.83      9350\n",
      "       right       0.82      0.83      0.83      8291\n",
      "       shift       0.90      0.90      0.90      8825\n",
      "\n",
      "    accuracy                           0.87     35124\n",
      "   macro avg       0.86      0.87      0.87     35124\n",
      "weighted avg       0.87      0.87      0.87     35124\n",
      "\n",
      "Total: 17116\n",
      "Correctly defined: 12702\n",
      "UAS: 0.74\n",
      "Full match: 0.2\n",
      "Logistic regression final test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        left       0.87      0.88      0.88      8658\n",
      "      reduce       0.85      0.78      0.81      9350\n",
      "       right       0.77      0.81      0.79      8291\n",
      "       shift       0.86      0.87      0.87      8825\n",
      "\n",
      "    accuracy                           0.84     35124\n",
      "   macro avg       0.84      0.84      0.84     35124\n",
      "weighted avg       0.84      0.84      0.84     35124\n",
      "\n",
      "Total: 17116\n",
      "Correctly defined: 12255\n",
      "UAS: 0.72\n",
      "Full match: 0.17\n"
     ]
    }
   ],
   "source": [
    "### Final test on conllu data with both classifiers\n",
    "print(\"Decision tree final test:\")\n",
    "predicted = dtc.predict(final_test_features_vectorized)\n",
    "print(classification_report(final_test_labels, predicted))\n",
    "\n",
    "\n",
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in final_test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse2(tree, dtc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(final_test_trees), 2))\n",
    "\n",
    "\n",
    "print(\"Logistic regression final test:\")\n",
    "predicted = lrc.predict(final_test_features_vectorized)\n",
    "print(classification_report(final_test_labels, predicted))\n",
    "\n",
    "\n",
    "total, tp, full_match = 0, 0, 0\n",
    "for tree in final_test_trees:\n",
    "    tree = [t for t in tree if type(t[\"id\"])==int]\n",
    "    golden = [(node[\"id\"], node[\"head\"]) for node in tree]\n",
    "    predicted = dep_parse(tree, lrc, vec, log=False)\n",
    "    total += len(tree)\n",
    "    tp += len(set(golden).intersection(set(predicted)))\n",
    "    if set(golden) == set(predicted):\n",
    "        full_match += 1\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Correctly defined:\", tp)\n",
    "print(\"UAS:\", round(tp/total, 2))\n",
    "print(\"Full match:\", round(full_match/len(final_test_trees), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Test on my data                                                                                                                                               \n",
    "\n",
    "from tokenize_uk import tokenize_uk\n",
    "import pymorphy2\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer(lang='uk')\n",
    "\n",
    "DET = ['будь-який', 'ваш', 'ввесь', 'весь', 'все', 'всенький', 'всякий',\n",
    "       'всілякий', 'деякий', 'другий', 'жадний', 'жодний', 'ин.', 'ін.',\n",
    "       'інакший', 'інш.', 'інший', 'їх', 'їхній', 'її', 'його', 'кожний',\n",
    "       'кожній', 'котрий', 'котрийсь', 'кілька', 'мій', 'наш', 'небагато',\n",
    "       'ніякий', 'отакий', 'отой', 'оцей', 'сам', 'самий', 'свій', 'сей',\n",
    "       'скільки', 'такий', 'тамтой', 'твій', 'те', 'той', 'увесь', 'усякий',\n",
    "       'усілякий', 'це', 'цей', 'чий', 'чийсь', 'який', 'якийсь']\n",
    "\n",
    "PREP = [\"до\", \"на\"]\n",
    "\n",
    "mapping = {\"ADJF\": \"ADJ\", \"ADJS\": \"ADJ\", \"COMP\": \"ADJ\", \"PRTF\": \"ADJ\",\n",
    "           \"PRTS\": \"ADJ\", \"GRND\": \"VERB\", \"NUMR\": \"NUM\", \"ADVB\": \"ADV\",\n",
    "           \"NPRO\": \"PRON\", \"PRED\": \"ADV\", \"PREP\": \"ADP\", \"PRCL\": \"PART\"}\n",
    "\n",
    "def normalize_pos(word):\n",
    "    if word.tag.POS == \"CONJ\":\n",
    "        if \"coord\" in word.tag:\n",
    "            return \"CCONJ\"\n",
    "        else:\n",
    "            return \"SCONJ\"\n",
    "    elif \"PNCT\" in word.tag:\n",
    "        return \"PUNCT\"\n",
    "    elif word.normal_form in PREP:\n",
    "        return \"PREP\"\n",
    "    elif word.normal_form in DET:\n",
    "        return \"DET\"\n",
    "    else:\n",
    "        return mapping.get(word.tag.POS, word.tag.POS)\n",
    "\n",
    "def get_word_feats(word):\n",
    "    feats = OrderedDict()\n",
    "    if word.tag.animacy:\n",
    "        feats[\"Animacy\"] = word.tag.animacy.capitalize()\n",
    "    if word.tag.aspect:\n",
    "        feats[\"Aspect\"] = word.tag.aspect.capitalize()\n",
    "    if word.tag.case:\n",
    "        feats[\"Case\"] = word.tag.case.capitalize()\n",
    "    if word.tag.gender:\n",
    "        feats[\"Gender\"] = word.tag.gender.capitalize()\n",
    "    if word.tag.mood:\n",
    "        feats[\"Mood\"] = word.tag.mood.capitalize()\n",
    "    if word.tag.number:\n",
    "        feats[\"Number\"] = word.tag.number.capitalize()\n",
    "    if word.tag.person:\n",
    "        feats[\"Person\"] = word.tag.person.capitalize()\n",
    "    if word.tag.tense:\n",
    "        feats[\"Tense\"] = word.tag.tense.capitalize()\n",
    "    if word.tag.voice:\n",
    "        feats[\"Voice\"] = word.tag.voice.capitalize()\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def parse_sentence(text):\n",
    "    tokens = tokenize_uk.tokenize_words(text)\n",
    "    tree_nodes = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        word = morph.parse(token)[0]\n",
    "        tree_nodes.append(\n",
    "            OrderedDict([\n",
    "                ('id', i+1), \n",
    "                ('form', str(word.word)), \n",
    "                ('lemma', str(word.normal_form)),\n",
    "                ('upostag', normalize_pos(word)),\n",
    "                ('feats', get_word_feats(word)),\n",
    "                ('deprel', None),\n",
    "                ('head', None),\n",
    "            ])\n",
    "        )\n",
    "        \n",
    "    return tree_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_relation_on_tree(tree_nodes, dep_parse_func,  oracle, vectorizer):\n",
    "    tree = deepcopy(tree_nodes)\n",
    "    relations = dep_parse_func(tree, oracle, vectorizer, log=False)\n",
    "    for child, head in relations:\n",
    "        tree[child - 1][\"head\"] = head - 1\n",
    "\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_tree(tree):\n",
    "    for node in tree:\n",
    "        head = node[\"head\"]\n",
    "        # print(node)\n",
    "        # print(head)\n",
    "        if head is None:\n",
    "            head_str = 'none'\n",
    "        elif head == 0:\n",
    "            head_str = 'root'\n",
    "        elif head > 0:\n",
    "            head_str = tree[head][\"form\"]\n",
    "        print(\"{} <-- {}\".format(node[\"form\"], head_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Долини падають і туляться до ніг, звивають завої, відсахуючись, гори.\",\n",
    "    \"Наш пружний крок тверда земля доріг стрічає стогоном покори.\",\n",
    "    \"Чи ж не підіб'єм, не зірвемо ми і обрій цей, і хмари ці рожеві?!\",\n",
    "    \"І вогкий вітер дужими грудьми співає на моїм мечеві.\",\n",
    "    \"Я приготував смачний обід.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree classifier:\n",
      "долини <-- падають\n",
      "падають <-- падають\n",
      "і <-- none\n",
      "туляться <-- падають\n",
      "до <-- none\n",
      "ніг <-- падають\n",
      ", <-- падають\n",
      "звивають <-- падають\n",
      "завої <-- падають\n",
      ", <-- none\n",
      "відсахуючись <-- падають\n",
      ", <-- none\n",
      "гори <-- падають\n",
      ". <-- падають\n",
      "наш <-- крок\n",
      "пружний <-- крок\n",
      "крок <-- стрічає\n",
      "тверда <-- none\n",
      "земля <-- крок\n",
      "доріг <-- крок\n",
      "стрічає <-- крок\n",
      "стогоном <-- стрічає\n",
      "покори <-- стрічає\n",
      ". <-- стрічає\n",
      "чи <-- підіб'єм\n",
      "ж <-- підіб'єм\n",
      "не <-- підіб'єм\n",
      "підіб'єм <-- підіб'єм\n",
      ", <-- підіб'єм\n",
      "не <-- зірвемо\n",
      "зірвемо <-- підіб'єм\n",
      "ми <-- підіб'єм\n",
      "і <-- обрій\n",
      "обрій <-- підіб'єм\n",
      "цей <-- none\n",
      ", <-- підіб'єм\n",
      "і <-- хмари\n",
      "хмари <-- підіб'єм\n",
      "ці <-- none\n",
      "рожеві <-- підіб'єм\n",
      "?! <-- підіб'єм\n",
      "і <-- вітер\n",
      "вогкий <-- вітер\n",
      "вітер <-- none\n",
      "дужими <-- none\n",
      "грудьми <-- none\n",
      "співає <-- none\n",
      "на <-- none\n",
      "моїм <-- none\n",
      "мечеві <-- none\n",
      ". <-- none\n",
      "я <-- приготував\n",
      "приготував <-- приготував\n",
      "смачний <-- none\n",
      "обід <-- приготував\n",
      ". <-- приготував\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## decision tree\n",
    "print(\"Decision tree classifier:\")\n",
    "for sentence in sentences:\n",
    "    tree_nodes = parse_sentence(sentence)\n",
    "    tree = set_relation_on_tree(tree_nodes, dep_parse2, dtc, vec)\n",
    "    print_tree(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression classifier:\n",
      "долини <-- падають\n",
      "падають <-- падають\n",
      "і <-- none\n",
      "туляться <-- падають\n",
      "до <-- none\n",
      "ніг <-- падають\n",
      ", <-- падають\n",
      "звивають <-- падають\n",
      "завої <-- падають\n",
      ", <-- none\n",
      "відсахуючись <-- падають\n",
      ", <-- none\n",
      "гори <-- падають\n",
      ". <-- падають\n",
      "наш <-- крок\n",
      "пружний <-- крок\n",
      "крок <-- стрічає\n",
      "тверда <-- none\n",
      "земля <-- крок\n",
      "доріг <-- крок\n",
      "стрічає <-- крок\n",
      "стогоном <-- стрічає\n",
      "покори <-- стрічає\n",
      ". <-- стрічає\n",
      "чи <-- підіб'єм\n",
      "ж <-- підіб'єм\n",
      "не <-- підіб'єм\n",
      "підіб'єм <-- підіб'єм\n",
      ", <-- підіб'єм\n",
      "не <-- зірвемо\n",
      "зірвемо <-- підіб'єм\n",
      "ми <-- підіб'єм\n",
      "і <-- обрій\n",
      "обрій <-- підіб'єм\n",
      "цей <-- none\n",
      ", <-- підіб'єм\n",
      "і <-- хмари\n",
      "хмари <-- підіб'єм\n",
      "ці <-- none\n",
      "рожеві <-- підіб'єм\n",
      "?! <-- підіб'єм\n",
      "і <-- вітер\n",
      "вогкий <-- вітер\n",
      "вітер <-- none\n",
      "дужими <-- none\n",
      "грудьми <-- none\n",
      "співає <-- none\n",
      "на <-- none\n",
      "моїм <-- none\n",
      "мечеві <-- none\n",
      ". <-- none\n",
      "я <-- приготував\n",
      "приготував <-- приготував\n",
      "смачний <-- none\n",
      "обід <-- приготував\n",
      ". <-- приготував\n"
     ]
    }
   ],
   "source": [
    "## logistic regression\n",
    "print(\"Logistic regression classifier:\")\n",
    "for sentence in sentences:\n",
    "    tree_nodes = parse_sentence(sentence)\n",
    "    tree = set_relation_on_tree(tree_nodes, dep_parse2, lrc, vec)\n",
    "    print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
