# Висновки
В якості покращень я використав препроцесінг, використання інших векторів, використання іншого класифікатора.

## 0. Фільтр по мові
На етапі підготовки датасету я відфільтрував україномовні звернення за допомогою бібліотеки langid.

### Стартові показники

                                                                        accuracy                           0.14     22625
                                                                       macro avg       0.05      0.05      0.04     22625
                                                                    weighted avg       0.16      0.14      0.14     22625

Повний результат у файлі: results_start.txt


## 1. Препроцесінг
На цьому етапі я провів лематизацію, прибрав пунктуаційні символи, токени які складаються виключно з цифр, а також відфільтрував токени за частинами мови. Особливого приросту якості це не дало.

###  Додання препроцесінгу


                                                                        accuracy                           0.16     22625
                                                                       macro avg       0.05      0.05      0.04     22625
                                                                    weighted avg       0.17      0.16      0.15     22625

Повний результат у файлі: results_preprocessed.txt


## 2. Інші вектори
Я спробував використати вектори які доступні за посиланням: https://lang.org.ua/en/models/#anchor4, але вони не дали відчутного покращення.
У зв'язу з цим я спробуав отримати вектори через TF-IDF. На цих векторах класифікатор показав значно кращі результати.

### Додання TF-IDF векторів


                                                                        accuracy                           0.49     22625
                                                                       macro avg       0.25      0.22      0.21     22625
                                                                    weighted avg       0.49      0.49      0.47     22625


Повний результат у файлі: results_tfidf_knn.txt


## 3. Інший класифікатор
Після вибору нових векторів я спробував використати інший класификатор а саме SVC. Перед цим я спробував декілька інших класифікаторів які показували нульовий результат, або взагалі не працювали через нестачу апаратних ресурсів.

### Використання SVC-класифікатора

                                                                        accuracy                           0.62     22625
                                                                       macro avg       0.31      0.21      0.22     22625
                                                                    weighted avg       0.61      0.62      0.58     22625


Повний результат у файлі: results_tfidf_svc.txt


## 4. Вектори документу
Також я спробував зробити класифікацію на векторах документу за допомогою Doc2Vec, ElMo, Universal Sentece Encoder.
В мене нічого не вийшло (:

Universal Sentece Encoder - не вдалося змусити його працювати в принципі.

Doc2Vec - вдалося його запустити, проте класифыкатора на цих векторах показав нульові результати. Підозрюю що я десь припустився помилки і чогось не зрозумів.

ElMo - вдалося запусити, хоча на це пішло багато часу :\ Основна проблема - побудова векторів працює дуууууже повільно. Я навіть пропалтив собі колаб, думав на GPU\TPU справа піде швидше :D
При цьому коли я запустив класифікатор на дуже обмеженій кількості векторів отриманих з ElMo, то результати були ненульовими. Тож я припускаю що в цілому word-embedding має бути перспектиним інструментом
для ціжї задачі.

## 5. Поєднання класифікаторів
Я спробував поєднати два єдині класифікатори які дали мені позитивні результати - це KNN та SVC. На жаль тут я знову уперся в нестачу апарантних ресурсів і чи є це позитивним покращенням такі не дізнався.
