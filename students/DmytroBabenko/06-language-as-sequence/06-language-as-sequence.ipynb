{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(data: str, file: str):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    result = []\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            l = line.strip()\n",
    "            if len(l) > 0:\n",
    "                result.append(l)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(file):\n",
    "    with open(file) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data/corpus.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \n",
    "    END_OF_SENT_PUNCT = ['.', '!', '?']\n",
    "    \n",
    "    \n",
    "    def generate(self, data: List[str]):\n",
    "        result = []\n",
    "        for data_line in data:\n",
    "            result += self.generate_for_text(data_line)\n",
    "        return result\n",
    "\n",
    "    def generate_for_text(self, text: str):\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        size = len(sentences)\n",
    "        start = 0\n",
    "        result = []\n",
    "        i = 0\n",
    "        while i < size:\n",
    "            num_of_sents = self.get_random_num_of_sentences()\n",
    "            end = i + num_of_sents if i + num_of_sents < len(sentences) else size\n",
    "\n",
    "            data = self.__generate_data_for_sentences(sentences[i:end])\n",
    "            i = end\n",
    "\n",
    "            if len(data) > 0:\n",
    "                result.append(data)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def __generate_data_for_sentences(self, sentences: List[str]):\n",
    "\n",
    "        result = []\n",
    "        sentences_size = len(sentences)\n",
    "        for i in range(0, sentences_size):\n",
    "\n",
    "            sent_data = []\n",
    "            tokens = word_tokenize(sentences[i])\n",
    "            tokens_size = len(tokens) \n",
    "            should_set_end_word = False\n",
    "            for j in range(tokens_size- 1, -1, -1):\n",
    "                token = tokens[j]\n",
    "                \n",
    "                if token in self.END_OF_SENT_PUNCT:\n",
    "                    if j == tokens_size - 1 and i < sentences_size - 1:\n",
    "                        should_set_end_word = True\n",
    "                    continue\n",
    "\n",
    "                word = self.__randomly_lowercase_word(token, word_idx=j, sent_idx=i)\n",
    "                \n",
    "                if should_set_end_word:\n",
    "                    sent_data.insert(0, [word, True])\n",
    "                    should_set_end_word = False\n",
    "                else:\n",
    "                    sent_data.insert(0, [word, False])\n",
    "            \n",
    "            if len(sent_data) > 0:\n",
    "                result += sent_data\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def __randomly_lowercase_word(self, word: str, word_idx: int, sent_idx: int):\n",
    "        if sent_idx == 0 or word_idx > 0:\n",
    "            return word\n",
    "\n",
    "        should_be_lower = False #random.choice([True, False])\n",
    "        if should_be_lower:\n",
    "            return word.lower()\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __is_punctuation(self, token: str):\n",
    "        if token in string.punctuation:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def __is_end_word_in_sent(self, word: str, word_idx: int, num_token_in_sents: int):\n",
    "        if self.word_pattern.match(word) is None:\n",
    "            return False\n",
    "\n",
    "        if word_idx == num_token_in_sents - 1:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "    def get_random_num_of_sentences(self):\n",
    "        num = random.choices([1, 2, 3, 4], weights=[1, 12, 4, 3], k=1)[0]\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Suicide won't oure shyness problems.  [Headline over Beth Winship's teen-advice column, Morning Union , Springfield, (Massachusetts), .  Submitted by .]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Suicide', False],\n",
       "  ['wo', False],\n",
       "  [\"n't\", False],\n",
       "  ['oure', False],\n",
       "  ['shyness', False],\n",
       "  ['problems', True],\n",
       "  ['[', False],\n",
       "  ['Headline', False],\n",
       "  ['over', False],\n",
       "  ['Beth', False],\n",
       "  ['Winship', False],\n",
       "  [\"'s\", False],\n",
       "  ['teen-advice', False],\n",
       "  ['column', False],\n",
       "  [',', False],\n",
       "  ['Morning', False],\n",
       "  ['Union', False],\n",
       "  [',', False],\n",
       "  ['Springfield', False],\n",
       "  [',', False],\n",
       "  ['(', False],\n",
       "  ['Massachusetts', False],\n",
       "  [')', False],\n",
       "  [',', False]],\n",
       " [['Submitted', False], ['by', False], [']', False]]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_generator.generate_for_text(\"Suicide won't oure shyness problems.  [Headline over Beth Winship's teen-advice column, Morning Union , Springfield, (Massachusetts), .  Submitted by .]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_generator.generate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['The', False],\n",
       "  ['Decline', False],\n",
       "  ['of', False],\n",
       "  ['the', False],\n",
       "  ['Northeastern', False],\n",
       "  ['Ohio', False],\n",
       "  ['Steel', False],\n",
       "  ['Market', False],\n",
       "  [':', False],\n",
       "  ['Why', False],\n",
       "  ['Did', False],\n",
       "  ['Attempts', False],\n",
       "  ['by', False],\n",
       "  ['Union', False],\n",
       "  ['Leaders', False],\n",
       "  ['and', False],\n",
       "  ['Concerned', False],\n",
       "  ['Citizens', False],\n",
       "  ['to', False],\n",
       "  ['Revive', False],\n",
       "  ['the', False],\n",
       "  ['Steel', False],\n",
       "  ['Industry', False],\n",
       "  ['Ultimately', False],\n",
       "  ['Fail', False],\n",
       "  ['An', False],\n",
       "  ['Extended', False],\n",
       "  ['Essay', False],\n",
       "  ['in', False],\n",
       "  ['HistoryBy', False],\n",
       "  ['Philosophy', False],\n",
       "  ['E.', False],\n",
       "  ['WalkerCandidate', False],\n",
       "  ['Number', False],\n",
       "  [':', False],\n",
       "  ['xxxxxxxxxSupervisor', False],\n",
       "  [':', False],\n",
       "  ['Alexis', False],\n",
       "  ['MamauxDate', False],\n",
       "  [':', False],\n",
       "  ['January', False],\n",
       "  ['12', False],\n",
       "  [',', False],\n",
       "  ['2004Word', False],\n",
       "  ['Count', False],\n",
       "  [':', False],\n",
       "  ['3215United', False],\n",
       "  ['World', False],\n",
       "  ['College', False],\n",
       "  ['of', False],\n",
       "  ['the', False],\n",
       "  ['American', False],\n",
       "  ['WestMontezuma', False],\n",
       "  [',', False],\n",
       "  ['NM87731USASeptember', False],\n",
       "  ['19', False],\n",
       "  [',', False],\n",
       "  ['1977', False],\n",
       "  ['is', False],\n",
       "  ['a', False],\n",
       "  ['date', False],\n",
       "  ['that', False],\n",
       "  ['few', False],\n",
       "  ['people', False],\n",
       "  ['in', False],\n",
       "  ['Youngstown', False],\n",
       "  [',', False],\n",
       "  ['Ohio', False],\n",
       "  ['will', False],\n",
       "  ['ever', False],\n",
       "  ['forget', True],\n",
       "  ['On', False],\n",
       "  ['that', False],\n",
       "  ['date', False],\n",
       "  ['JenningsLambeth', False],\n",
       "  [',', False],\n",
       "  ['president', False],\n",
       "  ['of', False],\n",
       "  ['Youngstown', False],\n",
       "  ['Sheet', False],\n",
       "  ['and', False],\n",
       "  ['Tube', False],\n",
       "  ['Company', False],\n",
       "  [',', False],\n",
       "  ['announced', False],\n",
       "  ['that', False],\n",
       "  ['most', False],\n",
       "  ['of', False],\n",
       "  ['the', False],\n",
       "  ['steel', False],\n",
       "  ['company', False],\n",
       "  ['’', False],\n",
       "  ['s', False],\n",
       "  ['CampbellWorks', False],\n",
       "  ['would', False],\n",
       "  ['close', False]],\n",
       " [['Although', False],\n",
       "  ['for', False],\n",
       "  ['other', False],\n",
       "  ['cities', False],\n",
       "  ['this', False],\n",
       "  ['would', False],\n",
       "  ['simply', False],\n",
       "  ['be', False],\n",
       "  ['a', False],\n",
       "  ['minor', False],\n",
       "  ['economic', False],\n",
       "  ['setback', False],\n",
       "  [',', False],\n",
       "  ['for', False],\n",
       "  ['the', False],\n",
       "  ['peopleof', False],\n",
       "  ['Youngstown', False],\n",
       "  ['and', False],\n",
       "  ['the', False],\n",
       "  ['surrounding', False],\n",
       "  ['area', False],\n",
       "  [',', False],\n",
       "  ['it', False],\n",
       "  ['meant', False],\n",
       "  ['disaster', True],\n",
       "  ['Mahoning', False],\n",
       "  ['County', False],\n",
       "  ['was', False],\n",
       "  ['a', False],\n",
       "  ['one-industry', False],\n",
       "  ['area', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['thepeople', False],\n",
       "  ['of', False],\n",
       "  ['Youngstown', False],\n",
       "  [',', False],\n",
       "  ['Struthers', False],\n",
       "  [',', False],\n",
       "  ['Campbell', False],\n",
       "  [',', False],\n",
       "  ['Boardman', False],\n",
       "  ['Township', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['the', False],\n",
       "  ['numerous', False],\n",
       "  ['other', False],\n",
       "  ['small', False],\n",
       "  ['towns', False],\n",
       "  ['andvillages', False],\n",
       "  ['in', False],\n",
       "  ['the', False],\n",
       "  ['area', False],\n",
       "  ['only', False],\n",
       "  ['had', False],\n",
       "  ['one', False],\n",
       "  ['main', False],\n",
       "  ['employer', False],\n",
       "  [':', False],\n",
       "  ['the', False],\n",
       "  ['steel', False],\n",
       "  ['mills.The', False],\n",
       "  ['events', False],\n",
       "  ['that', False],\n",
       "  ['would', False],\n",
       "  ['follow', False],\n",
       "  ['thisdate', False],\n",
       "  ['(', False],\n",
       "  ['known', False],\n",
       "  ['as', False],\n",
       "  ['Black', False],\n",
       "  ['Monday', False],\n",
       "  [')', False],\n",
       "  ['are', False],\n",
       "  ['seen', False],\n",
       "  ['by', False],\n",
       "  ['the', False],\n",
       "  ['people', False],\n",
       "  ['who', False],\n",
       "  ['witnessed', False],\n",
       "  ['them', False],\n",
       "  ['either', False],\n",
       "  ['as', False],\n",
       "  ['stories', False],\n",
       "  ['of', False],\n",
       "  ['great', False],\n",
       "  ['courageand', False],\n",
       "  ['determination', False],\n",
       "  ['or', False],\n",
       "  ['as', False],\n",
       "  ['monuments', False],\n",
       "  ['to', False],\n",
       "  ['human', False],\n",
       "  ['failure', False],\n",
       "  ['and', False],\n",
       "  ['false', False],\n",
       "  ['hope', False]],\n",
       " [['Rather', False],\n",
       "  ['than', False],\n",
       "  ['sit', False],\n",
       "  ['back', False],\n",
       "  ['and', False],\n",
       "  ['wait', False],\n",
       "  ['for', False],\n",
       "  ['theirjobs', False],\n",
       "  ['to', False],\n",
       "  ['be', False],\n",
       "  ['snatched', False],\n",
       "  ['away', False],\n",
       "  [',', False],\n",
       "  ['the', False],\n",
       "  ['workers', False],\n",
       "  ['and', False],\n",
       "  ['local', False],\n",
       "  ['union', False],\n",
       "  ['members', False],\n",
       "  ['in', False],\n",
       "  ['the', False],\n",
       "  ['mills', False],\n",
       "  ['fought', False],\n",
       "  ['long', False],\n",
       "  ['and', False],\n",
       "  ['hard', False],\n",
       "  ['to', False],\n",
       "  ['be', False],\n",
       "  ['ableto', False],\n",
       "  ['keep', False],\n",
       "  ['the', False],\n",
       "  ['factories', False],\n",
       "  ['open', True],\n",
       "  ['Petitions', False],\n",
       "  [',', False],\n",
       "  ['protests', False],\n",
       "  [',', False],\n",
       "  ['rallies', False],\n",
       "  [',', False],\n",
       "  ['collectivization', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['even', False],\n",
       "  ['the', False],\n",
       "  ['takeover', False],\n",
       "  ['of', False],\n",
       "  ['a', False],\n",
       "  ['steelcompany', False],\n",
       "  ['’', False],\n",
       "  ['s', False],\n",
       "  ['headquarters', False],\n",
       "  ['were', False],\n",
       "  ['all', False],\n",
       "  ['attempted', False],\n",
       "  ['in', False],\n",
       "  ['a', False],\n",
       "  ['desperate', False],\n",
       "  ['movement', False],\n",
       "  ['by', False],\n",
       "  ['those', False],\n",
       "  ['in', False],\n",
       "  ['the', False],\n",
       "  ['industry', False],\n",
       "  ['to', False],\n",
       "  ['preserve', False],\n",
       "  ['theonly', False],\n",
       "  ['source', False],\n",
       "  ['of', False],\n",
       "  ['employment', False],\n",
       "  ['that', False],\n",
       "  ['this', False],\n",
       "  ['town', False],\n",
       "  ['had', True],\n",
       "  ['These', False],\n",
       "  ['well-intentioned', False],\n",
       "  ['efforts', False],\n",
       "  ['ultimately', False],\n",
       "  ['failed', False],\n",
       "  [',', False],\n",
       "  ['leavingthousands', False],\n",
       "  ['with', False],\n",
       "  ['shattered', False],\n",
       "  ['dreams', False],\n",
       "  ['and', False],\n",
       "  ['a', False],\n",
       "  ['distinct', False],\n",
       "  ['lack', False],\n",
       "  ['of', False],\n",
       "  ['trust', False],\n",
       "  ['in', False],\n",
       "  ['fellow', False],\n",
       "  ['humankind.But', False],\n",
       "  ['why', False],\n",
       "  ['did', False],\n",
       "  ['thebrave', False],\n",
       "  ['attempts', False],\n",
       "  ['by', False],\n",
       "  ['union', False],\n",
       "  ['leaders', False],\n",
       "  ['and', False],\n",
       "  ['concerned', False],\n",
       "  ['citizens', False],\n",
       "  ['to', False],\n",
       "  ['revive', False],\n",
       "  ['the', False],\n",
       "  ['steel', False],\n",
       "  ['industry', False],\n",
       "  ['ultimately', False],\n",
       "  ['fail', False]],\n",
       " [['Whenexamining', False],\n",
       "  ['the', False],\n",
       "  ['area', False],\n",
       "  ['’', False],\n",
       "  ['s', False],\n",
       "  ['history', False],\n",
       "  [',', False],\n",
       "  ['culture', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['economic', False],\n",
       "  ['situation', False],\n",
       "  ['we', False],\n",
       "  ['can', False],\n",
       "  ['identify', False],\n",
       "  ['four', False],\n",
       "  ['main', False],\n",
       "  ['reasons', False],\n",
       "  [':', False],\n",
       "  ['the', False],\n",
       "  ['refusalof', False],\n",
       "  ['the', False],\n",
       "  ['international', False],\n",
       "  ['leadership', False],\n",
       "  ['of', False],\n",
       "  ['United', False],\n",
       "  ['Steelworkers', False],\n",
       "  ['of', False],\n",
       "  ['America', False],\n",
       "  ['to', False],\n",
       "  ['support', False],\n",
       "  ['their', False],\n",
       "  ['union', False],\n",
       "  ['’', False],\n",
       "  ['s', False],\n",
       "  ['Youngstownbranch', False],\n",
       "  [',', False],\n",
       "  ['the', False],\n",
       "  ['lagging', False],\n",
       "  ['international', False],\n",
       "  ['steel', False],\n",
       "  ['market', False],\n",
       "  [',', False],\n",
       "  ['the', False],\n",
       "  ['lack', False],\n",
       "  ['of', False],\n",
       "  ['a', False],\n",
       "  ['clear', False],\n",
       "  [',', False],\n",
       "  ['organized', False],\n",
       "  ['vision', False],\n",
       "  ['for', False],\n",
       "  ['individualinitiatives', False],\n",
       "  ['such', False],\n",
       "  ['as', False],\n",
       "  ['the', False],\n",
       "  ['Save', False],\n",
       "  ['Our', False],\n",
       "  ['Valley', False],\n",
       "  ['Campaign', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['crippling', False],\n",
       "  ['regionalism', False],\n",
       "  ['which', False],\n",
       "  ['caused', False],\n",
       "  ['animosity', False],\n",
       "  ['betweendifferent', False],\n",
       "  ['small', False],\n",
       "  ['towns', False],\n",
       "  ['in', False],\n",
       "  ['the', False],\n",
       "  ['region', False],\n",
       "  [',', False],\n",
       "  ['all', False],\n",
       "  ['contributed', False],\n",
       "  ['in', False],\n",
       "  ['some', False],\n",
       "  ['way', False],\n",
       "  ['to', False],\n",
       "  ['the', False],\n",
       "  ['failure', False],\n",
       "  ['of', False],\n",
       "  ['the', False],\n",
       "  ['workers', False],\n",
       "  ['and', False],\n",
       "  ['unionleaders', False],\n",
       "  ['to', False],\n",
       "  ['save', False],\n",
       "  ['the', False],\n",
       "  ['industry', True],\n",
       "  ['Most', False],\n",
       "  ['importantly', False],\n",
       "  [',', False],\n",
       "  ['the', False],\n",
       "  ['problem', False],\n",
       "  ['in', False],\n",
       "  ['Youngstown', False],\n",
       "  ['was', False],\n",
       "  ['a', False],\n",
       "  ['nationwide', False],\n",
       "  ['problem', True],\n",
       "  ['Althoughit', False],\n",
       "  ['affected', False],\n",
       "  ['Youngstown', False],\n",
       "  ['and', False],\n",
       "  ['the', False],\n",
       "  ['surrounding', False],\n",
       "  ['area', False],\n",
       "  ['more', False],\n",
       "  ['than', False],\n",
       "  ['it', False],\n",
       "  ['affected', False],\n",
       "  ['other', False],\n",
       "  ['regions', False],\n",
       "  [',', False],\n",
       "  ['the', False],\n",
       "  ['local', False],\n",
       "  ['people', False],\n",
       "  ['simplycould', False],\n",
       "  ['not', False],\n",
       "  ['solve', False],\n",
       "  ['a', False],\n",
       "  ['national', False],\n",
       "  ['crisis', False],\n",
       "  ['on', False],\n",
       "  ['a', False],\n",
       "  ['local', False],\n",
       "  ['level.A', False],\n",
       "  ['Brief', False],\n",
       "  ['History', False],\n",
       "  ['of', False],\n",
       "  ['Steel', False],\n",
       "  ['in', False],\n",
       "  ['Northeastern', False],\n",
       "  ['OhioIn', False],\n",
       "  ['1802', False],\n",
       "  ['James', False],\n",
       "  ['and', False],\n",
       "  ['Daniel', False],\n",
       "  ['Heaton', False],\n",
       "  ['discovered', False],\n",
       "  ['ore', False],\n",
       "  ['and', False],\n",
       "  ['coal', False],\n",
       "  ['lining', False],\n",
       "  ['Yellow', False],\n",
       "  ['Creek', False],\n",
       "  ['in', False],\n",
       "  ['an', False],\n",
       "  ['area', False],\n",
       "  ['outside', False],\n",
       "  ['of', False],\n",
       "  ['Youngstown', False],\n",
       "  ['known', False],\n",
       "  ['asPoland', False],\n",
       "  ['Township', True],\n",
       "  ['Their', False],\n",
       "  ['blast', False],\n",
       "  ['furnace', False],\n",
       "  [',', False],\n",
       "  ['“', False],\n",
       "  ['Hopewell', False],\n",
       "  [',', False],\n",
       "  ['”', False],\n",
       "  ['was', False],\n",
       "  ['the', False],\n",
       "  ['very', False],\n",
       "  ['first', False],\n",
       "  ['blast', False],\n",
       "  ['furnace', False],\n",
       "  ['in', False],\n",
       "  ['the', False],\n",
       "  ['area', False]],\n",
       " [['During', False],\n",
       "  ['the', False],\n",
       "  ['Civil', False],\n",
       "  ['War', False],\n",
       "  [',', False],\n",
       "  ['Youngstown', False],\n",
       "  ['played', False],\n",
       "  ['a', False],\n",
       "  ['vital', False],\n",
       "  ['role', False],\n",
       "  ['in', False],\n",
       "  ['supplying', False],\n",
       "  ['the', False],\n",
       "  ['Union', False],\n",
       "  ['army', False],\n",
       "  ['with', False],\n",
       "  ['iron', False],\n",
       "  ['products', True],\n",
       "  ['Youngstown', False],\n",
       "  ['also', False],\n",
       "  ['was', False],\n",
       "  ['a', False],\n",
       "  ['major', False],\n",
       "  ['railwaycrossroads', False],\n",
       "  [',', False],\n",
       "  ['due', False],\n",
       "  ['to', False],\n",
       "  ['its', False],\n",
       "  ['strategic', False],\n",
       "  ['position', False],\n",
       "  ['between', False],\n",
       "  ['Cleveland', False],\n",
       "  [',', False],\n",
       "  ['Pittsburgh', False],\n",
       "  [',', False],\n",
       "  ['New', False],\n",
       "  ['York', False],\n",
       "  [',', False],\n",
       "  ['and', False],\n",
       "  ['Chicago', False]]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataet to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = \"data/dataset.json\"\n",
    "write_to_file(data=json.dumps(dataset), file=dataset_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_n_gram_file(ngram_file):\n",
    "    result = dict()\n",
    "    lines = read_file(ngram_file)\n",
    "    for line in lines:\n",
    "        line_split = line.split('\\t')\n",
    "        key = ' '.join(line_split[1:])\n",
    "        result[key] = line_split[0]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use ngrams downloaded from here: https://www.ngrams.info/download_coca.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram_dict = read_n_gram_file(\"data/w2.txt\")\n",
    "three_gram_dict = read_n_gram_file(\"data/w3.txt\")\n",
    "four_gram_dict = read_n_gram_file(\"data/w4.txt\")\n",
    "five_gram_dict = read_n_gram_file(\"data/w5.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Напишіть базове рішення та метрику для тестування якості.\n",
    "- Для тестування використайте корпус run-on-test.json. Формат корпусу:\n",
    "```\n",
    "[\n",
    "  [\n",
    "    [\"Thanks\", false],\n",
    "    [\"for\", false],\n",
    "    [\"talking\", false],\n",
    "    [\"to\", false],\n",
    "    [\"me\", true],\n",
    "    [\"let\", false],\n",
    "    [\"'s\", false],\n",
    "    [\"meet\", false],\n",
    "    [\"again\", false],\n",
    "    [\"tomorrow\", true],\n",
    "    [\"Bye\", false],\n",
    "    [\".\", false]\n",
    "  ],\n",
    "...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"../../../tasks/06-language-as-sequence/run-on-test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_json(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StubBaselineRunOnSentences:\n",
    "    \n",
    "    def find_sentences(self, merged_sentences: List[str]):\n",
    "        result = []\n",
    "        sentence_tokens_list = []\n",
    "        for merged_sentence in merged_sentences:\n",
    "            tokens = word_tokenize(merged_sentence)\n",
    "            sentence_tokens_list.append(tokens)\n",
    "            \n",
    "            \n",
    "        return self.classify_stub(sentence_tokens_list)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def classify_stub(self, sentence_tokens_list):\n",
    "        #TODO: insert call of classification model\n",
    "        result = []\n",
    "        for tokens in sentence_tokens_list:\n",
    "            sent_result = [[token, False] for token in tokens]\n",
    "            result.append(sent_result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    \n",
    "    @staticmethod\n",
    "    def measure(result_true, result_predicted):\n",
    "        assert len(result_true) == len(result_predicted)\n",
    "        \n",
    "        size = len(result_true)\n",
    "        y_pred_flatten, y_true_flatten = [], []\n",
    "        num_of_mathced_sentences = 0\n",
    "        \n",
    "        for i in range(0, size):\n",
    "            sent_true = result_true[i]\n",
    "            sent_pred = result_predicted[i]\n",
    "            \n",
    "            \n",
    "            y_true = np.array(sent_true)[:, 1]\n",
    "            y_pred = np.array(sent_pred)[:, 1]\n",
    "            \n",
    "            y_true_flatten += y_true.tolist()\n",
    "            y_pred_flatten += y_pred.tolist()\n",
    "            \n",
    "            if sum(y_true == y_pred) == len(y_pred):\n",
    "                num_of_mathced_sentences += 1\n",
    "            \n",
    "            \n",
    "        return classification_report(y_true_flatten, y_pred_flatten), num_of_mathced_sentences / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show example of this metric on test data vs predicted result in stub baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stub_baseline_run_on_sentecnes = StubBaselineRunOnSentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens_list = [ np.array(item)[:, 0].tolist() for item in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_data = stub_baseline_run_on_sentecnes.classify_stub(sentence_tokens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report, matched_sents = Metric.measure(test_data, test_pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98      4542\n",
      "        True       0.00      0.00      0.00       155\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4697\n",
      "   macro avg       0.48      0.50      0.49      4697\n",
      "weighted avg       0.94      0.97      0.95      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are matched 25.0% sentences.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are matched {100 * matched_sents}% sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [np.array(sent)[:, 0].tolist() for sent in dataset]\n",
    "y = [np.array(sent)[:, 1].tolist() for sent in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunOnSentenceCRFClassifier:\n",
    "    def __init__(self, ngrams_dict_list):\n",
    "        self.crf = sklearn_crfsuite.CRF(\n",
    "            algorithm='lbfgs',\n",
    "            c1=0.1,\n",
    "            c2=0.1,\n",
    "            max_iterations=100,\n",
    "            all_possible_transitions=True)\n",
    "        \n",
    "        self.ngrams_dict_list = [bi_gram_dict, three_gram_dict, four_gram_dict, five_gram_dict]\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_data = [self.sent2features(s) for s in X]\n",
    "        self.crf.fit(X_data, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_data = [self.sent2features(s) for s in X]\n",
    "        return self.crf.predict(X)    \n",
    "    \n",
    "    def word2features(self, sent, pos):\n",
    "        word = sent[pos]\n",
    "\n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word.lower()': word.lower(),\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'word.istitle()': word.istitle(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "        }\n",
    "        if pos > 0:\n",
    "            word1 = sent[pos-1]\n",
    "            features.update({\n",
    "                '-1:word.lower()': word1.lower(),\n",
    "                '-1:word.istitle()': word1.istitle(),\n",
    "                '-1:word.isupper()': word1.isupper(),\n",
    "            })\n",
    "        else:\n",
    "            features['BOS'] = True\n",
    "\n",
    "        if pos < len(sent)-1:\n",
    "            word1 = sent[pos+1]\n",
    "            features.update({\n",
    "                '+1:word.lower()': word1.lower(),\n",
    "                '+1:word.istitle()': word1.istitle(),\n",
    "                '+1:word.isupper()': word1.isupper(),\n",
    "            })\n",
    "        else:\n",
    "            features['EOS'] = True\n",
    "            \n",
    "            \n",
    "        self.__update_features_with_nagram(features, sent, pos)\n",
    "\n",
    "        return features\n",
    "    \n",
    "    \n",
    "    def sent2features(self, sent):\n",
    "        return [self.word2features(sent, i) for i in range(len(sent))]\n",
    "    \n",
    "    \n",
    "    def split_dataset_into_X_and_y(self, dataset):\n",
    "        X = [np.array(sent)[:, 0].tolist() for sent in dataset]\n",
    "        y = [np.array(sent)[:, 1].tolist() for sent in dataset]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def X_y_to_dataset_format(self, X, y):\n",
    "        assert len(X) == len(y)\n",
    "        \n",
    "        result = []\n",
    "        for i in range(0, len(y)):\n",
    "            sent = [[X[i][j], y[i][j]] for j in range(0, len(X[i]))]\n",
    "            result.append(sent)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def __update_features_with_nagram(self, features, sent, pos):\n",
    "        \n",
    "        i = pos\n",
    "        while i < len(sent) - 1 and i - pos < len(self.ngrams_dict_list):\n",
    "            ngram = ' '.join(sent[pos: pos + i + 1])\n",
    "            \n",
    "            \n",
    "            n = i - pos + 2\n",
    "            if ngram in self.ngrams_dict_list[i - pos]:\n",
    "                features[f\"{n}-gram\"] = self.ngrams_dict_list[i - pos][ngram]\n",
    "            else:\n",
    "                features[f\"{n}-gram\"] = 0\n",
    "            \n",
    "            i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RunOnSentenceCRFClassifier([bi_gram_dict, three_gram_dict, four_gram_dict, five_gram_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flatten, y_test_flatten = [], []\n",
    "for i in range(0, len(y_pred)):\n",
    "    y_pred_flatten += y_pred[i]\n",
    "    y_test_flatten += y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      1.00      0.99     32271\n",
      "        True       0.00      0.00      0.00       687\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     32958\n",
      "   macro avg       0.49      0.50      0.49     32958\n",
      "weighted avg       0.96      0.98      0.97     32958\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_flatten, y_pred_flatten))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on available test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [np.array(sent)[:, 0].tolist() for sent in test_data]\n",
    "y_test = [np.array(sent)[:, 1].tolist() for sent in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = classifier.X_y_to_dataset_format(X_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_data = classifier.X_y_to_dataset_format(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_report, matched_sents = Metric.measure(test_data, pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      1.00      0.98      4542\n",
      "        True       0.00      0.00      0.00       155\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      4697\n",
      "   macro avg       0.48      0.50      0.49      4697\n",
      "weighted avg       0.94      0.97      0.95      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(clf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_sents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
