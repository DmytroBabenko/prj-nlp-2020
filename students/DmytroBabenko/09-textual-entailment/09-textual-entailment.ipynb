{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonnl(file):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = [json.loads(line) for line in f.readlines()]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snli_path = \"data/snli_1.0/snli_1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_jsonnl(f\"{snli_path}/snli_1.0_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = read_jsonnl(f\"{snli_path}/snli_1.0_dev.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_jsonnl(f\"{snli_path}/snli_1.0_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotator_labels': ['neutral'],\n",
       " 'captionID': '3416050480.jpg#4',\n",
       " 'gold_label': 'neutral',\n",
       " 'pairID': '3416050480.jpg#4r1n',\n",
       " 'sentence1': 'A person on a horse jumps over a broken down airplane.',\n",
       " 'sentence1_binary_parse': '( ( ( A person ) ( on ( a horse ) ) ) ( ( jumps ( over ( a ( broken ( down airplane ) ) ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN on) (NP (DT a) (NN horse)))) (VP (VBZ jumps) (PP (IN over) (NP (DT a) (JJ broken) (JJ down) (NN airplane)))) (. .)))',\n",
       " 'sentence2': 'A person is training his horse for a competition.',\n",
       " 'sentence2_binary_parse': '( ( A person ) ( ( is ( ( training ( his horse ) ) ( for ( a competition ) ) ) ) . ) )',\n",
       " 'sentence2_parse': '(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) (VP (VBG training) (NP (PRP$ his) (NN horse)) (PP (IN for) (NP (DT a) (NN competition))))) (. .)))'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = None\n",
    "for snli_item in dev_data:\n",
    "    if snli_item['gold_label'] =='-':\n",
    "        item = snli_item\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotator_labels': ['entailment',\n",
       "  'neutral',\n",
       "  'entailment',\n",
       "  'neutral',\n",
       "  'contradiction'],\n",
       " 'captionID': '3184031654.jpg#0',\n",
       " 'gold_label': '-',\n",
       " 'pairID': '3184031654.jpg#0r1e',\n",
       " 'sentence1': 'The middle eastern woman wearing the pink headscarf is walking beside a woman in a purple headscarf.',\n",
       " 'sentence1_binary_parse': '( ( ( The ( middle ( eastern woman ) ) ) ( wearing ( the ( pink headscarf ) ) ) ) ( ( is ( walking ( beside ( ( a woman ) ( in ( a ( purple headscarf ) ) ) ) ) ) ) . ) )',\n",
       " 'sentence1_parse': '(ROOT (S (NP (NP (DT The) (JJ middle) (JJ eastern) (NN woman)) (VP (VBG wearing) (NP (DT the) (JJ pink) (NN headscarf)))) (VP (VBZ is) (VP (VBG walking) (PP (IN beside) (NP (NP (DT a) (NN woman)) (PP (IN in) (NP (DT a) (JJ purple) (NN headscarf))))))) (. .)))',\n",
       " 'sentence2': 'Two women are walking together.',\n",
       " 'sentence2_binary_parse': '( ( Two women ) ( ( are ( walking together ) ) . ) )',\n",
       " 'sentence2_parse': '(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP are) (VP (VBG walking) (ADVP (RB together)))) (. .)))'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_X_and_y(nlp, data, feature_extractor):\n",
    "    X, y = [], []\n",
    "    for i in range(0, len(data)):\n",
    "        yi = data[i]['gold_label']\n",
    "        if yi not in ['entailment', 'contradiction', 'neutral']:\n",
    "            continue\n",
    "        xi = feature_extractor(nlp, data[i])\n",
    "        \n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim_by_lemma(sent_tokens1, sent_tokens2): \n",
    "    lemmas1 = set([token.lemma_ for token in sent_tokens1])\n",
    "    lemmas2 = set([token.lemma_ for token in sent_tokens2])\n",
    "\n",
    "    matched = lemmas1.intersection(lemmas2)\n",
    "    return float(len(matched)) / (len(lemmas1) + len(lemmas2) - len(matched))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim_by_verb(sent_tokens1, sent_tokens2): \n",
    "    verbs1 = set([token.lemma_ for token in sent_tokens1 if token.pos_ == \"VERB\" and not token.lemma == \"be\"])\n",
    "    verbs2 = set([token.lemma_ for token in sent_tokens2 if token.pos_ == \"VERB\" and not token.lemma == \"be\"])\n",
    "\n",
    "    matched = verbs1.intersection(verbs2)\n",
    "    if len(verbs1) + len(verbs2) - len(matched) == 0:\n",
    "        return None\n",
    "        \n",
    "    return float(len(matched)) / (len(verbs1) + len(verbs2) - len(matched))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_verbs_in_sent(sentence, nlp):\n",
    "    doc = nlp(sentence)\n",
    "    return set([token.lemma_ for token in doc if token.pos_ == \"VERB\" and not token.lemma == \"be\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_initial_features(nlp, snli_item):\n",
    "    features = {}\n",
    "    text_sent = snli_item['sentence1']\n",
    "    text_sent_tokens = nlp(text_sent)\n",
    "#     print(text_sent)\n",
    "    hypothesis_sent = snli_item['sentence2']\n",
    "    hypothesis_sent_tokens = nlp(hypothesis_sent)\n",
    "#     print(hypothesis_sent)\n",
    "    \n",
    "    features['text-hyp-sim'] = get_jaccard_sim_by_lemma(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    text_hyp_sim_verb = get_jaccard_sim_by_verb(text_sent_tokens, hypothesis_sent_tokens)\n",
    "    if text_hyp_sim_verb:\n",
    "        features['text-hyp-sim-verb'] = text_hyp_sim_verb\n",
    "\n",
    "    features['text-len'] = len(text_sent)\n",
    "    features['hyp-len'] = len(hypothesis_sent)\n",
    "    \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 40min 1s, sys: 12.3 s, total: 1h 40min 13s\n",
      "Wall time: 1h 40min 19s\n"
     ]
    }
   ],
   "source": [
    "%time X_train, y_train = convert_data_to_X_and_y(nlp, train_data, exctract_initial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev, y_dev = convert_data_to_X_and_y(nlp, dev_data, exctract_initial_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', DictVectorizer()),\n",
    "    ('svm', svm.SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 DictVectorizer(dtype=<class 'numpy.float64'>, separator='=',\n",
       "                                sort=True, sparse=True)),\n",
       "                ('svm',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_pred = clf.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.42      0.54      0.47      3278\n",
      "   entailment       0.57      0.49      0.53      3329\n",
      "      neutral       0.47      0.41      0.44      3235\n",
      "\n",
      "     accuracy                           0.48      9842\n",
      "    macro avg       0.49      0.48      0.48      9842\n",
      " weighted avg       0.49      0.48      0.48      9842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_dev_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
